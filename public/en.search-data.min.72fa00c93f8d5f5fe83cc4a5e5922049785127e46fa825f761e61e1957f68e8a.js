'use strict';(function(){const t={cache:!0};t.doc={id:"id",field:["title","content"],store:["title","href","section"]};const e=FlexSearch.create("balance",t);window.bookSearchIndex=e,e.add({id:0,href:"/posts/pgfplots/",title:"How to use TikZ in scientific plotting?",section:"Blog",content:" TikZ is a powerful drawing package for academics who are using LaTeX for paper writing. Unlike other TeX packages, TikZ itself is really huge, its manual contains about 1100+ pages, 100+ chapters. Tens of other packages, and serveral GUI applications are based on TikZ.\nInstead of being comprehensive, this page mainly aims to provide a curated list of awesome TikZ templates frequently used in our COLA laboratory.\n Scatter plots #   "}),e.add({id:1,href:"/posts/overleaf_naming/",title:"How to name your Overleaf project?",section:"Blog",content:"  Overleaf is a collaborative cloud-based LaTeX editor used for writing, editing and publishing scientific documents. In COLA laboratory, we use the Overleaf as the centralized place to manage our manuscripts. In order to make the projects be managed in an organized manner, a project is usually named as A_B_C.\n A: journal/conference name, e.g., TEVC/PPSN22 B: acronym of the algorithm, e.g., TBO2 C: first character of your name, e.g., RC  This comes up to be a typical example: TEVC_TBO2_RC.\nNote that since the University of Exeter is a partner of Overleaf, you are free to use the professional version by using your university\u0026rsquo;s email account to register. There are some very cool function of using this professional version.\n You can sync your project to either Dropbox or Github, though this is applicable for regular account. This is very useful when you find the online Overleaf version is kind of slow. It is very cool to track the changes by turning Track changes on. Try to get yourself comfortable with the comment function in Overleaf, so that we can address concerns in an interactive manner. \u0026hellip;\u0026hellip;  There can be even more cool stuffs. I will amend this later when it comes down.\n"}),e.add({id:2,href:"/posts/bibtex_rule/",title:"How to prepare your bibtex file?",section:"Blog",content:" Bibtex is a powerful tool to manage your references in scientific writing by using LaTeX. However, the bibtex sources can be messy in the wild. Here are some useful tips to prepare a beautiful and clean bibtex file.\n Instead of searching from Google, it might be more convenient to search the corresponding paper or author in DBLP. There is an option to choose the export record as the BibTeX. It will be more efficient to use some text editor like Vim to facilitate your editing. However, there is a steep learning curve to manage the Vim. Be careful to include unnecessary components in your bib. For example, it will take extra space if you include url and doi. Note that most publishers have a strict rule on the page length. If the corresponding paper is not published yet, i.e., just accepted or in press, there is usually NO pages, volume and number related information. Instead, we just need to amend a note component in the bibtex: note={accepted for publication}.  In the following paragraphs, we mainly focus on three types of publications to give you some tangible examples.\nJournal article\nLet us use the following example from one of my papers to explain the format.\n@article{LiZKLW14, author = {Ke Li and Qingfu Zhang and Sam Kwong and Miqing Li and Ran Wang}, title = {Stable Matching-Based Selection in Evolutionary Multiobjective Optimization}, journal = {{IEEE} Trans. Evol. Comput.}, volume = {18}, number = {6}, pages = {909--923}, year = {2014}, doi = {10.1109/TEVC.2013.2293776}, timestamp = {Mon, 27 Nov 2017 16:55:26 +0100}, biburl = {http://dblp.org/rec/bib/journals/tec/LiZKLW14}, bibsource = {dblp computer science bibliography, http://dblp.org} } Most components can be directly obtained from the paper itself. We only explicitly explain the following components.\n bibtex entry ABC:  A: The last name of the first author, e.g., \u0026ldquo;A = Li\u0026rdquo; in this example. B: The first letter of each of the other authors, e.g., \u0026ldquo;B = ZKLW\u0026rdquo; in this example. C: Shortcut of the publication year, e.g., \u0026ldquo;C = 14\u0026rdquo; in this example.   title: Please capitalize each word in the paper title, except for some conjunction words or so. journal: Please try to use the abbreviation of the journal name as much as you can. You can easily Google this information. Alternatively, you can refer to the relevant publisher for detailed information. pages: Please use double hyphens to connect the page numbers. doi, timestamp, biburl and bibsource are not always necessary. But you can find more information from the DBLP of the corresponding author(s).  If the paper is not published yet, the bibtex will be simplified as follows.\n@article{LiNGY21, author = {Ke Li and Haifeng Nie and Huiru Gao and Xin Yao}, title = {Posterior Decision-Making Based on Decomposition-Driven Knee Point Identification}, journal = {{IEEE} Trans. Evol. Comput.}, year = {2021}, note = {accepted for publication} }  Conference article\nConference paper is slightly different from the journal article. It is usually published as a proceeding thus there is no issue or volume number. Instead, we usually need to formulate the name of the proceeding. Sometimes the editors are required to be listed, but I usually recommend to omit that part. Let us use the following example to explain this format.\n@inproceedings{WuKJLZ17, author = {Mengyuan Wu and Sam Kwong and Yuheng Jia and Ke Li and Qingfu Zhang}, title = {Adaptive weights generation for decomposition-based multi-objective optimization using Gaussian process regression}, booktitle = {GECCO\u0026#39;17: Proc. of the 2017 Genetic and Evolutionary Computation Conference}, pages = {641--648}, publisher = {{ACM}}, year = {2017}, timestamp = {Fri, 27 Mar 2020 09:03:02 +0100}, biburl = {https://dblp.org/rec/conf/gecco/WuKJLZ17.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} } The other rules are almost the same as the journal article, except the following components.\n booktitle is formulated as: S'Y: Proc. of the xxxx Conference on  S: Abbreviation of the conference, e.g., \u0026ldquo;S = GECCO\u0026rdquo; in this example. Y: Shortcut of the conference year, e.g., \u0026ldquo;Y = 17\u0026rdquo; in this example. xxxx: conference year, e.g., \u0026ldquo;xxxx = 2017\u0026rdquo; in this example.     Book\nBook is a bit different from the journal and conference papers. Most components can be directly derived from the book itself. You can apply the previous formats here. Let us use the following example to explain this format.\n@book{Deb01, author = {Kalyanmoy Deb}, title = {Multi-Objective Optimization Using Evolutionary Algorithms}, publisher = {John Wiley \\\u0026amp; Sons, Inc.}, address = {New York, NY, USA}, year = {2001} }  Technical report\n@techreport{ABC, author = {xx and xx}, title = {xx}, institution = {xx}, year = {xxxx} }  ArXiv paper\n@article{Frazier18, author = {Peter I. Frazier}, title = {A Tutorial on {Bayesian} Optimization}, journal = {CoRR}, volume = {abs/1807.02811}, year = {2018}, url = {http://arxiv.org/abs/1807.02811}, archivePrefix = {arXiv}, eprint = {1807.02811}, timestamp = {Mon, 13 Aug 2018 16:48:03 +0200}, biburl = {https://dblp.org/rec/journals/corr/abs-1807-02811.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} } "}),e.add({id:3,href:"/academicons/academicons-1.9.0/README/",title:"Readme",section:"Academicons",content:"What is Academicons? #  Academicons is a specialist icon font for academics. It contains icons for websites and organisations related to academia that are often missing from mainstream font packages. It can be used by itself, but its primary purpose is to be used as a supplementary package alongside a larger icon set. Go here to view the full icon set along with instructions for their use.\nRequesting new icons #  New icons can be requested by creating an issue here. Before submitting a request, please check that the following conditions are satisfied:\n  The organisation in question is already using a logo/icon of appropriate dimensions (roughly square). If that doesn\u0026rsquo;t exist, then there\u0026rsquo;s really not much that can be done, and the request will have to be ignored until such time that a logo/icon can be provided.\n  An icon of appropriate resolution can be provided or linked to. Ideally, the provided file will be a vector file (e.g. SVG, EPS, AI) or a PDF with the vector file embedded. These files are all very easy to work with, and result in the most faithful reproductions of the icon. Altenatively, high resolution raster images (e.g. JPEG, PNG, GIF) can work, but only if the resolution is high enough that the underlying shapes can be reproduced. Icons made from raster images take much longer to prepare, and require hand drawing each component and figuring out the exact typeface used for any letters. This process can be rather tedious, and I will only do this if there is significant demand for the icon. Favicon files can be useful in conjunction with larger logos that have non-ideal aspect ratios—where they can indicate which part of the logo to strip down to—but they are pretty much useless by themselves. The only time I have made an icon from a favicon was for arXiv, and that was only because: (i) It was heavily requested, and (ii) I was able to get feedback on the new icon from Paul Ginsparg, who made the original icon. You can still submit the request, but it will likely be ignored until someone else comes along and provides the file we need.\n  The icon can be reduced to monochrome. This is one of the basic requirements of a versatile icon, but it is often overlooked when icons are made by people who are not professional designers. Academia is full of unprofessional designers, and it is sometimes the case that a logo relies entirely on the use of different colours. In certain cases we can be creative (see the dblp logo), but more often than not it will be impossible to create a monochrome version of the icon. Again, feel free to make the request, but it will probably be ignored if an alternate logo cannot be found.\n  License #   The Academicons font is licensed under the SIL OFL 1.1:   http://scripts.sil.org/OFL   Academicons CSS, LESS, and SASS files are licensed under the MIT License:   http://opensource.org/licenses/mit-license.html   The Academicons documentation is licensed under the CC BY 3.0 License:   http://creativecommons.org/licenses/by/3.0/    Author #   GitHub: https://github.com/jpswalsh Web: http://jpswalsh.com  "}),e.add({id:4,href:"/docs/events/archive/archive_seminar/",title:"Archive of COLA Seminar Series",section:"Docs",content:"  Archive of COLA Seminar Series #  2022 #  Agenda (Year 2021) #  June  Exeter-Leiden Symposium on Data-Driven Modeling and Optimization\n Website |  Ke Li, Hao Wang |  June 6   "}),e.add({id:5,href:"/docs/events/archive/archive_reading/",title:"Archive of Reading Group",section:"Docs",content:"Archive of Reading Group #  Agenda (Year 2022) #  Oct  Optimizing Millions of Hyperparameters by Implicit Differentiation\nAISTAS 2020\n paper |  slides |  Han Guo |  October 16   Agenda (Year 2021) #  June   Learning from Multiple Cities: A Meta-Learning Approach for Spatial-Temporal Prediction\nWWW 2019\n paper |  slides |  Jiangjiao Xu |  June 20\n  Bayesian temporal factorization for multidimensional time series prediction\nIEEE PAMI 2021\n paper |  slides |  Jiangjiao Xu |  June 13\n  Discrete Fourier Transform and Random Fourier Features\nData-Driven Science and Engineering, Chapter 2: 47\u0026ndash;83, 2019\n slides |  Phoenix Williams |  June 9\n  May   Global Optimization via Inverse Distance Weighting and Radial Basis Functions\nComput. Optim. Appl., 77: 571\u0026ndash;595, 2020\n paper |  slides |  Jiahao Zhou |  May 30\n  Sequential Monte Carlo: Theory and Applications\nFoundations and Trends in Machine Learning, 12(3): 307\u0026ndash;392, 2019\n paper |  slides |  Peili Mao |  May 23\n  Mar   Generalized Homotopy Approach to Multiobjective Optimization\nJ. Optimiz. Theory App., 110: 557\u0026ndash;583, 2001\n paper |  slides |  Yongqi Feng |  Mar 15\n  Machine Learning Approaches in Programming Language Type Inference\n slides |  Jiancheng Qian |  Mar 7\n  Feb  Understanding and Improving Information Transfer in Multi-Task Learning\nICLR 2020\n paper |  slides |  Renzhi Chen |  Feb 7  Jan   OOD-MAML: Meta-Learning for Few-ShotOut-of-Distribution Detection and Classification\nNIPS 2020\n paper |  slides |  Jiangjiao Xu |  Jan 31\n  Domination Measure: A New Metric for Solving Multiobjective Optimization\nINFORMS J. Comput., 32(3): 565\u0026ndash;581, 2020\n paper |  slides |  Xinyu Shan |  Jan 24\n  ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators\nICLR 2020\n paper |  slides |  Shasha Zhou |  Jan 3\n   Agenda (Year 2020) #  Dec   Surrogate Assisted Evolutionary Algorithms, Fan Li Dec 27\n[slides]\n  RoboGrammar: Graph Grammar for Terrain-Optimized Robot Design, ACM Trans. Graphics. Jiahao Zhou Dec 20\n[ paper] [slides]\n  Optimization, Fast and Slow: Optimally Switching Between Local and Bayesian Optimization, ICML 2018. Guozhao Wei Dec 13\n[ paper] [slides]\n  Nov   Ordinal Regression with Multiple Output CNN for Age Estimation, CVPR 2016. Guiyu Lai Nov 29\n[ paper] [ slides]\n  Towards Fast Adaptation of Neural Architectures with Meta Learning, ICLR 2020. Shasha Zhou Nov 22\n[ paper] [ slides]\n   "}),e.add({id:6,href:"/docs/events/archive/archive_study/",title:"Archive of Study Group",section:"Docs",content:"  Archive #  2022 #  "}),e.add({id:7,href:"/docs/events/seminars/",title:"COLA Seminar Series",section:"Docs",content:"COLA Seminar Series #     This is our seminar series where we exchange ideas with guest speakers, keeping you up to date with the latest developments and inspiring research topics. Occasionally, COLA researchers present their own work as well.  Agenda (Year 2023) #  April  Turing Workshop on Human-Centric AI and Applications\n Website |  Ke Li |  April 26-28    Previous seminar series can be found from our archive.\n"}),e.add({id:8,href:"/docs/misc/ddl/",title:"Deadlines",section:"Docs",content:"Deadlines #  Here are some important deadlines for the major conferences in artificial intelligence and machine learning (AI \u0026amp; ML), data mining (DM), natural language processing (NLP), software engineering (SE) and evolutionary computation (EC) domains.\nAI   IJCAI 2023: January 18, 2023  ECAI 2023: May 8, 2023  AAAI 2024: August 15, 2023  ICLR 2023: September 28, 2022  ML   ICML 2023: January 26, 2023  AutoML 2023: March 23, 2023  ECML/PKDD 2023: April 2, 2023  UAI 2022: February 17, 2023  NeurIPS 2023: May 17, 2023  AISTAS 2023: October 13, 2022  CV   CVPR 2023: November 11, 2022  ICCV 2023: March 8, 2023  ECCV 2022: March 7, 2022  DM   KDD 2023: February 2, 2023  ICDM 2023: July 1, 2023  SDM 2023: October 14, 2022  CIKM 2023: June 2, 2023  NLP   ACL 2022: November 15, 2021  NAACL 2022: Jan 15, 2022  COLING 2022: May 15, 2022  EMNLP 2022: May 24, 2022  SE   ISSTA 2023: November 10, 2022 (1st round) | February 16, 2023 (2nd round)  FSE 2023: February 2, 2023  ASE 2023: May 5, 2023  ICSE 2024: March 29, 2023 (1st round) | August 1, 2023 (2nd round)  ICSME 2023: April 27, 2023  ICPC 2023: December 19, 2022  ESEM 2023: May 2, 2023  ISSRE 2023: May 22, 2023  SANER 2023: October 21, 2022  ICST 2023: January 27, 2023  QRS 2022: September 10, 2022  MSR: January 16, 2023  EC   GECCO 2023: February 10, 2023  WCCI 2022: January 31, 2022  PPSN 2022: April 13, 2022  IJCNN 2022: January 31, 2023  CEC 2023: January 13, 2023  SMC 2023: April 15, 2023  FOGA 2022: May 7, 2022  SSCI 2023: June 30, 2023   "}),e.add({id:9,href:"/docs/research/emoc/",title:"EMOC",section:"Docs",content:" EMOC stands for Evolutionary Multi-objective Optimization in C++ which is a framework for single-objective and multi-objective optimization.\nFor more information about installation and usage, please refer to the document site.\n Features #    Rich algorithms and problems\nEMOC implemented about 30 algorithms and more than 80 test problems which both include single-objective and multi-objective types.\n  Developed in C++ and Cross-platform\nAll the source code of EMOC are wrote in C++. So the running efficiency is guaranteed when comparing other implementation with python, java or matlab. We also provide cross-platform compatibility for users with different operator systems.\n  Friendly GUI\nEMOC provides a user-friendly GUI with the function of configuring parameters of once-run and experiments without writing a single line of code.\n  Various Optimization Types\nEMOC supports unconstraint optimization, constraint optimization and combinatorial optimization (including binary encoding and permutation encoding).\n  Save into Excel or Latex\nUsers can save the experiment results of EMOC in the format of Latex.\n   Third Party Libraries #    GLFW  ALGLIB  Dear Imgui  pybind11  cxxopts  stb_image  Gnuplot  CMake  FontAwesome  "}),e.add({id:10,href:"/docs/research/grants/",title:"Grants",section:"Docs",content:"Grants #      hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 40% 60%; grid-gap: 5px; background-color: transparent; padding: 5px; }  We are grateful to have been generously supported by or closely working with the following funding bodies and industrial partners.  Ongoing  Transfer Optimisation System for Adaptive Automated Nature-Inspired Optimisation\n UKRI Future Leaders Fellowship Phase 2:  #MR/X011135/1 |  PI |  £743,285 (prima facie case) |  2023\u0026ndash;2026.\nPhase 1:  #MR/S017062/1 |  PI |  £1,370,803 |  2019\u0026ndash;2023.    Evolutionary Multi-Objective Search for Automating CNN Architecture Design\n Royal Society |  #IES\\R2\\212077 |  PI |  £11,815 |  2021\u0026ndash;2023.    Human-Centric Computing\n Alan Turing Fellowship |  PI |  2021\u0026ndash;2023.    Towards Scalable Multi-Objective Bilevel Optimization: Foundations, Methodologies and Applications\n Hong Kong GRF |  # 11211521 |  Co-I (with PI: Prof. Kay Chen Tan from The Hong Kong Polytechnic University) |  HK$1,150,000 |  2021\u0026ndash;2024.    Knowledge Representation in Transfer Optimisation System and Applications for Highly Configurable Software Systems\n EPSRC DTP Doctoral Prize |  #2404317 |  PI |  £74,000 |  2020\u0026ndash;2024.  Finished  Many Hands Make Work Light: Multi-task Deep Semantic Learning for Testing Web Application Firewalls\n Amazon Research Award |  PI |  $80,000 +  $10,000 |  2021\u0026ndash;2022.    Transfer Bayesian Optimization for Multi-Fidelity Data in Uncertain Environments\n European Network Fund |  #GP ENF5.10 |  PI |  £7,440 |  2021\u0026ndash;2022.    Dynamic Resource Management and Optimization for SLA Guarantees in Hyperconverged Communication Infrastructures\n EPSRC Industrial CASE Studentship |  #EP/P51049X/1 |  Co-I (with PI: Prof. Geyong Min) |  £81,430 |  2017\u0026ndash;2021.    Multi-Task Semi-Supervised Deep Learning based on Evolutionary Algorithms and Its Applications\n NSFC |  #61876162 |  Co-I (with PI: Prof. Kay Chen Tan) |  ¥640,000 |  2019\u0026ndash;2022.     University of Exeter Start-up Grant |  PI |  £10,000 |  2017\u0026ndash;present.    Three-Fold Decomposition in Multi-objective Optimization\n North-European Associated Team Project between INRIA Lille Nord Europe and University of Exeter |  PI |  €10,000 |  2018\u0026ndash;2020.    Key Questions in Multi-Label Active Learning: Multi-objective Optimisation\n Royal Society International Exchange Program (Cost Share with NSFC) |  #IEC/NSFC/170243 |  PI |  £11,863 |  2018\u0026ndash;2020.    Research on Key Problems in Dynamic Environment Multi-objective Evolutionary Optimization\n NSFC |  #61502408 |  Co-I (with PI: Prof. Juan Zou) |  ¥250,000 |  2015\u0026ndash;2018.    DAASE: Dynamic Adaptive Automated Software Engineering\n EPSRC Program Grant |  #EP/J017515/1 |  Research Fellow |  ¥6,834,903 |  2012\u0026ndash;2019.    Evolutionary Computation for Dynamic Optimisation in Network Environments\n EPSRC |  #EP/K001523/1 |  Research Fellow |  ¥512,325 |  2013\u0026ndash;2017.    Stable Matching Theory in Multiobjective Evolutionary Algorithm based on Decomposition\n Hong Kong GRF |  #11205314 |  proposal drafting and activity scheduling |  HK$692,894 |  2014\u0026ndash;2017.    RCUK #   International #   Industry Partners #  "}),e.add({id:11,href:"/docs/misc/dtec/",title:"IEEE DTEC",section:"Docs",content:"IEEE CIS Task Force 12 #  Task Force on Decomposition-based Techniques in Evolutionary Computation Objectives #  As the name suggests, the basic idea of the decomposition-based technique is to transform the original complex problem into simplified subproblem(s) so as to facilitate the optimization. Decomposition-based techniques have been widely used for solving both single- and multi-objective optimization problems. More specifically, in single-objective optimization, especially for the large-scale scenarios, which consider a tremendous amount of decision variables, the decomposition-based technique contains three aspects: 1) analyzing and understanding the fitness landscape and modularity structure of the underlying problem; 2) decomposing the original complex problem into several loosely coupled or independent subproblems based on the learnt characteristics; 3) using a meta-heuristic to solve these subproblems in a sequential or concurrent manner. As for multi-objective optimization, the decomposition means to decompose the original multi-objective optimization problem into a number of single-objective optimization sub-problems (or simple multi-objective optimization problems) and then uses a meta-heuristic to optimize these sub-problems simultaneously and collaboratively. In this big data era, the decomposition-based techniques used for both single- and multi-objective optimization can be sythesized to address the challenges posed by the curse of dimensionality, i.e., many objectives and large scale variables.\nThe key objective of this task force it to generalize the decomposition-based idea and to promote its related research, including its development, education and understanding of its sub topic areas.\nThe main objectives of the task force can be summarized as follows:\n create an active and healthy community to promote theme areas of decomposition-based techniques make student, researchers, end-users, developers, and consultants aware of the state-of-the-art promote the use of decomposition-based methodologies/techniques and tools organize conferences/workshop with IEEE CIS Technical Co-Sponsorship organize tutorials, workshops and special sessions launch edited volumes, books, and special issues in journals  Anticipated Interests #  This task force will focus on all aspects, including theory, practice and applications, of the decomposition-based technique in evolutionary computation for solving both single-, multi- and many-objective optimization problems. Topics of interest including but are not limited to the following:\n Design of novel weight vector generation methods Development of new decomposition methods Design of novel computational resource allocation strategies Integration of new reproduction operators Investigation of novel mating selection and replacement procedures Understanding of the relationship between subproblems and solutions Development of novel decomposition-based MOEAs Hybridization of dominance- and decomposition-based approaches Incorporation of user-preferences in decomposition-based MOEAs Extension to many-objective optimization problems Extension to constrained multi- and many-objective optimization problems Design of novel methods to analyze and understand the modularity structure Design of novel cooperative coevolution for large-scale optimization problems Theoretical analysis of the decomposition-based methods  On-Going Activities #   Special session on Advances in Decomposition-based Evolutionary Multi-­objective Optimization, at the 2021 IEEE Congress on Computational Intelligence (IEEE CEC 2021), organized by Saúl Zapotecas-Martínez, Bilel Derbel, Ke Li and Qingfu Zhang. Workshop on Decomposition Techniques in Evolutionary Optimization (DTEO), at the 2021 Genetic and Evolutionary Computation Conference (GECCO 2021). The deadline is February 4, 2021 Please consider submitting your best work to this workshop and see you in Cancun! Tutorial on Decomposition Multi-Objective Optimization: Current Developments and Future Opportunities, at the 2021 Genetic and Evolutionary Computation Conference (GECCO 2021), organised by Ke Li and Qingfu Zhang.  Past Activities #   Special session on Advances in Decomposition-­based Evolutionary Multi-­objective Optimization, at the 2020 IEEE Congress on Computational Intelligence (IEEE WCCI 2020), organized by Saúl Zapotecas-Martínez, Bilel Derbel, Ke Li and Qingfu Zhang. Workshop on Decomposition Techniques in Evolutionary Optimization (DTEO), at the 2020 Genetic and Evolutionary Computation Conference (GECCO 2020). The deadline is March 27, 2020 Please consider submitting your best work to this workshop and see you in Cancun! Tutorial on Decomposition Multi-Objective Optimization: Current Developments and Future Opportunities, at the 2020 Genetic and Evolutionary Computation Conference (GECCO 2020), organised by Ke Li and Qingfu Zhang. Tutorial on Decomposition Multi-Objective Optimization: Current Developments and Future Opportunities, at the 16th International Conference on Parallel Problem Solving from Nature (PPSN XVI), organised by Ke Li and Qingfu Zhang. Special session on Advances in Decomposition-­based Evolutionary Multi-­objective Optimization, at the 2019 IEEE Congress on Evolutionary Computation (IEEE CEC 2019), organized by Saúl Zapotecas-Martínez, Bilel Derbel, Ke Li and Qingfu Zhang. Workshop on Decomposition Techniques in Evolutionary Optimization (DTEO), at the 2019 Genetic and Evolutionary Computation Conference (GECCO 2019). The deadline is March 27, 2019. Please consider submitting your best work to this workshop and see you in Prague! Tutorial on Decomposition Multi-Objective Optimization: Current Developments and Future Opportunities, at the 2019 Genetic and Evolutionary Computation Conference (GECCO 2019), organised by Ke Li and Qingfu Zhang. Workshop on Decomposition Techniques in Evolutionary Optimization (DTEO), at the 2018 Genetic and Evolutionary Computation Conference (GECCO 2018). The deadline is March 27, 2018. Please consider submitting your best work to this workshop and see you in Kyoto! Tutorial on Decomposition Multi-Objective Optimization: Current Developments and Future Opportunities, at the 2018 Genetic and Evolutionary Computation Conference (GECCO 2018), organised by Ke Li and Qingfu Zhang. Special issue on Recent Advances in Evolutionary Multi-Objective Optimization, at the Swarm and Evolutionary Computation journal, organized by Slim Bechikh and Carlos. A. Coello Coello. The deadline is May 30, 2017. You are highly encouraged to submit your best work here! Special session on Advances in Multiobjective Evolutionary Algorithms based on Decomposition, at the IEEE Congress on Evolutionary Computation (IEEE CEC 2017), organized by Anupam Trivedi, Dipti Srinivasan and Qingfu Zhang. Tutorial on Recent Advances in Multi-objective and Many-objective Evolutionary Algorithms, at the IEEE Congress on Evolutionary Computation (IEEE CEC 2017), organized by Anupam Trivedi and Dipti Srinivasan. Plenary Talk on Use of Traditional Optimization Methods in Multiobjective Evolutionary Computation, at the IEEE Congress on Evolutionary Computation (IEEE CEC 2017), delivered by Qingfu Zhang. Tutorial on Advances in Multi-objective Evolutionary Algorithms based on Decomposition, at the Australasian Conference on Artificial Life and Computational Intelligence (ACALCI 2017), organized by Anupam Trivedi and Dipti Srinivasan. Special session on Advances in Decomposition­based Evolutionary Multi­objective Optimization, at the IEEE World Congress on Computational Intelligence (IEEE WCCI 2016), organized by Sa\u0026rsquo;ul Zapotecas Mart\u0026rsquo;inez, Bilel Derbel, Qingfu Zhang and Carlos A. Coello Coello. Tutorial on Decomposition and Cooperative Coevolution Techniques for Large Scale Global Optimization, at the IEEE Congress on Evolutionary Computation (IEEE CEC 2015), organized by Xiaodong Li. Tutorial on Decomposition and Cooperative Coevolution Techniques for Large Scale Global Optimization, Genetic and Evolutionary Computation Conference (GECCO 2014), organized by Xiaodong Li.  Resources #    Repository of the state-of-the-art developments of multi-objective evolutionary algorithm based on decomposition (MOEA/D) can be found from here.\n  Recent survey paper on the developments of MOEA/D:\n A. Trivedi, D. Srinivasan, K. Sanyal, A. Ghosh, A Survey of Multiobjective Evolutionary Algorithms based on Decomposition, IEEE Trans. on Evolutionary Computation, 21(3): 440-462, 2016. A. Santiago, H. Huacuja, B. Dorronsoro, J. Pecero, C. Santillan, J. Barbosa, J. Monterrubio, A Survey of Decomposition Methods for Multi-objective Optimization, Recent Advances on Hybrid Approaches for Designing Intelligent Systems, 453-465, 2014.    Chairs #    Bilel Derbel (Chair), University of Lille, France.  Ke Li (Vice Chair, Founding Chair), Department of Computer Science, University of Exeter, Exeter, UK.  Qingfu Zhang (Vice Chair), Department of Computer Science, City University of Hong Kong, Hong Kong SAR, China.  Members #    Slim Bechikh, University of Tunis, Tunisia.  Ran Cheng, Southern University of Science and Technology, China.  Kalyanmoy Deb, Michigan State University, USA.  Hisao Ishibuchi, Osaka Prefecture University, Japan.  Yaochu Jin, University of Surrey, UK.  Sam Kwong, City University of Hong Kong, Hong Kong SAR, China.  Xiaodong Li, RMIT University, Australia.  Arnaud Liefooghe, University of Lille, France.  Hui Li, Xi\u0026rsquo;an Jiaotong University, China.  Miqing Li, University of Birmingham, UK.  Sanaz Mostaghim, Otto von Guericke University of Magdeburg, Germany.  Tapabrata Ray, University of New South Wales, Australia.  Dipti Srinivasan, National University of Singapore, Singapore.  Hiroyuki Sato, University of Electro-communications, Japan.  Kay Chen Tan, City University of Hong Kong, Hong Kong SAR, China.  Ke Tang, Southern University of Science and Technology, China.  Shengxiang Yang, De Montfort University, UK.  Aimin Zhou, East China Normal University, China.  Saúl Zapotecas, Unidad Cuajimalpa, México.  "}),e.add({id:12,href:"/docs/home/members/",title:"Members",section:"Docs",content:"Members #      hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 15% 35% 15% 35%; grid-gap: 15px; background-color: transparent; padding: 5px; align-content: left; }   Lookup table of acronyms in this page. \u0026#43;   EMO: evolutionary multi-objective optimization BO: Bayesian optimization BLO: bi-level optimization MFO: multi-fidelity optimization CO: constrained optimization DO: dynamic optimization MCM: Monte Carlo method    LA: landscape analysis TL: transfer learning MTL: multi-task learning LL: life-long learning GP: Gaussian processes NLP: natural language processing SE: software engineering VNF: virtual network functions         Faculty #   Dr Ke Li\nUKRI FLF | Turing Fellow\nSenior Lecturer\nDepartment of Computer Science\nUniversity of Exeter\n          Research Staff(s) #   Dr Fan Li\nResearch Fellow\n04/2021 – present\nInterests: MFO, TL, MTL, EMO     PhD Student(s) #   Phoenix Williams\nPhD Student\n2020 - present\nInterests: BO, TL, EMO   Heng Yang\nPhD Student\n2021 – present\nInterests: NLP, SE, Code naturalness    Peili Mao\nPhD Student\n2021 – present\nInterests: SE, BO, MCM, LA   Shengbo Wang\nPhD Student\n2021 – present\nInterests: BO, SO    Jiancheng Qian\nPhD Student\n2020 – present\nInterests: NLP, SE, Code naturalness   Savas Yuec\nPhD Student\n2018 - present\nInterests: EMO, BO, reliability    Dongya Wang\nPhD Student\n2018 - present\nInterests: EMO, CO     Visitor(s) #   Shuang Li\nVisiting PhD Student\nHarbin Institute of Technology\n08/2022 – present\nInterests: EMO, BO   Kailai Gao\nVisiting PhD Student\nNortheastern University\n02/2023 – present\nInterests: BO, MTL     Alumni #  PhD students   Dr Joseph Billingsly\n 01/09/2017 \u0026ndash; 01/05/2022, University of Exeter PhD student, co-supervised with Prof. Geyong Min Job: -\u0026gt; G-Research London Outputs: 2 EMO papers, 1 GLOBECOM paper, 1 WCCI paper    Dr Mengyuan Wu\n 01/09/2014 \u0026ndash; 01/07/2018, City University of Hong Kong PhD student, co-supervised with Prof. Sam Kwong Job: -\u0026gt; Huawei Noah\u0026rsquo;s Ark Laboratory Outputs: 3 IEEE Trans papers, 1 GECCO paper, 1 SMC paper    Dr Renzhi Chen\n 01/09/2013 \u0026ndash; 01/06/2018, University of Birmingham PhD student, co-supervised with Prof. Xin Yao Job: -\u0026gt; National Defense University of Technology -\u0026gt; PLA Academy of Military Science Outputs: 4 IEEE Trans papers    Postdocs   Dr Jiangjiao Xu\n 01/07/2020 - 01/11/2022, University of Exeter Job: Zhongneng Integrated Smart Energy Technology Co. Ltd. Beijing, China    Dr Xinqi Li\n 01/11/2021 \u0026ndash; 01/08/2022, University of Exeter Job: -\u0026gt; GLAMOROUS.AI    Visiting students  Miss Jiaxin Chen  06/2021 \u0026ndash; 05/2023, Northeastern University Visiting PhD student   Miss Huan Zhang  06/2021 \u0026ndash; 01/12/2022, Northeastern University Visiting PhD student   Mr Jiadi Liu  01/11/2019 \u0026ndash; 05/11/2020, Southwest University Visiting PhD student   Mr Ruxin Zhao  01/11/2019 \u0026ndash; 05/11/2020, Nanjing University of Science and Technology Visiting PhD student   Miss Yingying Guan  01/11/2019 \u0026ndash; 05/11/2020, Northeastern University Visiting PhD student   Mr Lingjie Li  01/09/2019 \u0026ndash; 01/12/2019, Shenzhen University Visiting student   Dr Nan Mu  01/06/2018 \u0026ndash; 31/12/2018, Wuhan University of Technology Visiting PhD student Job: -\u0026gt; Sichuan Normal University    Visiting scholars  Dr Lei Yang  01/12/2017 \u0026ndash; 01/12/2018, South China Agricultural University Visiting scholar Job: -\u0026gt; South China Agricultural University   Dr Geng Lin  01/07/2018 \u0026ndash; 01/08/2018, Minjiang University Visiting scholar Job: -\u0026gt; Minjiang University     "}),e.add({id:13,href:"/docs/home/news/",title:"News",section:"Docs",content:"  News Archive #  2022 #  Dec   COLA-Lab is hiring!!! We have multiple fully funded PhD studentships available for September 2023 entry. Detailed information can be found from here.  December 1\n  Our papers on \u0026ldquo;Interactive Evolutionary Multi-Objective Optimization via Learning-to-Rank\u0026rdquo; has been accepted to IEEE Trans. Evol. Comput. Congratulations to Guiyu!  December 22\n  We have two papers accepted to EMO 2023. Congratulations to Renzhi and Phoenix! See you in Leiden!  December 7\n  My UKRI Future Leaders Fellowship renewal has been approved as a prima facie case, i.e., without any further interview justification. There will be an additional three-year funding started from May 2023. Really appreciated the generous support from UKRI in the past nearly four years. Look forward to create a new research programme and fight for its future in the coming years.  December 1\n  Our paper on \u0026ldquo;MTLP-JR: Multi-Task Learning-Based Prediction for Joint Ranking in Neural Architecture Search\u0026rdquo; has been accepted to Computers \u0026amp; Electrical Engineering. Congratulations to Bo and collaborators!  December 1\n  Oct   We have three papers accepted to the NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems. Congratulations to Renzhi, Peili and Jiangjiao, very well done!  October 14\n  I am proud to be recognized in the Top 2% Scientists Worldwide in a latest study from Stanford University. This is my third consecutive year to be recognized in this list.  October 13\n  Sep   Our paper on \u0026ldquo;Efficient Spectral Graph Convolutional Network Deployment on Memristive Crossbars\u0026rdquo; has been accepted to IEEE Trans. Emerg. Topics Comput. Congratulations to Bo and collaborators!  September 29\n  The 12th International Conference Series on Evolutionary Multi-Criterion Optimization ( EMO 2023) is calling for papers. The deadline is November 30 October 12, 2022. This is biannual event for all EMO researchers and this time it will be on March 2023 in Leiden, the Netherlands.  September 12 September 22\n  Our lab has been a bit slient for the last three months since I have been busy with a preparation of my project interview. Finger crossed and hope it will be secured at the end!  September 5\n  Jun  We have two papers get accepted to PPSN 2022. One is about a new angle look into the use of constant violation in constrained evolutionary multi-objective optimization and the other is about adversarial attack instance generation in natural language process. Congratulations to Shuang and Shasha!  June 6  May   We are going to organize a Exeter-Leiden Symposium on Data Driven Modeling and Optimization on June 6. Relevant information can be found here. It is running fully online and we are looking forward seeing you there.  May 28\n  We are glad to announce a fully funded opportunity for undergraduate student(s) in the UK who are interested in experiencing a research placement at Exeter. The project is outlined in here and the proposed start date is 1st July, 2022.  May 25\n  It is my great honor to be promoted as an IEEE Senior Member, which is an honor bestowed only to those who have made significant contributions to the profession.  May 2\n  We are pleased to announce that we will host a summer school on Data-Driven Artificial/Computational Intelligence: Theory and Applications this August/September. This summer school is kindly supported by IEEE Computational Intelligence Society. We had a very successful one last year and hope to continue to prosperity this time and beyond  May 1\n  Mar   We have two papers get accepted to GECCO 2022. Both of them are about adversarial attack for neural networks. Congratulations to Shasha and Phoenix!  Mar 25\n  Our paper on \u0026ldquo;Batched Data-Driven Evolutionary Multi-Objective Optimization Based on Manifold Interpolation\u0026rdquo; has been accepted to IEEE Trans. Evolutionary Computation. Congratulations to Renzhi!  Mar 20\n  It is my great honor to join the Organization Committee of EMO 2023 as a Program Chair. We are looking forward to seeing you to join the biggest party in our EMO community in Leiden, the Netherlands!  Mar 12\n  It is my great honor to participate the GREAT Talent campaign organized by the Cabinet Office. The story telling video is currently available online from here.  Mar 1\n  Feb  Our tutorial proposal on decomposition evolutionary multi-objective optimization has been accepted in PPSN 2022! Congratulations and see you guys all in Dortmund!  Feb 14  Jan  Our paper on \u0026ldquo;Preference based Multi-Objective Reinforcement Learning for Multi-Microgrid System Optimization Problem in Smart Grid\u0026rdquo; has been accepted to Memetic Computing. Congratulations to Jiangjiao!  Jan 4   2021 #  Dec  I have been invited to renew my term as an Associate Editor of IEEE Trans. Evolutionary Computation in 2022. Be humbled to serve our best journal in the evolutionary computation community.  Dec 27  Nov  Our paper \u0026ldquo;Distributed UAV Swarm Formation and Collision Avoidance Strategies Over Fixed and Switching Topologies\u0026rdquo; is accepted to IEEE Trans. Cybernetics. Congratulations to Jia!  Nov 24  Oct   I am proud to be recognized in the Top 2% Scientists Worldwide in a latest study from Stanford University.  Oct 28\n  We are pleased to announce that our collaborative bid with Dr Hao Wang at Leiden University has been funded by Europe Network Fund 2021-22. Looking forward to have many exciting collaboration therein!  Oct 20\n  We are pleased to announce that our collaborative bid with UTS in Australia has been funded by Royal Society under the International Exchange scheme. Looking forward to have many exciting collaboration therein!  Oct 7\n  Sep   Our paper \u0026ldquo;Posterior Decision-Making Based on Decomposition-Driven Knee Point Identification\u0026rdquo; is accepted to IEEE Trans. Evolutionary Computation. Congratulations to Haifeng!  Sep 15\n  It is honored to join Alan Turing Institute as a Alan Turing Fellow. I am looking forward new exciting opportunities in this UK\u0026rsquo;s national institute for data science and artificial intelligence.  Sep 3\n  Collaborating with some colleagues, we have established a new theme focused on Trustworthy AI in Institute of Data Science and Artificial Intelligence at Exeter. We are exciting to promote many follow-up activates associated with this theme in due course.  Sep 1\n  After four days intensive talks from our prestigious speakers, we are pleased to announce that our first IEEE CIS Summer School on Data-Driven Artificial/Computational Intelligence is successfully finished. Related materials will be released in due course after the permission from our speakers and IEEE.  Sep 1\n  Aug   Our paper \u0026ldquo;Neural Architecture Search for Portrait Parsing\u0026rdquo; is accepted to IEEE Trans. Neural Networks and Learning Systems. Congratulations to our fantastic collaborators!  Aug 11\n  We have four papers accepted by IEEE SMC 2021. Congratulations to Renzhi, Phoenix and Jiangjiao!  Aug 4\n  One proposal get funded by Hong Kong GRF. Congratulations to Prof. Kay Chen Tan and looking forward to working with you soon.  Aug 1\n  Jun   Our paper on \u0026ldquo;Transfer Learning Based Parallel Evolutionary Algorithm Framework for Bi-level Optimization\u0026rdquo; is accepted to IEEE Trans. Evolutionary Computation. Congratulations to Lei and collaborators!  Jun 30\n  I have been identified as 2% top scientists in the world across all disciplines from a report published by Stanford University. At the moment, I am ranked around #3200 in the AI subfield worldwide.  Jun 20\n  We are pleased to announce that we will host a summer school on Data-Driven Artificial/Computational Intelligence: Theory and Applications this August. This summer school is kindly supported by IEEE Computational Intelligence Society.  Jun 17\n  We are pleased to announce that Heng has successfully secured his PhD studentship from both CSC and Exeter. He will start his PhD journal in our lab since this autumn.  Jun 3\n  May   We are pleased to announce that Peili has successfully secured his studentship and will start his PhD journal since this autumn.  May 28\n  We are glad to announce that Maja Kaczmarek, a second year undergraduate student from the University of Manchester, has been awarded a REP studentship from SWBio DTP (only two in Exeter). We will work with Dr Yiliang Ding\u0026rsquo;s group from John Innes Centre on some exciting topics about RNA structure prediction.  May 17\n  Apr   Proud to be one of three awardees in the UK to win an Amazon Research Awards 2020. Really appreciate the generous support from Amazon to carry on our interesting work on multi-task learning! Please see press news from [ Amazon Science 1], [ Amazon Science 2], [ About Amazon Blog UK], [ Exeter News], [ Linkedin], [ 机器之心], [ 新智元], [ AI科技评论].  Apr 29\n  Our paper \u0026ldquo;A Vector Angles-based Many-objective Particle Swarm Optimization Algorithm Using Archive\u0026rdquo; is accepted to Applied Soft Computing. Congratulations to Lei!  Apr 27\n  Our paper \u0026ldquo;Vertical Distance Based Clonal Selection Mechanism for Multi-objective Immune Algorithm\u0026rdquo; is accepted to Swarm and Evolutionary Computation. Congratulations to Lingjie!  Apr 14\n  Our paper on empirical study of various control mechanisms in interactive evolutionary multi-objective optimization is accepted to IEEE CEC 2021. Congratulations to Guiyu!  Apr 6\n  Mar   It is grateful to receive an unrestricted gift from Amazon Research Awards for multi-task learning semantic feature from various injections to test Web application firewalls. Thanks for Amazon\u0026rsquo;s generous support!  Mar 24\n  After a wonderful three-year journey of founding and serving as the Chair of the IEEE Task Force 12 on Decomposition-based Techniques in Evolutionary Computation, I have stepped down as a Vice Chair since this year. It is my pleasure to witness the growing up of our community and a wider range of engagements worldwide. My colleague Prof. Bilel Derbel kindly takes up the new Chair position and will promote the activities further.  Mar 4\n  Jan  I have been invited to renew my role as an Associate Editor for the prestigious IEEE Trans. Evol. Comput., the flagship journal in artificial/computational Intelligence.  Jan 3   2020 #  Dec   Our paper on Bayesian Network Based Label Correlation Analysis For Multi-label Classifier Chain has been accepted for publication in Information Sciences. Congratulations to my collaborators! Dec 8\n  There are multiple openings in our lab for PhD students 2021 entry. The studentships are available for both UK/EU and international students. Please have a look at vacancies and feel free to contact with me for more details.\n  Our workshop on Decomposition Techniques in Evolutionary Optimization ( DTEO) has been approved by GECCO 2021! Please submit your latest work to DTEO. Dec 3\n  Our tutorial on Decomposition Multi-Objective Optimization: Current Developments and Future Opportunities has been approved by GECCO 2021! This is the 4th time we have this tutorial in GECCO. See you next year in Lille, hopefully the pandemic is over then. Dec 3\n  Nov   There are multiple openings in our lab for PhD students 2021 entry. The studentships are available for both UK/EU and international students. Please have a look at vacancies and feel free to contact with me for more details.\n  Our special issue on Advances in Decomposition-based Evolutionary Multi-objective Optimization ( ADEMO) has been approved by CEC 2021! Please submit your latest work on all decomposition-based approaches to ADEMO. Nov 19\n  All our three submissions to EMO 2021 are accepted for oral presentation. Congratulations to Jiangjiao, Joe and Xinyu! See you in Shenzhen (virtually)! Nov 13\n  Aug   Our paper on \u0026ldquo;Knee Point Identification Based on Voronoi Diagram\u0026rdquo; has been accepted to the IEEE SMC 2020 as a full paper for oral presentation. Congratulations to Haifeng! Aug 21\n  Our paper on “Performance Analysis of SDN and NFV enabled Mobile Cloud Computing” has been accepted to the IEEE GLOBECOM 2020 as a full paper for oral presentation. Congratulations to Joseph! Aug 17\n  Jul   Our paper on \u0026ldquo;Bilevel Programming for Automated Model Discovery in Cross-Project Defect Prediction\u0026rdquo; has been accepted to the ASE 2020 as a full paper (acceptance rate is 93/414 = 22.5%). We have developed a bilevel programming tool to automate the model discovery in cross-project defect prediction. More details will be released in our project page. Jul 30\n  Glad to be invited to join the Editorial Board of Complex \u0026amp; Intelligent Systems. Jul 22\n  Jun   Finally, I win the trophy for the Teaching Awards 2020 as a Outstanding Supervisor. Really appreciate the support and hard work from my team! Jun 26\n  It is so privilege and kind of unexpected to be shortlisted in the Teaching Awards 2020 as a Outstanding Supervisor. Really appreciate the nomination from my students. It is my pleasure to grow with you guys. Jun 16\n  May   Our paper “Adaptive Operator Selection Based on Dynamic Thompson Sampling for MOEA/D” has been accepted to PPSN 2020 for oral presentation. Congratulations to Lei! May 27\n  Congratulations to my students Phoenix Williams who win an competitive EPSRC DTP Studentship and Jiancheng Qian who wins the China Scholarship Council and University of Exeter PhD Scholarship. Both of them will join my lab this September. Phoenix previous worked with me under the support of EPSRC Vacation Internship last summer. May 13\n  Apr   Glad to serve as a PC member of PPSN 2020. Apr 20\n  Our paper \u0026ldquo;DeepSQLi: Deep Semantic Learning for Testing SQL Injection\u0026rdquo; has been accepted to ISSTA 2020 as a full paper (acceptance rate is 43/162 = 26.5%). We have developed a revolutionary view of taking advantage of the semantic information embedded in SQL injection cases. Thereafter, we use a state-of-the-art natural language processing tool to learn such semantic information and use that to automate the test case generation. More details will be released in our project page. Apr 15\n  Mar   Our paper \u0026ldquo;Surrogate Assisted Evolutionary Algorithm for Medium Scale Multi-Objective Optimisation Problems\u0026rdquo; has been accepted to GECCO 2020 as a full paper. We provide a new framework to scale up the surrogate-assisted evolutionary algorithm for problems with up to 50 variables. Mar 20\n  Our paper \u0026ldquo;Routing-Led Placement of VNFs in Arbitrary Networks\u0026rdquo; and \u0026ldquo;Surrogate Assisted Evolutionary Algorithm Based on Transfer Learning for Dynamic Expensive Multi-Objective Optimisation Problems\u0026rdquo; have been accepted to WCCI 2020 as full papers. Mar 20\n  Our paper \u0026ldquo;Does Preference Always Help? A Holistic Study on Preference-Based Evolutionary Multi-Objective Optimisation Using Reference Points\u0026rdquo; has been accepted to IEEE Trans. Evolutionary Computation. We have several interesting findings first of their kind reported in this study. Project page will be released soon and please stay tuned to our latest information. Mar 17\n  Feb   I am thrilled to be finally awarded the Research Excellence Awards of the CEMPS Academic Recognition Awards 2020! Feb 19\n  I am glad to be shortlisted for the Research Excellence Awards of the CEMPS Academic Recognition Awards 2020! Look forward to getting the crown. Feb 6\n  Jan   I have been invited to serve as an Associate Editor for IEEE Trans. Evolutionary Computation, the flagship journal in artificial intelligence and the best in evolutionary computation. Jan 10\n  Our paper “On the Combined Impact of Population Size and Sub-problem Selection in MOEA/D” has been accepted to the 20th European Conference on Evolutionary Computation in Combinatorial Optimisation ( EvoCOP 2020). Congratulations to my collaborators! Jan 8\n  Our paper \u0026ldquo;Reference Point Based Multi-Objective Optimization of Reservoir Operation: A Comparison of Three Algorithms\u0026rdquo; has been accepted to Water Resources Management. Congratulations to my collaborators! Jan 7\n   "}),e.add({id:14,href:"/docs/research/landscapes/",title:"Publications",section:"Docs",content:"     function toggle_visibility(id) { var e = document.getElementById(id); if(e.style.display == 'block') e.style.display = 'none'; else e.style.display = 'block'; } function toggle_visibility_extend(id_prefix, current_order, total_num) { // get all ids for different blocks var id_array = []; for(var i = 0;i  hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 40% 60%; grid-gap: 5px; background-color: transparent; padding: 5px; } .bibtexpre{ background-color:#F8F8FA; border-radius:5px; border: 2px solid #D8D8DA; margin:10px; white-space: pre-wrap; word-wrap: break-word; } .title{ color: black; } .text-box { display: flex; } .column-left { flex-basis: 17%; } .column-right { flex-basis: 83%; }   Graph-Based Fitness Landscape Analysis Leveraging the advanced tools developed in the field of network science to facilite the understanding of complex configurable systems in different domains.\n Our Work #    Publications](#publications) - [ Analysis Methods](#analysis_methods) - [ Statistical Features](#statistical_features) - [ Landscape Visualization](#landscape_visualization) - [ High-Level Topological Features](#topological_features) - [ Case Studies](#case_studies) - [ Combinatorial Optimization](#combinatorial_optimization) - [ Automated Machine Learning](#automl) - [ Software Engineering](#software_engineering) (Developer Note: the hyperlink of the contents is to be fixed later.) --  Publications #   Exploring Structural Similarity in Fitness Landscapes via Graph Data Mining: A Case Study on Number Partitioning Problems\n Mingyu Huang and Ke Li\n Proc. of the 32nd International Joint Conference on Artificial Intelligence (IJCAI'23)\n 2023 |  Conference Paper |  Abs |  PDF |  Supp |  BiB | One of the most common problem-solving heuristics is by analogy. For a given problem, a solver can be viewed as a strategic walk on its fitness landscape. Thus if a solver works for one problem instance, we expect it will also be effective for other instances whose fitness landscapes essentially share structural similarities with each other. However, due to the black-box nature of combinatorial optimization, it is far from trivial to infer such similarity in real-world scenarios. To bridge this gap, by using local optima network as a proxy of fitness landscapes, this paper proposed to leverage graph data mining techniques to conduct qualitative and quantitative analyses to explore the latent topological structural information embedded in those landscapes. In our experiments, we use the number partitioning problem as the case and our empirical results are inspiring to support the overall assumption of the existence of structural similarity between landscapes within neighboring dimensions. Besides, experiments on simulated annealing demonstrate that the performance of a meta-heuristic solver is similar on structurally similar landscapes.    Analysis Methods #   Statistical Features #   Landscape Visualization #   High-Level Topological Features #   Case Studies #   Classic BBOPs #   AutoML #  HousePrice-Train  HousePrice-Test  Stone-Train  Stone-Test    Software Engineering #   Resources #       Paper List of Landscape Analysis\n  Survey Papers  Exploratory Landscape Analysis (ELA)  Benchmarks  Algorithm Selection Problem  Instance Space Analysis  Fitness Landscape Analysis (FLA)  Problem-Specific  Landscape Visualization      Paper List of AutoML\n    Projects and Websites\n   Paper List of Landscape Analysis #    Survey Papers\n   A Comprehensive Survey on Fitness Landscape Analysis\n Erik Pitzer and Michael Affenzeller  Recent Advances in Intelligent Engineering Systems\n 2012 |  Survey Paper \n   A Survey of Techniques for Characterising Fitness Landscapes and Some Possible Ways Forward\n Katherine M. Malan and Andries Engelbrecht\n Information Sciences\n 2013 |  Survey Paper \n   A Survey of Advances in Landscape Analysis for Optimisation\n Katherine M. Malan\n Algorithms\n 2021 |  Survey Paper \n   A Survey of Landscape Analysis for Optimisation\n Feng Zou, Debao Chen, Hui Liu, Siyu Cao, Xuying Ji and Yan Zhang\n Neurocomputing\n 2022 |  Survey Paper \n  Exploratory Landscape Analysis (ELA)\n   Exploratory Landscape Analysis\n Olaf Mersmann, Bernd Bischl, Heike Trautmann, Mike Preuss, Claus Weihs and Gnter Rudolph\n Proc. of the 13th Annual Genetic and Evolutionary Computation Conference (GECCO'11)\n 2011 |  Conference Paper\n   Comprehensive Feature-Based Landscape Analysis of Continuous and Constrained Optimization Problems Using the R-Package Flacco\n Pascal Kerschke and Heike Trautmann\n Applications in Statistical Computing: From Music Data Analysis to Industrial Quality Improvement\n 2019 |  Book Chapter\n   Flaccogui: Exploratory Landscape Analysis for Everyone\n Christian Hanster, Pascal Kerschke  Proc. of the 13th Annual Genetic and Evolutionary Computation Conference (GECCO'17)\n 2017 |  Conference Paper\n   Exploratory Landscape Analysis is Strongly Sensitive to the Sampling Strategy\n Quentin Renau, Carola Doerr, Johann Dreo and Benjamin Doerr  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;XVI)\n 2020 |  Conference Paper\n   Automated Algorithm Selection on Continuous Black-Box Problems by Combining Exploratory Landscape Analysis and Machine Learning\n Pascal Kerschke and Heike Trautmann  Evolutionary Computation\n 2019 |  Journal Paper\n   Benchmarking Evolutionary Algorithms: Towards Exploratory Landscape Analysis\n Olaf Mersmann, Mike Preuss and Heike Trautmann  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;XI)\n 2010 |  Conference Paper\n  Benchmarks\n   Real-Parameter Black-Box Optimization Benchmarking 2009: Noiseless Functions Definitions\n Nikolaus Hansen, Steffen Finck, Raymond Ros and Anne Auger  INRIA\n 2009 |  Research Report\n   COCO: a platform for comparing continuous optimizers in a black-box setting\n Nikolaus Hansen, Anne Auger, Raymond Ros, Olaf Mersmann, Tea Tušar and Dimo Brockhoff  Optimization Methods and Software\n 2021 |  Journal Paper\n  Algorithm Selection\n   Automated Algorithm Selection: Survey and Perspectives\n Pascal Kerschke, Holger H. Hoos, Frank Neumann and Heike Trautmann\n Evolutionary Computation\n 2019 |  Survey Paper\n   Algorithm selection for black-box continuous optimization problems: A survey on methods and challenges\n Mario A. Muñoz, Yuan Sun, Michael Kirley and Saman K. Halgamuge\n Information Science\n 2015 |  Survey Paper\n   Cross-disciplinary perspectives on meta-learning for algorithm selection\n Kate A. Smith-Miles\n ACM Computing Survey\n 2009 |  Survey Paper\n   Algorithm Selection for Combinatorial Search Problems: A Survey\n Lars Kotthoff\n Data Mining and Constraint Programming\n 2016 |  Book Chapter\n   SATzilla: Portfolio-based Algorithm Selection for SAT\n Lin Xu, Frank Hutter, Holger H. Hoos and Kevin Leyton-Brown\n Journal of Artificial Intelligence Research  2008 |  Journal Paper\n   Automated Algorithm Selection on Continuous Black-Box Problems by Combining Exploratory Landscape Analysis and Machine Learning\n Pascal Kerschke and Heike Trautmann  Evolutionary Computation\n 2019 |  Journal Paper\n   Algorithm selection based on exploratory landscape analysis and cost-sensitive learning\n Bernd Bischl, Olaf Mersmann, Heike Trautmann and Mike Preuß\n Proc. of the 13th Annual Genetic and Evolutionary Computation Conference (GECCO'17)\n 2017 |  Conference Paper\n   Sequential Model-Based Optimization for General Algorithm Configuration\n Frank Hutter, Holger H. Hoos and Kevin Leyton-Brown\n Proc. of the 5th International Conference on Learning and Intelligent Optimization (LION'11)\n 2011 |  Conference Paper\n   ParamILS: An Automatic Algorithm Configuration Framework\n Frank Hutter, Holger H. Hoos, Kevin Leyton-Brown and Thomas Stützle\n Journal of Artificial Intelligence Research  2009 |  Journal Paper\n   ASlib: A benchmark library for algorithm selection\n Bernd Bischl, Pascal Kerschke, Lars Kotthoff, Marius Lindauer, Yuri Malitsky, Alexandre Fréchette, Holger Hoos, Frank Hutter, Kevin Leyton-Brown, Kevin Tierney and Joaquin Vanschoren\n Artificial Intelligence  2016 |  Journal Paper\n  Instance Space Analysis\n   Towards objective measures of algorithm performance across instance space\n Kate Smith-Miles, Davaatseren Baatar, Brendan Wreford and Rhyd Lewis\n Computers \u0026amp; Operations Research  2014 |  Journal Paper\n   Measuring Algorithm Footprints in Instance Space\n Kate Smith-Miles and Thomas T. Tan\n Proc. of the 2012 IEEE Congress on Evolutionary Computation (CEC'12)  2012 |  Conference Paper\n  Fitness Landscape Analysis (FLA)\nFitness Landscapes\n   Combinatorial Landscapes\n Christian M. Reidys and Peter F. Stadler\n SIAM Review  2002 |  Journal Paper\n   Fitness landscapes\n Peter F. Stadler\n Biological Evolution and Statistical Physics  2002 |  Book Chapter\n  Evolvability / Searchability\n   Fitness landscapes and evolvability\n Tom Smith, Phil Husbands, Paul Layzell and Michael O\u0026rsquo;Shea\n Evolutionary Computation  2002 |  Journal Paper | Fitness Evolvability\n   A Comprehensive View of Fitness Landscapes with Neutrality and Fitness Clouds\n Leonardo Vanneschi, Marco Tomassini, Philippe Collard, Sébastien Vérel, Yuri Pirola and Giancarlo Mauri  Proc. of the European Conference on Genetic Programming (EuroGP'07)\n 2007 |  Conference Paper | Fitness Clouds, Neutrality\n   Where are bottlenecks in NK fitness landscapes?\n Sebastien Verel, Philippe Collard and Manuel Clergue\n Proc. of the 2012 IEEE Congress on Evolutionary Computation (CEC'03)  2003 |  Conference Paper | Fitness Clouds\n   Fitness Clouds and Problem Hardness in Genetic Programming\n Leonardo Vanneschi, Manuel Clergue, Philippe Collard, Marco Tomassini and Sébastien Vérel  Proc. of the 2004 Annual Genetic and Evolutionary Computation Conference (GECCO'04)\n 2004 |  Conference Paper | Fitness Clouds\n   Fitness-Probability Cloud and a Measure of Problem Hardness for Evolutionary Algorithms\n Guanzhou Lu, Jinlong Li and Xin Yao  Proc. of the European Conference on Genetic Programming (EuroGP'11)\n 2011 |  Conference Paper | Fitness Probability Clouds\n  Variable Interdependency / Epistasis\n   Epistasis Variance: A Viewpoint on GA-Hardness\n Yuval Davidor\n Foundations of Genetic Algorithms\n 1991 |  Journal Paper | Epistasis Variance\n   A Bit-Wise Epistasis Measure for Binary Search Spaces\n Cyril Fonlupt, Denis Robilliard and Philippe Preux  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;V)\n 1998 |  Conference Paper | Bit-wise Epistasis\n   The Eﬀect of Spin-Flip Symmetry on the Performance of the Simple GA\n Bart Naudts and Jan Naudts  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;V)\n 1998 |  Conference Paper | Bit-wise Epistasis\n   Quantifying Variable Interactions in Continuous Optimization Problems\n Yuan Sun, Michael Kirley and Saman K. Halgamuge  IEEE Transactions on Evolutionary Computation (TEVC)\n 2017 |  Journal Paper\n  Information / Deception\n   Suﬃcient Conditions for Deceptive and Easy Binary Functions\n Kalyanmoy Deb and David E. Goldberg\n Annals of Mathematics and Artificial Intelligence  1994 |  Journal Paper | Deception\n  Simple Genetic Algorithm and minimal deceptive problem,” University of Albana\n David. E. Goldberg\n Genetic Algorithms and Simulated Annealing  1994 |  Book Chapter | Deception\n   Genetic Algorithms and Walsh Functions: Part II, Deception and Its Analysis\n David E. Goldberg\n Complex Systems  1989 |  Journal Paper | Deception\n   Problem difficulty analysis for particle swarm optimization: deception and modality\n Bin Xin, Jie Chen and Feng Pan\n Proc. of the first ACM/SIGEVO Summit on Genetic and Evolutionary Computation (GEC'09)\n 2009 |  Conference Paper | Deception\n  Fitness Distance Correlation\n   Fitness Distance Correlation as a Measure of Problem Diﬃculty for Genetic Algorithms\n Terry Jones and Stephanie Forrest\n Proc. of the 6th International Conference on Genetic Algorithms (ICGA'95)\n 1995 |  Conference Paper | Fitness Distance Correlation\n   Fitness Distance Correlation Analysis: An Instructive Counterexample\n Lee Altenberg\n Proc. of the 7th International Conference on Genetic Algorithms (ICGA'97)\n 1997 |  Conference Paper | Fitness Distance Correlation\n   A Study of Fitness Distance Correlation as a Difficulty Measure in Genetic Programming\n Marco Tomassini, Leonardo Vanneschi, Philippe Collard and Manuel Clergue  Evolutionary Computation\n 2005 |  Journal Paper | Fitness Distance Correlation\n  Local Optima, Basins of Attractions and Funnels\n   An Evaluation of Methods for Estimating the Number of Local Optima in Combinatorial Optimization Problems\n Leticia Hernando, Alexander Mendiburu and Jose A. Lozano  Evolutionary Computation\n 2013 |  Journal Paper | Local Optima\n   Simple Random Sampling Estimation of the Number of Local Optima\n Khulood Alyahya and Jonathan E. Rowe  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;XIV)\n 2016 |  Conference Paper | Local Optima\n   Local Optima and Weight Distribution in the Number Partitioning Problem\n Khulood Alyahya and Jonathan E. Rowe  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;XIII)\n 2014 |  Conference Paper | Local Optima\n   PSO and multi-funnel landscapes: how cooperation might limit exploration\n Andrew M. Sutton, Darrell Whitley, Monte Lunacek and Adele Howe\n Proc. of the Annual Genetic and Evolutionary Computation Conference (GECCO'06)\n 2006 |  Conference Paper | Funnel\n   The dispersion metric and the CMA evolution strategy\n Monte Lunacek and Darrell Whitley\n Proc. of the Annual Genetic and Evolutionary Computation Conference (GECCO'06)\n 2006 |  Conference Paper | Funnel\n   A Closer Look Down the Basins of Attraction\n Erik Pitzer, Michael Affenzeller and Andreas Beham\n Proc. of the 2010 UK Workshop on Computational Intelligence (UKCI'10)\n 2010 |  Conference Paper | Basin of Attraction\n   Anatomy of the Attraction Basins: Breaking with the Intuition\n Leticia Hernando, Alexander Mendiburu and Jose A. Lozano  Evolutionary Computation\n 2019 |  Journal Paper | Basin of Attraction\n  Neutrality\n   Neutrality in fitness landscapes\n Christian M. Reidys and Peter F. Stadler\n Applied Mathematics and Computation\n 2001 |  Journal Paper | Neutrality\n   When Gravity Fails: Local Search Topology\n Jeremy Frank, Peter Cheeseman and John Stutz\n Journal of Artificial Intelligence Research  1997 |  Journal Paper Neutrality\n   A quantitative study of neutrality in GP boolean landscapes\n Leonardo Vanneschi, Yuri Pirola and Philippe Collard\n Proc. of the Annual Genetic and Evolutionary Computation Conference (GECCO'06)\n 2006 |  Conference Paper | Neutrality\n  Fitness Distribution\n   Re-evaluating genetic algorithm performance under coordinate rotation of benchmark functions. A survey of some theoretical and practical aspects of genetic algorithms\n Ralf Salomon\n Biosystems\n 1996 |  Journal Paper\n   An Analysis of the Conﬁguration Space of the Maximal Constraint Satisfaction Problem\n Meriema Belaidouni and Jin-Kao Hao  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;VI)\n 2000 |  Conference Paper\n  Modality\n   Advanced fitness landscape analysis and the performance of memetic algorithms\n Peter Merz  Evolutionary Computation\n 2004 |  Journal Paper\n   How to Detect all Maxima of a Function\n J. Garnier and L. Kallel  Journal of Theoretical Biology\n 2001 |  Book Chapter\n  Ruggedness\n   Towards a General Theory of Adaptive Walks on Rugged Landscapes\n Stuart Kauffman and Simon Levin  Journal of Theoretical Biology\n 1987 |  Journal Paper | Adaptive Walks\n   Correlated and Uncorrelated Fitness Landscapes and How to Tell the Diﬀerence\n Stuart Kauffman and Simon Levin  Biological Cybernetics\n 1990 |  Journal Paper | Autocorrelation\n   Memetic Algorithms for Combinatorial Optimization Problems: Fitness Landscapes and Effective Search Strategies\n Peter Merz  2000 |  PhD Thesis | Autocorrelation\n   Smoothness, Ruggedness and Neutrality of Fitness Landscapes: from Theory to Application\n Vesselin K. Vassilev, Terence C. Fogarty and Julian F. Miller  Advances in Evolutionary Computing\n 1990 |  Book Chapter | Autocorrelation, Entropy\n  The Genetic Algorithm and the Structure of the Fitness Landscape\n B. Manderick, M. D. Weger and Piet Spiessens\n Proc. of the International Conference on Genetic Algorithms (ICGA'91)\n 1991 |  Conference Paper | Correlation Length\n   Towards a Theory of Landscapes\n Peter F. Stadler and Santa Fe Institute  Complex Systems and Binary Networks\n 2007 |  Book Chapter | Correlation Length\n   A Measure of Landscapes \n Wim Hordijk  Evolutionary Computation\n 1996 |  Journal Paper | Correlation Length\n   Adaptation on rugged landscapes generated by iterated local interactions of neighboring genes\n Mark Lipsitch\n Proc. of the International Conference on Genetic Algorithms (ICGA'91)\n 1991 |  Conference Paper | Correlation Length\n   Information Characteristics and the Structure of Landscapes\n Vesselin K. Vassilev, Terence C. Fogarty and Julian F. Miller  Evolutionary Computation\n 2000 |  Journal Paper | Entropy\n   Quantifying Ruggedness of Continuous Landscapes using Entropy\n Katherine M. Malan and Andries P. Engelbrecht\n Proc. of the 2009 IEEE Congress on Evolutionary Computation (CEC'09)  2009 |  Conference Paper | Entropy\n   Amplitude Spectra of Fitness Landscapes\n Wim Hordijk and Peter F. Stadler\n Advances in Complex Systems  1998 |  Journal Paper | Amplitude Spectra\n   Adaptation on Rugged Landscapes\n Daniel A. Levinthal\n Management Science  1997 |  Journal Paper | Amplitude Spectra\n  Information Content\n   Landscape Characterization of Numerical Optimization Problems using Biased Scattered Data\n Mario A. Muñoz, Michael Kirley and Saman K. Halgamuge\n Proc. of the 2012 IEEE Congress on Evolutionary Computation (CEC'12)  2012 |  Conference Paper | Information Content\n   Exploratory Landscape Analysis of Continuous Space Optimization Problems Using Information Content\n Mario A. Muñoz, Michael Kirley and Saman K. Halgamuge  IEEE Transactions on Evolutionary Computation (TEVC)\n 2015 |  Journal Paper | Information Content\n  Algorithm Performance and Problem Difficulty\n   Measuring Instance Difficulty for Combinatorial Optimization Problems\n Kate Smith-Miles and Leo Lopes\n Computers \u0026amp; Operations Research  2012 |  Journal Paper | Problem Difficulty\n   The Effects of Constant and Bit-Wise Neutrality on Problem Hardness, Fitness Distance Correlation and Phenotypic Mutation Rates\n Riccardo Poli and Edgar Galvan-Lopez  IEEE Transactions on Evolutionary Computation (TEVC)\n 2012 |  Journal Paper\n   Identifying Features of Fitness Landscapes and Relating Them to Problem Difficulty \n I. Moser, M. Gheorghita and A. Aleti  Evolutionary Computation\n 2017 |  Journal Paper\n   Algorithm Runtime Prediction: Methods \u0026amp; Evaluation\n Frank Hutter, Lin Xu, Holger H. Hoos and Kevin Leyton-Brown\n Artificial Intelligence  2014 |  Journal Paper | Algorithm Runtime\n   Understanding TSP Difficulty by Learning from Evolved Instances\n Kate Smith-Miles, Jano van Hemert and Xin Yu Lim  Proc. of the 2010 International Conference on Learning and Intelligent Optimization (LION'10)\n 2010 |  Conference Paper | Problem Difficulty, Eovoled Instances\n   Evolving Combinatorial Problem Instances That Are Difficult to Solve\n Jano I. van Hemert\n Evolutionary Computation\n 2006 |  Journal Paper | Problem Difficulty, Eovoled Instances\n   Feature-Based Diversity Optimization for Problem Instance Classification \n Wanru Gao, Samadhi Nallaperuma, Frank Neumann  Evolutionary Computation\n 2021 |  Journal Paper | Problem Difficulty\n   Feature-Based Diversity Optimization for Problem Instance Classification \n Wanru Gao, Samadhi Nallaperuma and Frank Neumann  Evolutionary Computation\n 2021 |  Journal Paper\n   Understanding the Empirical Hardness of NP-Complete Problems\n Kevin Leyton-Brown, Holger H. Hoos, Frank Hutter and Lin Xu\n Communications of the ACM\n 2014 |  Journal Paper | Empirical Hardness Model (EHM)\n   Fixed budget computations: a different perspective on run time analysis\n Thomas Jansen and Christine Zarges\n Proc. of the 14th Annual Genetic and Evolutionary Computation Conference (GECCO'12)\n 2012 |  Conference Paper | Algorithm Performance\n   Performance analysis of randomised search heuristics operating with a fixed budget\n Thomas Jansen and Christine Zarges\n Theoretical Computer Science  2014 |  Journal Paper | Algorithm Performance\n   Towards an analytic framework for analysing the computation time of evolutionary algorithms\n Jun He and Xin Yao\n Artificial Intelligence  2003 |  Journal Paper | Algorithm Performance\n   Empirical hardness models: Methodology and a case study on combinatorial auctions\n Kevin Leyton-Brown, Eugene Nudelman and Yoav Shoham\n Journal of the ACM\n 2009 |  Journal Paper | Empirical Hardness Model (EHM)\n   A Note on Problem Difficulty Measures in Black-Box Optimization: Classification, Realizations and Predictability\n Jun He, Colin Reeves, Carsten Witt and Xin Yao  Evolutionary Computation\n 2007 |  Journal Paper | Problem Difficulty\n   Genetic Algorithm Difficulty and the Modality of Fitness Landscapes\n Jeffrey Horn and David E. Goldberg\n Foundations of Genetic Algorithms  1995 |  Journal Paper\n   A comparison of predictive measures of problem difficulty in evolutionary algorithms\n B. Naudts and L. Kallel\n IEEE Transactions on Evolutionary Computation (TEVC)\n 2000 |  Journal Paper\n  Problem-Specific\n  On the Landscapes of Combinatorial Opitmization Problems\n Mohammad-H. Tayarani-N. and Adam Prügel-Bennett  IEEE Transactions on Evolutionary Computation (TEVC)\n 2014 |  Journal Paper  Maximum Satisfiability Problem\n   Clustering of Solutions in the Random Satisfiability Problem\n Marc. Mézard, T. Mora, and R. Zecchina\n Physical Review Letter  2005 |  Journal Paper\n   Rigorous location of phase transitions in hard optimization problems\n Dimitris Achlioptas, Assaf Naor and Yuval Peres  Nature\n 2010 |  Journal Paper\n   The random K-satisfiability problem: From an analytic solution to an efficient algorithm\n Marc Mézard and Riccardo Zecchina\n Physical Review E  2002 |  Journal Paper\n   Symmetry breaking in population-based optimization\n A. Prugel-Bennett  IEEE Transactions on Evolutionary Computation (TEVC)\n 2004 |  Journal Paper\n   Hard and easy distributions of SAT problems\n David Mitchell, Bart Selman and Hector Levesque  Proc. of the 10th National Conference on Artificial Intelligence (AAAI'92)\n 2012 |  Conference Paper\n   Experimental results on the crossover point in random 3-SAT\n James M. Crawford and Larry D. Auton\n Artificial Intelligence  1996 |  Journal Paper\n   Determining computational complexity from characteristic ‘phase transitions’\n Rémi Monasson, Riccardo Zecchina, Scott Kirkpatrick, Bart Selman and Lidror Troyansky  Nature\n 1999 |  Journal Paper\n   Statistical mechanics methods and phase transitions in optimization problems\n Olivier C. Martin, Rémi Monasson and Riccardo Zecchina\n Theoretical Computer Science  2001 |  Journal Paper\n   Global Landscape Structure and the Random MAX-SAT Phase Transition\n Gabriela Ochoa, Francisco Chicano and Marco Tomassini  Proc. of the International Conference on Parallel Problem Solving from Nature (PPSN\u0026rsquo;XVI)\n 2020 |  Conference Paper\n   Maximum Satisfiability: Anatomy of the Fitness Landscape for a Hard Combinatorial Optimization Problem\n Adam Prugel-Bennett and Mohammad-Hassan Tayarani-Najaran  IEEE Transactions on Evolutionary Computation (TEVC)\n 2012 |  Journal Paper\n   Learning the Large-Scale Structure of the MAX-SAT Landscape Using Populations\n Mohamed Qasem; Adam Prügel-Bennett  IEEE Transactions on Evolutionary Computation (TEVC)\n 2010 |  Journal Paper\n  Traveling Salesman Problem\n   An Analysis of the Fitness Landscape of Travelling Salesman Problem \n Mohammad-H. Tayarani-N. and Adam Prügel-Bennett  Evolutionary Computation\n 2016 |  Journal Paper\n   A fitness landscape analysis of the travelling thief problem\n Mohamed El Yafrani, Marcella S. R. Martins, Mehdi El Krari, Markus Wagner, Myriam R. B. S. Delgado, Belaïd Ahiod and Ricardo Lüders\n Proc. of the Genetic and Evolutionary Computation Conference (GECCO'18)\n 2018 |  Conference Paper\n   Runtime Analysis of an Ant Colony Optimization Algorithm for TSP Instances\n Yuren Zhou  IEEE Transactions on Evolutionary Computation (TEVC)\n 2009 |  Journal Paper\n   A hybrid heuristic for the traveling salesman problem\n R. Baraglia, J.I. Hidalgo and Perego  IEEE Transactions on Evolutionary Computation (TEVC)\n 2001 |  Journal Paper\n   Ant colony system: a cooperative learning approach to the traveling salesman problem\n M. Dorigo and L.M. Gambardella  IEEE Transactions on Evolutionary Computation (TEVC)\n 1997 |  Journal Paper\n   An Effective Heuristic Algorithm for the Traveling-Salesman Problem\n S. Lin and B. W. Kernighan  Operational Research\n 1973 |  Journal Paper\n   Toward minimal restriction of genetic encoding and crossovers for the two-dimensional Euclidean TSP\n Soonchul Jung and Byung-Ro Moon  IEEE Transactions on Evolutionary Computation (TEVC)\n 2022 |  Journal Paper\n   Parameterized Runtime Analyses of Evolutionary Algorithms for the Planar Euclidean Traveling Salesperson Problem\n Andrew M. Sutton, Frank Neumann and Samadhi Nallaperuma  Evolutionary Computation\n 2014 |  Journal Paper\n   Feature-Based Diversity Optimization for Problem Instance Classification \n Wanru Gao, Samadhi Nallaperuma, Frank Neumann  Evolutionary Computation\n 2021 |  Journal Paper\n  Number Paritioning Problem\n   Phase Transition and Landscape Properties of the Number Partitioning Problem\n Khulood Alyahya and Jonathan E. Rowe  Proc. of the European Conference on Evolutionary Computation in Combinatorial Optimization (EvoCOP'14)\n 2014 |  Conference Paper\n   Heuristics and exact methods for number partitioning\n João Pedro Pedroso and Mikio Kubo\n European Journal of Operational Research  2010 |  Journal Paper\n   Phase Transition in the Number Partitioning Problem\n Stephan Mertens\n Physical Review Letter  1998 |  Journal Paper\n   Phase transition and landscape statistics of the number partitioning problem\n Peter F. Stadler, Wim Hordijk, and José F. Fontanari\n Physical Review E  2003 |  Journal Paper\n  Knapsack Problem\n   Where are the hard knapsack problems?\n David Pisinger\n Computers \u0026amp; Operations Research  2005 |  Journal Paper\n   Set Theory-Based Operator Design in Evolutionary Algorithms for Solving Knapsack Problems\n Ran Wang and Zichao Zhang  IEEE Transactions on Evolutionary Computation (TEVC)\n 2021 |  Journal Paper\n   Multidimensional knapsack problem: a fitness landscape analysis\n Jorge Tavares, Francisco B. Pereira and Ernesto Costa  IEEE Transactions on Systems, Man, and Cybernetics\n 2008 |  Journal Paper\n  NK Landscapes\n   Local Optima Networks of NK Landscapes with Neutrality\n Sébastien Verel, Gabriela Ochoa and Marco Tomassini  IEEE Transactions on Evolutionary Computation (TEVC)\n 2011 |  Journal Paper\n   An Analysis of NK Landscapes: Interaction Structure, Statistical Properties, and Expected Number of Local Optima\n Jeffrey Buzas and Jeffrey Dinitz\n IEEE Transactions on Evolutionary Computation (TEVC)\n 2014 |  Journal Paper\n  Quadratic Assignment Problem\n   Fitness landscape analysis and memetic algorithms for the quadratic assignment problem\n P. Merz and B. Freisleben\n IEEE Transactions on Evolutionary Computation (TEVC)\n 2000 |  Journal Paper\n   Quadratic assignment problem: a landscape analysis\n Mohammad-H. Tayarani-N. and Adam Prügel-Bennett  Evolutionary Intelligence  2015 |  Journal Paper\n  Landscape Visualization\n  Low-Dimensional Euclidean Embedding for Visualization of Search Spaces in Combinatorial Optimization\n Krzysztof Michalak\n IEEE Transactions on Evolutionary Computation (TEVC)\n 2019 |  Journal Paper   Paper List of AutoML #  (Still under development)\nHPO Essentials\n   Meta-Learning: A Survey\n Joaquin Vanschoren\n arXiv\n 2015 |  Survey Paper\n   Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges\n Bernd Bischl, Martin Binder, Michel Lang, Tobias Pielok, Jakob Richter, Stefan Coors, Janek Thomas, Theresa Ullmann, Marc Becker, Anne-Laure Boulesteix, Difan Deng, Marius Lindauer\n WIREs Data Mining and Knowledge Discovery\n 2023 |  Survey Paper\n   On hyperparameter optimization of machine learning algorithms: Theory and practice\n Li Yang, Abdallah Shami\n Neurocomputing\n 2020 |  Survey Paper\n   Hyperparameter optimization in learning systems\n Răzvan Andonie\n Journal of Membrane Computing\n 2019 |  Survey Paper\n   Beyond Manual Tuning of Hyperparameters\n Frank Hutter, Jörg Lücke, Lars Schmidt-Thieme  KI - Künstliche Intelligenz\n 2018 |  Survey Paper\n   A review of automatic selection methods for machine learning algorithms and hyper-parameter values\n Gang Luo\n Network Modeling Analysis in Health Informatics and Bioinformatics\n 2016 |  Survey Paper | Cited by 313\n   Hyperparameter Optimization\n Matthias Feurer, Frank Hutter  Automated Machine Learning: Methods, Systems, Challenges\n 2019 |  Survey Paper\n   Random search for hyper-parameter optimization\n James Bergstra, Yoshua Bengio\n Journal of Machine Learning Research (JMLR)\n 2012 |  Journal Paper\n   Towards an Empirical Foundation for Assessing Bayesian Optimization of Hyperparameters\n Katharina Eggensperger, Matthias Feurer, Frank Hutter, James Bergstra, Jasper Snoek, Holger Hoos, Kevin Leyton-Brown\n NIPS workshop on Bayesian Optimization in Theory and Practice\n 2013 |  Conference Paper\n   Practical Bayesian Optimization of Machine Learning Algorithms\n Jasper Snoek, Hugo Larochelle, Ryan P. Adams\n Advances in Neural Information Processing Systems (NIPS'12)\n 2012 |  Conference Paper\n   Sequential Model-Based Optimization for General Alg. Configuration\n Frank Hutter, Holger H. Hoos, Kevin Leyton-Brown\n LION'11: Proc. of the International Conference on Learning and Intelligent Optimization\n 2011 |  Conference Paper\n   Algorithms for Hyper-Parameter Optimization\n James Bergstra, Rémi Bardenet, Yoshua Bengio, Balázs Kégl\n Advances in Neural Information Processing Systems (NIPS'11)\n 2011 |  Conference Paper\n   Practical Recommendations for Gradient-Based Training of Deep Architectures\n Yoshua Bengio\n Neuralnetworks: Tricks of the Trade\n 2012 |  Book Chapter\n   Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures\n James Bergstra, Daniel Yamins, David Cox\n ICML'13: Proc. of the 30th International Conference on Machine Learning\n 2013 |  Conference Paper\n   Multi-Task Bayesian Optimization\n Kevin Swersky, Jasper Snoek, Ryan P. Adams\n Advances in Neural Information Processing Systems (NIPS'13)\n 2013 |  Conference Paper\n   Gradient-based Hyperparameter Optimization through Reversible Learning\n Dougal Maclaurin, David Duvenaud, Ryan P. Adams\n ICML'15: Proc. of the 32th International Conference on Machine Learning\n 2015 |  Conference Paper\n   Efficient Benchmarking of Hyperparameter Optimizers via Surrogates\n Katharina Eggensperger, Frank Hutter, Holger H Hoos, Kevin Leyton-Brown\n AAAI'15: Proceedings of the AAAI Conference on Artificial Intelligence\n 2015 |  Conference Paper\n  AutoML\n   AutoML: A survey of the state-of-the-art\n Xin He, Kaiyong Zhao, Xiaowen Chu  Knowledge-Based Systems\n 2012 |  Survey Paper Cited by 985\n   Automated Machine Learning: State-of-The-Art and Open Challenges\n Radwa Elshawi, Mohamed Maher, Sherif Sakr  arXiv\n 2019 |  Survey Paper Cited by 159\n   Automated Machine Learning: Methods, Systems, Challenges\n Matthias Feurer, Frank Hutter  Springer\n 2019 |  Book | Cited by 1,317\n   Taking Human out of Learning Applications: A Survey on Automated Machine Learning\n Quanming Yao, Mengshuo Wang, Yuqiang Chen, Wenyuan Dai, Yu-Feng Li, Wei-Wei Tu, Qiang Yang, Yang Yu  arXiv\n 2019 |  Survey Paper | Cited by 356\n   Benchmark and Survey of Automated Machine Learning Frameworks\n Marc-Andre Zoller, Marco F. Huber  Journal of Artificial Intelligence Research\n 2021 |  Survey Paper | Cited by 251\n  Feature Importance\n   An Efficient Approach for Assessing Hyperparameter Importance\n Frank Hutter, Holger Hoos, Kevin Leyton-Brown  ICML'14: Proc. of the 31th International Conference on Machine Learning\n 2014 |  Conference Paper\n   Explaining Hyperparameter Optimization via Partial Dependence Plots\n Julia Moosbauer, Julia Herbinger, Giuseppe Casalicchio, Marius Lindauer, Bernd Bischl\n NeurIPS'21: Proc. of the 35th Conference on Neural Information Processing Systems\n 2021 |  Conference Paper\n   Hyperparameter Importance Across Datasets\n Jan N. van Rijn, Frank Hutter\n KDD \u0026lsquo;18: Proc. of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026amp; Data Mining\n 2018 |  Conference Paper\n   Efficient Parameter Importance Analysis via Ablation with Surrogates\n Andre Biedenkapp, Marius Lindauer, Katharina Eggensperger, Frank Hutter\n AAAI'17: Proc. of the Thirty-First AAAI Conference on Artificial Intelligence\n 2017 |  Conference Paper\n  Loss Landscape\n   Visualizing the Loss Landscape of Neural Nets\n Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, Tom Goldstein\n NeurIPS'18: Advances in Neural Information Processing Systems\n 2018 |  Conference Paper\n   Large Scale Structure of Neural Network Loss Landscapes\n Stanislav Fort, Stanislaw Jastrzebski\n NeurIPS'19: Advances in Neural Information Processing Systems\n 2019 |  Conference Paper\n   Taxonomizing local versus global structure in neural network loss landscapes\n Yaoqing Yang, Liam Hodgkinson, Ryan Theisen, Joe Zou, Joseph E. Gonzalez, Kannan Ramchandran, Michael W. Mahoney\n NeurIPS'21: Proc. of the 35th Conference on Neural Information Processing Systems\n 2021 |  Conference Paper\n  Related Papers\n   Efficient Global Optimization of Expensive Black-Box Functions\n Donald R. Jones, Matthias Schonlau, William J. Welch  Journal of Global Optimization\n 1998 |  Journal Paper | Cited by 8,000\n   Effect of the Sampling of a Dataset in the Hyperparameter Optimization Phase over the Efficiency of a Machine Learning Algorithm\n Noemí DeCastro-García, Ángel Luis Muñoz Castañeda, David Escudero García, Miguel V. Carriegos  Complexity\n 2019 |  Journal Paper | Cited by 43\n   Projects and Websites #    MATILDA  LON Maps  Flacco  COCO   GBFLAT #       Framwork   Installation   Documentation    GBFLAT.lon   GBFLAT.ils   GBFLAT.problems     Quick Start   Framework #  Under construction.   Installation #  Under construction.   Documentation #   GBFLAT.lon #  class GBFLAT.LON.LocalOptimalNetwork()  This is the general object we use to construct, access, analyze and manipulate LONs.\n Methods LocalOptimalNetwork.read_ils(problem_name, n_runs, n_iters, n, k, seed, path, directed=False, weighted=False, addi_attri=False) -\u0026gt; None  Create LON using recorded data from iterated local search (ILS)\n Parameters ↕   problem_name : {\u0026ldquo;NPP\u0026rdquo;, \u0026ldquo;MaxSat\u0026rdquo;, \u0026ldquo;KP\u0026rdquo;}\nThe name of the problem instance. This together with the n_runs, n_iter, n, k, seed, and path parameters will form the full path for locating the ILS logger file. n_runs : int\nNumber of runs performed during ILS. n_iter : int\nNumber of maximum iterations in each run when performing ILS. n : int\nThe dimension of the problem instance. k : float\nAdditional control parameter of the problem. seed : int\nRandom seed used when performing ILS. path : path to a directory Path to the directory where the ILS data is stored. directed : bool, default = False\nWhether to include edge directions in the created LON  if True: then the LON will be based on NetworkX.DiGraph(), where an edge will be drawn from a source node (i.e., current local optimum) to the target ndoe (i.e., an improving move to a better local optimum via perturbation followed by hill-climbing).  if False: the LON will be constructed via NetworkX.Graph().     Setting directed to True will forbid the the use of certain methods such as NetworkX.number_connected_components(), since they are not implemented for directed graphs, but could enable more node attributes that depend on the availability of edge direction (e.g., \u0026ldquo;in_degree\u0026rdquo; and \u0026ldquo;out_degree\u0026rdquo;).    weighted : bool, default = Fasle\nWhether to include edge weights in the created LON  if True: then weights representing the probabilites of visiting the transition between the two local optima will be added to edges (as edge attributes). For each edge, the associated weight is given by dividing the frequencies of visiting this transition by the total number of transitions encountered during ILS. Thereby, all weights should sum up to 1.\n if False, then no edge weights will be included in the LON (or say, all edges have equal weights).     The introducing of edge weights will also enable a richer set of node attributes, e.g., weighted degree and weighted clustering coefficient.        LocalOptimalNetwork.describe() -\u0026gt; pd.DataFrame  Obtain a pandas dataframe containing basic descriptions of the LON.\n Returns ↕  A pd.DataFrame containing the following statistis of the LON:\n n_nodes: number of nodes (i.e., local optima) in the LON. n_edges: number of edges (i.e., transitions occured between local optima) in the LON. density: network density of the LON. clustering: average clustering coefficient of the LON. degree_assor: degree assortativity of the LON. fit_assor: fitness assortativity of the LON. n_components: connected components in the LON. n_sinks: number of sink nodes in the LON. n_sources: number of source nodes in the LON.       LocalOptimalNetwork.read_lon(problem_name, n_runs, n_iters, n, k, seed, path, directed=False, weighted=False) -\u0026gt; None  Create LON using saved graph data.\n Parameters ↕   problem_name : {\u0026ldquo;NPP\u0026rdquo;, \u0026ldquo;MaxSat\u0026rdquo;, \u0026ldquo;KP\u0026rdquo;}\nThe name of the problem instance. This together with the n_runs, n_iter, n, k, seed, and path parameters will form the full path for locating the ILS logger file. n_runs : int\nNumber of runs performed during ILS. n_iter : int\nNumber of maximum iterations in each run when performing ILS. n : int\nThe dimension of the problem instance. k : float\nAdditional control parameter of the problem. seed : int\nRandom seed used when performing ILS. path : path to a directory Path to the directory where the ILS data is stored. directed : bool, default = False\nWhether to include edge directions in the created LON  if True: then the LON will be based on NetworkX.DiGraph(), where an edge will be drawn from a source node (i.e., current local optimum) to the target ndoe (i.e., an improving move to a better local optimum via perturbation followed by hill-climbing).  if False: the LON will be constructed via NetworkX.Graph().     Setting directed to True will forbid the the use of certain methods such as NetworkX.number_connected_components(), since they are not implemented for directed graphs, but could enable more node attributes that depend on the availability of edge direction (e.g., \u0026ldquo;in_degree\u0026rdquo; and \u0026ldquo;out_degree\u0026rdquo;).    weighted : bool, default = Fasle\nWhether to include edge weights in the created LON  if True: then weights representing the probabilites of visiting the transition between the two local optima will be added to edges (as edge attributes). For each edge, the associated weight is given by dividing the frequencies of visiting this transition by the total number of transitions encountered during ILS. Thereby, all weights should sum up to 1.\n if False, then no edge weights will be included in the LON (or say, all edges have equal weights).     The introducing of edge weights will also enable a richer set of node attributes, e.g., weighted degree and weighted clustering coefficient.    addi_attri : bool, default = False\nWhether to calculate additional node attributes, e.g., clustering coefficients and various centrality metrics. This could take to additional time for LON construction.        GBFLAT.ils #   GBFLAT.problems #   Quick Start #  Here we provide a simple yet comprehensive guide to illustrate the core functions of GBFLAT. Say, for example, we want to study the landscape characteristics of number partitioning problem (NPP) with 10 items.\nWe first import core classes and functions from GBFLAT along with some other necessary packages.\n The GBFLAT.Problems module implements various classic combinatorial optimization problems such as NPP, the traveling salesman problem (TSP), and the knapsack problem (KP), etc. Customized problem instances could be easily generated based on these problem classes. In GBFLAT.IteratedLocalSearch, we implement ILS method for sampling local optima from the fitness landscape (i.e., search space) of a given problem instance. It also contains various functions for performing neighbourhood exploration, local search as well as perturbation. The GBFLAT.LocalOptimalNetwork module contains the essential LON class, which stores a wide range of useful information for performing data mining, manipulation and visualization. In particular, the local optima data is available in both tabular format and graph-structured format, and this is why we always use pandas and networkx library along with GBFLAT. Finally, some other depend libraries would sometimes be necessary. For instance, when apply the node embedding method along with dimensionality reduction to draw plain visualizations of LONs, karaterclub and scikit-learn will be needed.  1import pandas as pd 2import networkx as nx 3from karaterclub import HOPE 4from sklean.manifold import TSNE 5from GBFLAT.Problems import NumberPartitioning, Knapsack 6from GBFLAT.LocalOptimalNetwork import LON 7from GBFLAT.IteratedLocalSearch import { 8 ILS, hill_climber, flip_neighbour_explorer, two_bit_flip_pertubator} After all the necessary modules have been imported, we could now get started by creating an instance of our target problem \u0026ndash; an NPP with 10 items. This could be easily done with the following script. Notice that here we also specify k=0.7, which is a control parameter that has impact on the hardness of the NPP. It is also related a phenomenon called \u0026ldquo;phase transition\u0026rdquo;. We also set seed=1, which would enable us to come back to this specific instance again at somewhere else.\n1# create a problem instance 2instance = NumberPartitioning(n = 10, k = 0.7, seed = 1) Now we are ready to perform ILS on our created problem instance! We first initialize an ILS searcher object by specifying the total number of independent ILS runs to perform, the maximum number of non-improvement iterations allowed for each run, as well as the method used for neighbour exploration, local search and perturbation. Here, since the solution vector for NPP is constitued by binary bits, a simple bit-flip-based strategy could be applied to perform neighbour exploration. We adopt hill climbing, a widely used local search strategy to find local optima. After the algorithm encounters a local optimum, a perturbation, which is a two-bits flip here, will be applied to it in the hope to escape. After properly configured the ils_searcher, we then proceed to conduct the sampling on our target instance. This process here, backended by tqdm, supports parellel processing. Just specify the n_jobs parameter according to the computational budget. In addition, a file path needs to be provided to save the ILS data. The ILS data will be saved as a .csv file, containing a rich amount of information recorded during the sampling.\n1# create an ils_searcher object 2ils_searcher = ILS(n_runs = 1000, 3 max_iters = 100, 4 local_searcher = hill_climbing, 5 neighbour_explorer = flip_neighbour_explorer, 6 perturbator = two_bit_flip_pertubator) 7 8# perform ILS sampling using multiple CPU threads 9ils_searcher.search(instance = instance, 10 path = \u0026#34;ils_data/\u0026#34;, 11 n_jobs = 8) We now create the LON for our instance. We initialize an LON object and use the LON.read_ils method to construct a LON based on ILS data. We just specifiy the information regard the problem instance and ILS process, these will serve as an unique identifier for the algorithm to locate the ILS file. We then choose whether to consider direction and edge weights in the LON.\n1# create LON object using ILS data 2lon = LON() 3lon.read_ils(problem_name = \u0026#34;NPP\u0026#34;, 4 n = 10, 5 k = 0.7, 6 seed = 1, 7 nb_runs = 1000, 8 nb_iters = 100, 9 weighted = True, 10 directed = True) Up to this step, our LON has been constructed! What makes GBFLAT an brilliant tool for graph-based landscape analysis is that the data LON is accessible in both pd.DataFrame and networkx.Graph (or networkx.DiGraph for directed LON) format. This would allow great flexibility and possibility for performing data mining, manipulation and visualization. Simply access your data via the LON.data or LON.graph property.\n1# get LON data 2graph = LON.graph # get LON data as pandas dataframe object 3data = LON.data # get LON as NetworkX graph object The resulting dataframe or graph could power numerious analysis tasks, and here we only present some simpliest examples of these.\n1# data manipulation example 2print(data.sort_values(by = \u0026#34;fitness\u0026#34;)) 3# graph manipulation example 4sol = [1, 0, 0, 1, 1, 1, 0, 0, 1, 1] 5print(nx.neighbors(graph, sol)) The LON class also has various built-in methods for analyzing LONs. For example, LON.draw_lon method could output a naive visualization of the graph. This is however, only trivial for low-dimensional problems with no more than 1,000 local optima, as when the number of nodes in the graph gets higher, the plot will quickly become messy and not able to depict useful any useful pattern. Another way for visualizing LON is to leverage node embedding and dimensionality reduction technique. This is implemented by the LON.draw_embedding method. You may obtain a informative LON visualization by changing node embedding and dimensionality reduction method according to the specific task at hand.\n1# draw LON as graph 2lon.draw_lon() 3# draw LON in 2D via node embedding and dimensionality reduction 4lon.draw_embedding(model = HOPE(), reducer = TSNE()) 5# get statistical description of LON 6lon.describe() Finally, we could save the constructed LON (along with all the node and edge attributes) to .csv file for quicker accessing next time.\n1# save LON 2lon.save_lon(name = \u0026#34;npp_n10_k0.7_seed1\u0026#34;) "}),e.add({id:15,href:"/docs/research/projects/",title:"Publications",section:"Docs",content:"Projects #  "}),e.add({id:16,href:"/docs/research/publications/",title:"Publications",section:"Docs",content:"Publications #       function toggle_visibility(id) { var e = document.getElementById(id); if(e.style.display == 'block') e.style.display = 'none'; else e.style.display = 'block'; } //Params: // id_prefix: the prefix of the id for the showing blocks // current_order: the order of the current block, start from 0 // total_num: the total number of showing blocks //Usage: // All the showing blocks should have id with the form 'id_prefix_#', e.g., // for id_prefix = 'test', total_num = 4, the id for showing blocks should be // 'test_0', 'test_1', 'test_2', 'test_3'. //Example: // `test1` // `test2` // `test3` // `test4` // ShowBibtex_ file=\"/content/xxx.txt\" id=\"test_0\" // ShowBibtex_ file=\"/content/xxx.txt\" id=\"test_1\" // ShowBibtex_ file=\"/content/xxx.txt\" id=\"test_2\" // ShowBibtex_ file=\"/content/xxx.txt\" id=\"test_3\" // (Note: add the brackets for shortcode when using, because it cannot be dircetly added here for interpreter errors) function toggle_visibility_extend(id_prefix, current_order, total_num) { // get all ids for different blocks var id_array = []; for(var i = 0;i  hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 40% 60%; grid-gap: 5px; background-color: transparent; padding: 5px; } .bibtexpre{ background-color:#F8F8FA; border-radius:5px; border: 2px solid #D8D8DA; margin:10px; white-space: pre-wrap; word-wrap: break-word; }   The copyrights of published papers are transferred to publishers. Misuse of any material posted here may result in plagiarism. + means my current/previous student or visitor. * means equal contribution       To appear #   Technical Report #    Evolutionary Multi-Objective Optimization for Virtual Network Function Placement\nJoseph Billingsley+, Ke Li, Geyong Min, Nektarios Georgalas\n CoRR abs/2106.14727 |  March 2023\n PDF |  Supp |  BiB @article{BillingsleyLMMG22, author = {Joseph Billingsley and Ke Li and Wang Miao and Geyong Min and Nektarios Georgalas}, title = {Evolutionary Multi-Objective Virtual Network Function Placement: {A} Formal Model and Effective Algorithms}, journal = {CoRR}, volume = {abs/2106.14727}, year = {2021}, url = {https://arxiv.org/abs/2106.14727}, eprinttype = {arXiv}, eprint = {2106.14727}, timestamp = {Thu, 19 May 2022 17:23:34 +0200}, biburl = {https://dblp.org/rec/journals/corr/abs-2106-14727.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Multidimensional Resource Fragmentation-Aware Virtual Network Embedding in MEC Systems Interconnected by Metro Optical Networks\nYingying Guan+, Qingyang Song, Weijing Qi, Ke Li, Lei Guo, Abbas Jamalipour\n CoRR abs/2303.15878 |  February 2023\n PDF |  BiB @article{GuanSQLGJ23, author = {Yingying Guan and Qingyang Song and Weijing Qi and Ke Li and Lei Guo and Abbas Jamalipour}, title = {Multidimensional Resource Fragmentation-Aware Virtual Network Embedding in MEC Systems Interconnected by Metro Optical Networks}, journal = {CoRR}, volume = {abs/2301.12148}, year = {2023}, url = {https://arxiv.org/abs/2301.12148}, eprinttype = {arXiv}, eprint = {2301.12148} } \n  Quality Indicators for Preference-based Evolutionary Multi-objective Optimization Using a Reference Point: A Review and Analysis\nRyoji Tanabe, Ke Li\n CoRR abs/2301.12148 |  January 2023\n PDF |  Supp |  BiB @article{TanabeL23, author = {Ryoji Tanabe and Ke Li}, title = {Quality Indicators for Preference-based Evolutionary Multi-objective Optimization Using a Reference Point: A Review and Analysis}, journal = {CoRR}, volume = {abs/2301.12148}, year = {2023}, url = {https://arxiv.org/abs/2301.12148}, eprinttype = {arXiv}, eprint = {2301.12148} } \n  A Data-Driven Evolutionary Transfer Optimization for Expensive Problems in Dynamic Environments\nKe Li*, Renzhi Chen+*, Xin Yao\n CoRR abs/2211.02879 |  November 2022\n PDF |  Supp |  BiB @article{LiCY22, author = {Ke Li and Renzhi Chen and Xin Yao}, title = {A Data-Driven Evolutionary Transfer Optimization for Expensive Problems in Dynamic Environments}, journal = {CoRR}, volume = {abs/2211.0287}, year = {2022}, url = {https://arxiv.org/abs/2211.02879}, eprinttype = {arXiv}, eprint = {2211.02879} } \n  DaNuoYi: Evolutionary Multi-Task Injection Testing on Web Application Firewalls\nKe Li, Heng Yang+, Willem Visser\n CoRR abs/2206.05743 |  June 2022\n PDF |  BiB @article{LiYV22, author = {Ke Li and Heng Yang and Willem Visser}, title = {DaNuoYi: Evolutionary Multi-Task Injection Testing on Web Application Firewalls}, journal = {CoRR}, volume = {abs/2206.05743}, year = {2022}, url = {https://arxiv.org/abs/2206.05743}, doi = {10.48550/arXiv.2206.05743}, eprinttype = {arXiv}, eprint = {2206.05743} } \n  Art-Attack: Black-Box Adversarial Attack via Evolutionary Art\nPhoenix Williams+, Ke Li\n CoRR abs/2203.04405 |  March 2022\n PDF |  BiB @article{WilliamsL22, author = {Phoenix Neale Williams and Ke Li}, title = {Art-Attack: Black-Box Adversarial Attack via Evolutionary Art}, journal = {CoRR}, volume = {abs/2203.04405}, year = {2022}, url = {https://doi.org/10.48550/arXiv.2203.04405}, doi = {10.48550/arXiv.2203.04405}, eprinttype = {arXiv}, eprint = {2203.04405}, timestamp = {Thu, 19 May 2022 17:23:34 +0200}, biburl = {https://dblp.org/rec/journals/corr/abs-2203-04405.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Automated Few-Shot Time Series Forecasting based on Bi-level Programming\nJiangjiao Xu+, Ke Li\n CoRR abs/2203.03328 |  March 2022\n PDF |  BiB @article{XuL22, author = {Jiangjiao Xu and Ke Li}, title = {Automated Few-Shot Time Series Forecasting based on Bi-level Programming}, journal = {CoRR}, volume = {abs/2203.03328}, year = {2022}, url = {https://doi.org/10.48550/arXiv.2203.03328}, doi = {10.48550/arXiv.2203.03328}, eprinttype = {arXiv}, eprint = {2203.03328}, timestamp = {Wed, 16 Mar 2022 16:39:52 +0100}, biburl = {https://dblp.org/rec/journals/corr/abs-2203-03328.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  LONViZ: Unboxing the Black-Box of Configurable Software Systems from a Complex Networks Perspective\nKe Li, Peili Mao+, Tao Chen\n CoRR abs/2201.01429 |  January 2022\n PDF |  BiB @article{LiMC22, author = {Ke Li and Peili Mao and Tao Chen}, title = {LONViZ: Unboxing the black-box of Configurable Software Systems from a Complex Networks Perspective}, journal = {CoRR}, volume = {abs/2201.01429}, year = {2022}, url = {https://arxiv.org/abs/2201.01429}, eprinttype = {arXiv}, eprint = {2201.01429}, timestamp = {Mon, 10 Jan 2022 13:39:01 +0100}, biburl = {https://dblp.org/rec/journals/corr/abs-2201-01429.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Decomposition Multi-Objective Evolutionary Optimization: From State-of-the-Art to Future Opportunities\nKe Li\n CoRR abs/2108.09588 |  August 2021\n PDF |  BiB @article{Li22, author = {Ke Li}, title = {Decomposition Multi-Objective Evolutionary Optimization: From State-of-the-Art to Future Opportunities}, journal = {CoRR}, volume = {abs/2108.09588}, year = {2021}, url = {https://arxiv.org/abs/2108.09588}, eprinttype = {arXiv}, eprint = {2108.09588}, timestamp = {Fri, 27 Aug 2021 15:02:29 +0200}, biburl = {https://dblp.org/rec/journals/corr/abs-2108-09588.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n    In press #    Multioutput Surrogate Assisted Evolutionary Algorithm for Expensive Multi-Modal Optimization Problems\nRenzhi Chen+, Ke Li\nProc. of the 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC'23)\n Abs |  PDF |  BiB\n  Empirical Studies of Resampling Strategies in Noisy Evolutionary Multi-Objective Optimization\nShasha Zhou+, Ke Li\nProc. of the 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC'23)\n Abs |  PDF |  BiB\n  Preference-Based Multi-Objective Optimization with Gaussian Process\nTian Huang+, Ke Li\nProc. of the 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC'23)\n Abs |  PDF |  BiB\n  Boosting Text Augmentation via Hybrid Instance Filtering Framework\nHeng Yang+, Ke Li\nPorc. of the 61st Annual Meeting of the Association for Computational Linguistics (ACL'23)\n Abs |  PDF |  BiB\n  Exploring Structural Similarity in Fitness Landscapes via Graph Data Mining: A Case Study on Number Partitioning Problems\nMingyu Huang+, Ke Li\nPorc. of the 32nd International Joint Conference on Artificial Intelligence (IJCAI'23)\n Abs |  PDF |  Supp |  BiB |  ≈15% One of the most common problem-solving heuristics is by analogy. For a given problem, a solver can be viewed as a strategic walk on its fitness landscape. Thus if a solver works for one problem instance, we expect it will also be effective for other instances whose fitness landscapes essentially share structural similarities with each other. However, due to the black-box nature of combinatorial optimization, it is far from trivial to infer such similarity in real-world scenarios. To bridge this gap, by using local optima network as a proxy of fitness landscapes, this paper proposed to leverage graph data mining techniques to conduct qualitative and quantitative analyses to explore the latent topological structural information embedded in those landscapes. In our experiments, we use the number partitioning problem as the case and our empirical results are inspiring to support the overall assumption of the existence of structural similarity between landscapes within neighboring dimensions. Besides, experiments on simulated annealing demonstrate that the performance of a meta-heuristic solver is similar on structurally similar landscapes. \n  A Surrogate Assisted Evolutionary Strategy for Image Approximation by Density-Ratio Estimation\nPhoenix Williams+, Ke Li\nProc. of 2023 IEEE Congress on Evolutionary Computation (CEC'23)\n Abs |  PDF |  BiB\n  A Multi-Population Evolutionary Algorithm Using New Cooperative Mechanism for Solving Multi-Objective Problems with Multi-Constraint\nJuan Zou, Ruiqing Sun, Yuan Liu, Yaru Hu, Shengxiang Yang, Jinhua Zheng, Ke Li\nIEEE Trans. Evolutionary Computation (TEVC)\n  10.1109/TEVC.2023.3260306\n Abs |  PDF |  BiB In science and engineering, multi-objective optimization problems usually contain multiple complex constraints, which poses a significant challenge in obtaining the optimal solution. This paper aims to solve the challenges brought by multiple complex constraints. First, this paper analyzes the relationship between single constrained Pareto Front (SCPF) and their common Pareto Front sub-constrained Pareto Front (SubCPF). Next, we discussed the SCPF, SubCPF, and Unconstrainti Pareto Front (UPF)’s help to solve constraining Pareto Front (CPF). Then further discusses what kind of cooperation should be used between multiple populations constrained multi-objective optimization algorithm (CMOEA) to better deal with multi-constrained multi-objective optimization problems (mCMOPs). At the same time, based on the discussion in this paper, we propose a new multi-population CMOEA called MCCMO, which uses a new cooperation mechanism. MCCMO uses C+2 (C is the number of constraints) populations to find the UPF, SCPF, and SubCPF at an appropriate time. Furthermore, MCCMO uses the newly proposed Activation Dormancy Detection (ADD) to accelerate the optimization process and uses the proposed Combine Occasion Detection (COD) to find the appropriate time to find the SubCPF. The performance on 32 mCMOPs and real-world mCMOPs shows that our algorithm can obtain competitive solutions on MOPs with multiple constraints. \n  Black-Box Sparse Adversarial Attack via Multi-Objective Optimisation\nPhoenix Williams+, Ke Li\nProc. of 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR'23)\n Abs |  PDF |  BiB |  ≈25% Deep neural networks (DNNs) are susceptible to adversarial images, raising concerns about their reliability in safety-critical tasks. Sparse adversarial attacks, which limit the number of modified pixels, have shown to be highly effective in causing DNNs to misclassify. However, existing methods often struggle to simultaneously minimize the number of modified pixels and the size of the modifications, often requiring a large number of queries and assuming unrestricted access to the targeted DNN. In contrast, other methods that limit the number of modified pixels often permit unbounded modifications, making them easily detectable. To address these limitations, we propose a novel multi-objective sparse attack algorithm that efficiently minimizes the number of modified pixels and their size during the attack process. Our algorithm draws inspiration from evolutionary computation and incorporates a mechanism for prioritizing objectives that aligns with an attacker's goals. Our approach outperforms existing sparse attacks on CIFAR-10 and ImageNet trained DNN classifiers while requiring only a small query budget, attaining competitive attack success rates while perturbing fewer pixels. Overall, our proposed attack algorithm provides a solution to the limitations of current sparse attack methods by jointly minimizing the number of modified pixels and their size. Our results demonstrate the effectiveness of our approach in restricted scenarios, highlighting its potential to enhance DNN security. \n  Evolutionary Bi-level Optimization via Multi-objective Transformation Based Lower Level Search\nLei Chen, Hai-Lin Liu, Ke Li, Kay Chen Tan\nIEEE Trans. Evolutionary Computation (TEVC)\n  10.1109/TEVC.2023.3236455\n Abs |  PDF |  BiB Nested evolutionary algorithms (EAs) have been regarded as very promising tools for bi-level optimization. Due to the nested structure, the upper level population evaluation requires a set of complete lower level optimizations, thereby reducing the efficiency and practicability of EA methods. In this paper, a multi-objective transformation-based evolutionary algorithm (MOTEA) is proposed to perform multiple lower level optimizations in a parallel and collaborative manner. Specifically, the corresponding multiple lower level optimizations for each generation of the upper level population evaluation are transformed into locating a set of Pareto optimal solutions of a constructed multi-objective optimization problem. By utilizing the built-in implicit parallelism of evolutionary multi-objective optimization, multiple lower level problems can thus be optimized in parallel. Within one multi-objective search population, the collaboration among the parallel lower level optimization can be realized by exploiting and utilizing the implicit similarities among them for better efficiency. The effectiveness and efficiency of the proposed MOTEA are verified by comparing it with four state-of-the-art evolutionary bi-level optimization algorithms on two sets of popular bi-level optimization benchmark test problems and three application problems. \n  Interactive Evolutionary Multi-Objective Optimization via Learning-to-Rank\nKe Li, Guiyu Lai+, Xin Yao\nIEEE Trans. Evolutionary Computation (TEVC)\n  10.1109/TEVC.2023.3234269\n Abs |  PDF |  Supp |  BiB In practical multi-criterion decision-making, it is cumbersome if a decision maker (DM) is asked to choose among a set of trade-off alternatives covering the whole Pareto-optimal front. This is a paradox in conventional evolutionary multi-objective optimization (EMO) that always aim to achieve a well balance between convergence and diversity. In essence, the ultimate goal of multi-objective optimization is to help a decision maker (DM) identify solution(s) of interest (SOI) achieving satisfactory trade-offs among multiple conflicting criteria. Bearing this in mind, this paper develops a framework for designing preference-based EMO algorithms to find SOI in an interactive manner. Its core idea is to involve human in the loop of EMO. After every several iterations, the DM is invited to elicit her feedback with regard to a couple of incumbent candidates. By collecting such information, her preference is progressively learned by a learning-to-rank neural network and then applied to guide the baseline EMO algorithm. Note that this framework is so general that any existing EMO algorithm can be applied in a plug-in manner. Experiments on 48 benchmark test problems with up to 10 objectives and a real-world multi-objective robot control problem fully demonstrate the effectiveness of our proposed algorithms for finding SOI.  @article{LiLY22, author = {Ke Li and Guiyu Lai and Xin Yao}, title = {Interactive Evolutionary Multi-Objective Optimization via Learning-to-Rank}, journal = {CoRR}, volume = {abs/2204.02604}, year = {2022}, url = {https://doi.org/10.48550/arXiv.2204.02604}, doi = {10.48550/arXiv.2204.02604}, eprinttype = {arXiv}, eprint = {2204.02604}, timestamp = {Tue, 12 Apr 2022 18:42:14 +0200}, biburl = {https://dblp.org/rec/journals/corr/abs-2204-02604.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   2023 #   Journal #    Efficient Spectral Graph Convolutional Network Deployment on Memristive Crossbars\nBo Lyu+, Maher Hamdi, Yin Yang, Yuting Cao, Zheng Yan, Ke Li, Shiping Wen, Tingwen Huang\nIEEE Trans. Emerging Topics in Computational Intelligence (TETCI), 7(2): 415-425, 2023\n  10.1109/TETCI.2022.3210998\n Abs |  PDF |  BiB Multi-objective optimization problems are ubiquitous in real-world science, engineering and design optimization problems. It is not uncommon that the objective functions are as a black box, the evaluation of which usually involve time-consuming and/or costly physical experiments. Data-driven evolutionary optimization can be used to search for a set of non-dominated trade-off solutions, where the expensive objective functions are approximated as a surrogate model. In this paper, we propose a framework for implementing batched data-driven evolutionary multi-objective optimization. It is so general that any off-the-shelf evolutionary multi-objective optimization algorithms can be applied in a plug-in manner. There are two unique components: 1) based on the Karush-Kuhn-Tucker conditions, a manifold interpolation approach that explores more diversified solutions with a convergence guarantee along the manifold of the approximated Pareto-optimal set; and 2) a batch recommendation approach that reduces the computational time of the data-driven evolutionary optimization process by evaluating multiple samples at a time in parallel. Comparing against 7 state-of-the-art surrogate-assisted evolutionary algorithms, experiments on 168 benchmark test problem instances with various properties and a real-world application on hyper-parameter optimization fully demonstrate the effectiveness and superiority of our proposed framework, which is featured with a faster convergence and a stronger resilience to various PF shapes.  @article{LyuHYCYLSH22, author = {Bo Lyu and Maher Hamdi and Yin Yang and Yuting Cao and Zheng Yan and Ke Li and Shiping Wen and Tingwen Huang}, journal = {IEEE Trans. Emerg. Top. Comput. Intell.}, title = {Efficient Spectral Graph Convolutional Network Deployment on Memristive Crossbars}, year = {2022}, pages = {1-11}, note = {accepted for publication}, doi = {10.1109/TETCI.2022.3210998} } \n  Neural Architecture Search for Portrait Parsing\nBo Lyu+, Yin Yang, Shiping Wen, Tingwen Huang, Ke Li\nIEEE Trans. Neural Networks and Learning Systems (TNNLS), 34(3): 1112-1121, 2023\n  10.1109/TNNLS.2021.3104872\n Abs |  PDF |  BiB This work proposes a neural architecture search (NAS) method for portrait parsing, which is a novel up-level task based on portrait segmentation and face labeling. Recently, NAS has become an effective method in terms of automatic machine learning. However, remarkable achievements have been made only in image classification and natural language processing (NLP) areas. Meanwhile, state-of-the-art portrait segmentation and face labeling approaches are all manually designed, but few models reach a tradeoff between efficiency and performance. Thus, we are extremely interested in improving existing NAS methods for dense-per-pixel prediction tasks on portrait datasets. To achieve that, we resort to a cell-based encoder-decoder architecture with an elaborate design of connectivity structure and searching space. As a result, we achieve state-of-the-art performance on three portrait tasks, including 96.8% MIOU on EG1800 (portrait segmentation), 91.2% overall F1-score on HELEN (face labeling), and 95.1% overall F1-score on CelebAMask-HQ (portrait parsing) with only 2.29M model parameters. That is, our approach compares favorably with all previous works on portrait datasets. More crucially, we empirically prove that even a fundamental encoder-decoder architecture may reach an outstanding result on the aforementioned tasks with the help of the innovative approach of NAS. To the best of our knowledge, our work is also the first to report the success of applying NAS on these portrait tasks.  @ARTICLE{LyuYWHL22, author = {Lyu, Bo and Yang, Yin and Wen, Shiping and Huang, Tingwen and Li, Ke}, journal = {IEEE Transactions on Neural Networks and Learning Systems}, title = {Neural Architecture Search for Portrait Parsing}, year = {2021}, doi = {10.1109/TNNLS.2021.3104872} }\n  Batched Data-Driven Evolutionary Multi-Objective Optimization Based on Manifold Interpolation\nKe Li*, Renzhi Chen+*\nIEEE Trans. Evolutionary Computation (TEVC), 27(1): 126-140, 2023\n  10.1109/TEVC.2022.3162993\n Abs |  PDF |  Supp |  BiB Multi-objective optimization problems are ubiquitous in real-world science, engineering and design optimization problems. It is not uncommon that the objective functions are as a black box, the evaluation of which usually involve time-consuming and/or costly physical experiments. Data-driven evolutionary optimization can be used to search for a set of non-dominated trade-off solutions, where the expensive objective functions are approximated as a surrogate model. In this paper, we propose a framework for implementing batched data-driven evolutionary multi-objective optimization. It is so general that any off-the-shelf evolutionary multi-objective optimization algorithms can be applied in a plug-in manner. There are two unique components: 1) based on the Karush-Kuhn-Tucker conditions, a manifold interpolation approach that explores more diversified solutions with a convergence guarantee along the manifold of the approximated Pareto-optimal set; and 2) a batch recommendation approach that reduces the computational time of the data-driven evolutionary optimization process by evaluating multiple samples at a time in parallel. Comparing against 7 state-of-the-art surrogate-assisted evolutionary algorithms, experiments on 168 benchmark test problem instances with various properties and a real-world application on hyper-parameter optimization fully demonstrate the effectiveness and superiority of our proposed framework, which is featured with a faster convergence and a stronger resilience to various PF shapes.  @ARTICLE{LiC22, author = {Li, Ke and Chen, Renzhi}, journal = {IEEE Transactions on Evolutionary Computation}, title = {Batched Data-Driven Evolutionary Multi-Objective Optimization Based on Manifold Interpolation}, year = {2022}, doi = {10.1109/TEVC.2022.3162993}}\n  MTLP-JR: Multi-Task Learning-Based Prediction for Joint Ranking in Neural Architecture Search\nBo Lyu+, Longfei Lu, Maher Hamdi, Shiping Wen, Yin Yang, Ke Li\nComputers \u0026amp; Electrical Engineering, 105: 108474, 2023\n  10.1016/j.compeleceng.2022.108474\n Abs |  PDF |  BiB\n   Conference #    Data-Driven Evolutionary Multi-Objective Optimization Based on Multiple-Gradient Descent for Disconnected Pareto Fronts\nRenzhi Chen+, Ke Li\nProc. of the 12th International Conference on Evolutionary Multi-Criterion Optimization (EMO'23), Springer, p. 56-70, March, 2023\n  10.1007/978-3-031-27250-9_5\n Abs |  PDF |  Supp |  BiB Data-driven evolutionary multi-objective optimization (EMO) has been recognized as an effective approach for multi-objective optimization problems with expensive objective functions. The current research is mainly developed for problems with a 'regular' triangle-like Pareto-optimal front (PF), whereas the performance can significantly deteriorate when the PF consists of disconnected segments. Furthermore, the offspring reproduction in the current data-driven EMO does not fully leverage the latent information of the surrogate model. Bearing these considerations in mind, this paper proposes a data-driven EMO algorithm based on multiple-gradient descent. By leveraging the regularity information provided by the up-to-date surrogate model, it is able to progressively probe a set of well distributed candidate solutions with a convergence guarantee. In addition, its infill criterion recommends a batch of promising candidate solutions to conduct expensive objective function evaluations. Experiments on 33 benchmark test problem instances with disconnected PFs fully demonstrate the effectiveness of our proposed method against four selected peer algorithms. \n  Sparse Adversarial Attack via Bi-Objective Optimization\nPhoenix Williams+, Ke Li, Geyong Min\nProc. of the 12th International Conference on Evolutionary Multi-Criterion Optimization (EMO'23), Springer, p. 118-133, March, 2023\n  10.1007/978-3-031-27250-9_9\n Abs |  PDF |  BiB\n  2022 #   Journal #    Posterior Decision-Making Based on Decomposition-Driven Knee Point Identification\nKe Li, Haifeng Nie+, Huiru Gao+, Xin Yao\nIEEE Trans. Evolutionary Computation (TEVC), 26(6): 1409-1423, 2022\n  10.1109/TEVC.2021.3116121\n Abs |  PDF |  Code |  Supp |  BiB Knee points, characterized as a small improvement on one objective can lead to a significant degradation on at least one of the other objectives, are attractive to decision makers in multi-criterion decision-making. This paper presents a simple and effective knee point identification method to help decision makers identify solution(s) of interest from a given set of trade-off solutions thus facilitating posterior decision-making. Our basic idea is to sequentially validate whether a solution is a knee point or not by comparing its localized trade-off utility with others within its neighborhood characterized from a decomposition perspective. In particular, a solution is a knee point if and only if it has the best localized trade-off utility among its neighbors. We implement a GPU version that carries out the knee point identification in a parallel manner. This GPU version reduces the worst-case complexity from quadratic to linear. The performance of our proposed method is compared with five state-of-the-art knee point identification methods on 134 test problem instances and two real-world engineering design problems. Empirical results demonstrate its outstanding performance especially on problems with many local knee points. We further validate the usefulness of our proposed method for guiding evolutionary multi-objective optimization algorithms to search for knee points on the fly during the evolutionary process.  @article{LiNGY22, author = {Li, Ke and Nie, Haifeng and Gao, Huiru and Yao, Xin}, journal = {IEEE Transactions on Evolutionary Computation}, title = {Posterior Decision-Making Based on Decomposition-Driven Knee Point Identification}, year = {2021}, publisher = {IEEE} }\n  Distributed UAV Swarm Formation and Collision Avoidance Strategies Over Fixed and Switching Topologies\nJia Wu, Chunbo Luo, Yang Luo, Ke Li\nIEEE Trans. Cybernetics (TCYB), 52(10): 10969-10979, 2022\n  10.1109/TCYB.2021.3132587\n Abs |  PDF |  BiB This article proposes a controlling framework for multiple unmanned aerial vehicles (UAVs) to integrate the modes of formation flight and swarm deployment over fixed and switching topologies. Formation strategies enable UAVs to enjoy key collective benefits including reduced energy consumption, but the shape of the formation and each UAV's freedom are significantly restrained. Swarm strategies are thus proposed to maximize each UAV's freedom following simple yet powerful rules. This article investigates the integration and switch between these two strategies, considering the deployment environment factors, such as poor network conditions and unknown and often highly mobile obstacles. We design a distributed formation controller to guide multiple UAVs in orderless states to swiftly reach an intended formation. Inspired by starling birds and similar biological creatures, a distributed collision avoidance controller is proposed to avoid unknown and mobile obstacles. We further illustrated the stability of the controllers over both fixed and switching topologies. The experimental results confirm the effectiveness of the framework.  @article{WuLLL22, author = {Jia Wu and Chunbo Luo and Yang Luo and Ke Li}, title = {Distributed {UAV} Swarm Formation and Collision Avoidance Strategies Over Fixed and Switching Topologies}, journal = {{IEEE} Trans. Cybern.}, volume = {52}, number = {10}, pages = {10969--10979}, year = {2022}, url = {https://doi.org/10.1109/TCYB.2021.3132587}, doi = {10.1109/TCYB.2021.3132587}, timestamp = {Thu, 13 Oct 2022 16:02:10 +0200}, biburl = {https://dblp.org/rec/journals/tcyb/WuLLL22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Transfer Learning Based Parallel Evolutionary Algorithm Framework for Bi-level Optimization\nLei Chen, Hai-Lin Liu, Kay Chen Tan, Ke Li\nIEEE Trans. Evolutionary Computation (TEVC), 26(1): 115-129, 2022\n  10.1109/TEVC.2021.3095313\n Abs |  PDF |  Code |  BiB Evolutionary algorithms (EAs) have been recognized as a promising approach for bilevel optimization. However, the population-based characteristic of EAs largely influences their efficiency and effectiveness due to the nested structure of the two levels of optimization problems. In this article, we propose a transfer learning-based parallel EA (TLEA) framework for bilevel optimization. In this framework, the task of optimizing a set of lower level problems parameterized by upper level variables is conducted in a parallel manner. In the meanwhile, a transfer learning strategy is developed to improve the effectiveness of each lower level search (LLS) process. In practice, we implement two versions of the TLEA: the first version uses the covariance matrix adaptation evolutionary strategy and the second version uses the differential evolution as the evolutionary operator in lower level optimization. The experimental studies on two sets of widely used bilevel optimization benchmark problems are conducted, and the performance of the two TLEA implementations is compared to that of four well-established evolutionary bilevel optimization algorithms to verify the effectiveness and efficiency of the proposed algorithm framework.  @article{ChenLTL22, author = {Lei Chen and Hai{-}Lin Liu and Kay Chen Tan and Ke Li}, title = {Transfer Learning-Based Parallel Evolutionary Algorithm Framework for Bilevel Optimization}, journal = {{IEEE} Trans. Evol. Comput.}, volume = {26}, number = {1}, pages = {115--129}, year = {2022}, url = {https://doi.org/10.1109/TEVC.2021.3095313}, doi = {10.1109/TEVC.2021.3095313}, timestamp = {Wed, 23 Feb 2022 11:16:38 +0100}, biburl = {https://dblp.org/rec/journals/tec/ChenLTL22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Preference based Multi-Objective Reinforcement Learning for Multi-Microgrid System Optimization Problem in Smart Grid\nJiangjiao Xu+, Ke Li, Mohammad Abusara\nMemetic Computing (MC), 14(2): 225-235, 2022\n  10.1007/s12293-022-00357-w\n Abs |  PDF |  BiB Grid-connected microgrids comprising renewable energy, energy storage systems and local load, play a vital role in decreasing the energy consumption of fossil diesel and greenhouse gas emissions. A distribution power network connecting several microgrids can promote more potent and reliable operations to enhance the security and privacy of the power system. However, the operation control for a multi-microgrid system is a big challenge. To design a multi-microgrid power system, an intelligent multi-microgrids energy management method is proposed based on the preference-based multi-objective reinforcement learning (PMORL) techniques. The power system model can be divided into three layers: the consumer layer, the independent system operator layer, and the power grid layer. Each layer intends to maximize its benefit. The PMORL is proposed to lead to a Pareto optimal set for each object to achieve these objectives. A non-dominated solution is decided to execute a balanced plan not to favor any particular participant. The preference-based results show that the proposed method can effectively learn different preferences. The simulation outcomes confirm the performance of the PMORL and verify the viability of the proposed method.  @article{XuLA22, author = {Jiangjiao Xu and Ke Li and Mohammad Abusara}, title = {Preference based multi-objective reinforcement learning for multi-microgrid system optimization problem in smart grid}, journal = {Memetic Comput.}, volume = {14}, number = {2}, pages = {225--235}, year = {2022}, url = {https://doi.org/10.1007/s12293-022-00357-w}, doi = {10.1007/s12293-022-00357-w}, timestamp = {Thu, 02 Jun 2022 16:43:14 +0200}, biburl = {https://dblp.org/rec/journals/memetic/XuLA22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n   Conference #    Surrogate-Assisted Evolutionary Multi-Objective Optimization for Hardware Design Space Exploration\nRenzhi Chen+, Ke Li\nProc. of the NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems, 2022\n Abs |  PDF |  BiB Hardware design space exploration (DSE) aims to find a suitable micro-architecture for the dedicated hardware accelerators. It is a computationally expensive black-box optimization problem with more than one conflicting performance indicator. Surrogate-assisted evolutionary algorithm is a promising framework for expensive multi-objective optimization problems given its surrogate modeling for handling expensive objective functions and population-based characteristics that search for a set of trade-off solutions simultaneously. However, most, if not all, existing studies mainly focus ‘regular’ Pareto-optimal fronts (PFs), whereas the PF is typically irregular in hardware DSE. In the meanwhile, the gradient information of the differentiable surrogate model(s) is beneficial to navigate a more effective exploration of the search space, but it is yet fully exploited. This paper proposes a surrogate-assisted evolutionary multi-objective optimization based on multiple-gradient descent (MGD) for hardware DSE. Empirical results on both synthetic problems with irregular PFs and real-world hardware DSE cases fully demonstrate the effectiveness and outstanding performance of our proposed algorithm. \n  Are All Training Data Useful? A Empirical Revisit of Subset Selection in Bayesian Optimization\nPeili Mao+, Ke Li\nProc. of the NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems, 2022\n Abs |  PDF |  BiB Bayesian optimization (BO) has been widely recognized as a powerful approach for black-box optimization problems with expensive objective function(s). Gaussian process (GP), which has been widely used for surrogate modeling in BO, is notorious for its cubic computational complexity grows with the increase of the amount of evaluated samples. This can lead to a significantly increased computational time for BO due to its sequential decision-making nature. This paper revisit the simple and effective subset selection methods to pick up a small group of representative data from the entire dataset to carry out the training and inference of GP in the context of BO. Empirical studies demonstrate that subset selection methods not only promote the performance of the vanilla BO but also significantly reduce the computational time for up to 98%. \n  Imputation and Forecasting for Multi-Output Gaussian Process in Smart Grid\nJiangjiao Xu+, Ke Li\nProc. of the NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems, 2022\n Abs |  PDF |  BiB\n  Do We Really Need to Use Constraint Violation in Constrained Evolutionary Multi-Objective Optimization?\nShuang Li+, Ke Li, Wei Li\nProc. of the 17the International Conference on Parallel Problem Solving from Nature (PPSN'22), Springer, p. 124-137, September, 2022\n  10.1007/978-3-031-14721-0_9\n PDF |  BiB\n  @inproceedings{LiLL22, author = {Shuang Li and Ke Li and Wei Li}, title = {Do We Really Need to Use Constraint Violation in Constrained Evolutionary Multi-objective Optimization?}, booktitle = {PPSN'22: Proc. of 17th International Conference on Parallel Problem Solving from Nature}, series = {Lecture Notes in Computer Science}, volume = {13399}, pages = {124--137}, publisher = {Springer}, year = {2022}, url = {https://doi.org/10.1007/978-3-031-14721-0\\_9}, doi = {10.1007/978-3-031-14721-0\\_9}, timestamp = {Thu, 25 Aug 2022 08:35:33 +0200}, biburl = {https://dblp.org/rec/conf/ppsn/LiLL22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }  \n Attention-Based Genetic Algorithm for Adversarial Attack in Natural Language Processing\nShasha Zhou+, Ke Li, Geyong Min\nProc. of the 17the International Conference on Parallel Problem Solving from Nature (PPSN'22), Springer, p. 341-355, September, 2022\n  10.1007/978-3-031-14714-2_24\n PDF |  BiB  @inproceedings{ZhouLM22_b, author = {Shasha Zhou and Ke Li and Geyong Min}, title = {Attention-Based Genetic Algorithm for Adversarial Attack in Natural Language Processing}, booktitle = {PPSN'22: Proc. of 17th International Conference on Parallel Problem Solving from Nature}, series = {Lecture Notes in Computer Science}, volume = {13398}, pages = {341--355}, publisher = {Springer}, year = {2022}, url = {https://doi.org/10.1007/978-3-031-14714-2\\_24}, doi = {10.1007/978-3-031-14714-2\\_24}, timestamp = {Thu, 25 Aug 2022 08:35:33 +0200}, biburl = {https://dblp.org/rec/conf/ppsn/ZhouLM22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }  \n Black-Box Adversarial Attack via Overlapped Shapes\nPhoenix Williams+, Ke Li, Geyong Min\nProc. of the 24th Annual Conference on Genetic and Evolutionary Computation (GECCO’22), ACM, p. 467-468, July, 2022\n  10.1145/3520304.3528934\n PDF |  BiB  @inproceedings{Williams0M22, author = {Phoenix Neale Williams and Ke Li and Geyong Min}, title = {Black-box adversarial attack via overlapped shapes}, booktitle = {{GECCO}'22: Proc. of Genetic and Evolutionary Computation Conference, Companion Volume}, pages = {467--468}, publisher = {{ACM}}, year = {2022}, url = {https://doi.org/10.1145/3520304.3528934}, doi = {10.1145/3520304.3528934}, timestamp = {Mon, 25 Jul 2022 17:04:27 +0200}, biburl = {https://dblp.org/rec/conf/gecco/Williams0M22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }  \n Adversarial Attack Example Generation via Genetic Algorithm: A Preliminary Result\nShasha Zhou+, Ke Li, Geyong Min\nProc. of the 24th Annual Conference on Genetic and Evolutionary Computation (GECCO’22), ACM, p. 469-470, July, 2022\n  10.1145/3520304.3528981\n PDF |  BiB  @inproceedings{ZhouLM22, author = {Shasha Zhou and Ke Li and Geyong Min}, title = {Adversarial example generation via genetic algorithm: a preliminary result}, booktitle = {{GECCO}'22: Proc. of Genetic and Evolutionary Computation Conference, Companion Volume}, pages = {469--470}, publisher = {{ACM}}, year = {2022}, url = {https://doi.org/10.1145/3520304.3528981}, doi = {10.1145/3520304.3528981}, timestamp = {Mon, 25 Jul 2022 17:04:27 +0200}, biburl = {https://dblp.org/rec/conf/gecco/Zhou0M22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }  \n Decomposition Multi-Objective Optimisation: Current Developments and Future Opportunities\nKe Li, Qingfu Zhang\nProc. of the 24th Annual Conference on Genetic and Evolutionary Computation (GECCO’22), ACM, p. 469-470, July, 2022\n  10.1145/3520304.3533629\n PDF |  BiB  @inproceedings{LiZ22, author = {Ke Li and Qingfu Zhang}, title = {Decomposition multi-objective optimisation: current developments and future opportunities}, booktitle = {{GECCO}'22: Proc. of the Genetic and Evolutionary Computation Conference, Companion Volume}, pages = {1554--1571}, publisher = {{ACM}}, year = {2022}, url = {https://doi.org/10.1145/3520304.3533629}, doi = {10.1145/3520304.3533629}, timestamp = {Mon, 25 Jul 2022 17:04:27 +0200}, biburl = {https://dblp.org/rec/conf/gecco/LiZ22.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }  \n 2021 #   Journal #    Vertical Distance-based Clonal Selection Mechanism for the Multiobjective Immune Algorithm\nLingjie Li+, Qiuzhen Lin, Ke Li, Zhong Ming\nSwarm and Evolutionary Computation (SWEVO), 106: 107299, 2021\n  10.1016/j.swevo.2021.100886\n PDF |  BiB @article{LiLLM21, author = {Lingjie Li and Qiuzhen Lin and Ke Li and Zhong Ming}, title = {Vertical distance-based clonal selection mechanism for the multiobjective immune algorithm}, journal = {Swarm Evol. Comput.}, volume = {63}, pages = {100886}, year = {2021}, url = {https://doi.org/10.1016/j.swevo.2021.100886}, doi = {10.1016/j.swevo.2021.100886}, timestamp = {Tue, 15 Jun 2021 09:16:57 +0200}, biburl = {https://dblp.org/rec/journals/swevo/LiLLM21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  A Vector Angles-Based Many-Objective Particle Swarm Optimization Algorithm Using Archive\nLei Yang+, Xin Hu, Ke Li\nApplied Soft Computing (ASOC), 63: 100886, 2021\n  10.1016/j.asoc.2021.107299\n PDF |  BiB @article{YangHL21, author = {Lei Yang and Xin Hu and Ke Li}, title = {A vector angles-based many-objective particle swarm optimization algorithm using archive}, journal = {Appl. Soft Comput.}, volume = {106}, pages = {107299}, year = {2021}, url = {https://doi.org/10.1016/j.asoc.2021.107299}, doi = {10.1016/j.asoc.2021.107299}, timestamp = {Fri, 03 Dec 2021 13:16:58 +0100}, biburl = {https://dblp.org/rec/journals/asc/YangHL21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Bayesian Network Based Label Correlation Analysis For Multi-label Classifier Chain\nRan Wang, Suhe Ye, Ke Li, Sam Kwong\nInformation Sciences (INS), 554: 256\u0026ndash;275, 2021\n  10.1016/j.ins.2020.12.010\n PDF |  BiB @article{WangYLK21, author = {Ran Wang and Suhe Ye and Ke Li and Sam Kwong}, title = {Bayesian network based label correlation analysis for multi-label classifier chain}, journal = {Inf. Sci.}, volume = {554}, pages = {256--275}, year = {2021}, url = {https://doi.org/10.1016/j.ins.2020.12.010}, doi = {10.1016/j.ins.2020.12.010}, timestamp = {Fri, 09 Apr 2021 18:25:48 +0200}, biburl = {https://dblp.org/rec/journals/isci/WangYLK21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   Conference #    Knee Point Identification Based on the Geometric Characteristic\nRenzhi Chen+, Ke Li\nProc. of the 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC'21), IEEE, p. 764\u0026ndash;769, October, 2021\n  10.1109/SMC52423.2021.9658848\n PDF |  BiB @inproceedings{Chen021, author = {Renzhi Chen and Ke Li}, title = {Knee Point Identification Based on the Geometric Characteristic}, booktitle = {2021 {IEEE} International Conference on Systems, Man, and Cybernetics, {SMC} 2021, Melbourne, Australia, October 17-20, 2021}, pages = {764--769}, publisher = {{IEEE}}, year = {2021}, url = {https://doi.org/10.1109/SMC52423.2021.9658848}, doi = {10.1109/SMC52423.2021.9658848}, timestamp = {Tue, 11 Jan 2022 10:00:39 +0100}, biburl = {https://dblp.org/rec/conf/smc/Chen021.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Large-Scale Evolutionary Optimization via Multi-Task Random Grouping\nPhoenix Williams+, Ke Li\nProc. of the 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC'21), IEEE, p. 778\u0026ndash;783, October, 2021\n  10.1109/SMC52423.2021.9659276\n PDF |  BiB @inproceedings{WilliamsLM21, author = {Phoenix Neale Williams and Ke Li and Geyong Min}, title = {Large-Scale Evolutionary Optimization via Multi-Task Random Grouping}, booktitle = {2021 {IEEE} International Conference on Systems, Man, and Cybernetics, {SMC} 2021, Melbourne, Australia, October 17-20, 2021}, pages = {778--783}, publisher = {{IEEE}}, year = {2021}, url = {https://doi.org/10.1109/SMC52423.2021.9659276}, doi = {10.1109/SMC52423.2021.9659276}, timestamp = {Thu, 19 May 2022 17:23:34 +0200}, biburl = {https://dblp.org/rec/conf/smc/WilliamsLM21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Transfer Bayesian Optimization for Expensive Black-Box Optimization in Dynamic Environment\nRenzhi Chen+, Ke Li\nProc. of the 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC'21), IEEE, p. 1374\u0026ndash;1379, October, 2021\n  10.1109/SMC52423.2021.9659200\n PDF |  BiB @inproceedings{ChenL21, author = {Renzhi Chen and Ke Li}, title = {Transfer Bayesian Optimization for Expensive Black-Box Optimization in Dynamic Environment}, booktitle = {2021 {IEEE} International Conference on Systems, Man, and Cybernetics, {SMC} 2021, Melbourne, Australia, October 17-20, 2021}, pages = {1374--1379}, publisher = {{IEEE}}, year = {2021}, url = {https://doi.org/10.1109/SMC52423.2021.9659200}, doi = {10.1109/SMC52423.2021.9659200}, timestamp = {Tue, 11 Jan 2022 10:00:39 +0100}, biburl = {https://dblp.org/rec/conf/smc/Chen021a.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  ADMM-based OPF Problem Against Cyber Attacks in Smart Grid\nJiangjiao Xu+, Ke Li, Mohammad Abusara, Yan Zhang\nProc. of the 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC'21), IEEE, p. 1418\u0026ndash;1423, October, 2021\n  10.1109/SMC52423.2021.9658699\n PDF |  BiB @inproceedings{XuLA021, author = {Jiangjiao Xu and Ke Li and Mohammad Abusara and Yan Zhang}, title = {ADMM-based {OPF} Problem Against Cyber Attacks in Smart Grid}, booktitle = {2021 {IEEE} International Conference on Systems, Man, and Cybernetics, {SMC} 2021, Melbourne, Australia, October 17-20, 2021}, pages = {1418--1423}, publisher = {{IEEE}}, year = {2021}, url = {https://doi.org/10.1109/SMC52423.2021.9658699}, doi = {10.1109/SMC52423.2021.9658699}, timestamp = {Thu, 10 Mar 2022 11:05:49 +0100}, biburl = {https://dblp.org/rec/conf/smc/XuLA021.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  An Enhancement of the NSGA-II Reliability Optimization using Extended Kalman Filter Based Initialization\nSavas Yuec+, Ke Li\nProc. of the 2021 20th UK Workshop on Computational Intelligence (UKCI'21), Springer, p. 121\u0026ndash;128, September, 2021\n  10.1007/978-3-030-87094-2_11\n PDF |  BiB @inproceedings{YuceL21, author = {Savas Yuce and Ke Li}, title = {An Enhancement of the {NSGA-II} Reliability Optimization Using Extended Kalman Filter Based Initialization}, booktitle = {Advances in Computational Intelligence Systems - Contributions Presented at the 20th {UK} Workshop on Computational Intelligence, September 8-10, 2021, Aberystwyth, Wales, {UK}}, series = {Advances in Intelligent Systems and Computing}, volume = {1409}, pages = {121--128}, publisher = {Springer}, year = {2021}, url = {https://doi.org/10.1007/978-3-030-87094-2\\_11}, doi = {10.1007/978-3-030-87094-2\\_11}, timestamp = {Thu, 16 Dec 2021 15:07:27 +0100}, biburl = {https://dblp.org/rec/conf/ukci/YuceL21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Empirical Studies on the Role of the Decision Maker in Interactive Evolutionary Multi-Objective Optimization\nGuiyu Lai+, Minhui Liao, Ke Li\nProc. of the 2021 IEEE Congress on Evolutionary Computation (CEC'21), IEEE, p. 1\u0026ndash;8, June, 2021\n  10.1109/CEC45853.2021.9504980\n PDF |  BiB @inproceedings{LaiL021, author = {Guiyu Lai and Minhui Liao and Ke Li}, title = {Empirical Studies on the Role of the Decision Maker in Interactive Evolutionary Multi-Objective Optimization}, booktitle = {{IEEE} Congress on Evolutionary Computation, {CEC} 2021, Krak{\\'{o}}w, Poland, June 28 - July 1, 2021}, pages = {185--192}, publisher = {{IEEE}}, year = {2021}, url = {https://doi.org/10.1109/CEC45853.2021.9504980}, doi = {10.1109/CEC45853.2021.9504980}, timestamp = {Thu, 12 Aug 2021 16:39:59 +0200}, biburl = {https://dblp.org/rec/conf/cec/LaiL021.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Empirical Study of Correlations in the Fitness Landscapes of Combinatorial Optimization Problems\nLongfei Zhang+, Ke Li, Shi Gu\nProc. of the 23th Annual Conference on Genetic and Evolutionary Computation (GECCO’21), ACM, p. 247\u0026ndash;248, July, 2021.\n  10.1145/3449726.3459528\n PDF |  BiB @inproceedings{ZhangLG21, author = {Longfei Zhang and Ke Li and Shi Gu}, title = {Empirical study of correlations in the fitness landscapes of combinatorial optimization problems}, booktitle = {{GECCO} '21: Genetic and Evolutionary Computation Conference, Companion Volume, Lille, France, July 10-14, 2021}, pages = {247--248}, publisher = {{ACM}}, year = {2021}, url = {https://doi.org/10.1145/3449726.3459528}, doi = {10.1145/3449726.3459528}, timestamp = {Thu, 19 May 2022 17:23:34 +0200}, biburl = {https://dblp.org/rec/conf/gecco/ZhangLG21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  An Improved Two-Archive Evolutionary Algorithm for Constrained Multi-Objective Optimization\nXinyu Shan+, Ke Li\nProc. of the 11th International Conference on Evolutionary Multi-Criterion Optimization (EMO'21), Springer LNCS, volume 12654, p. 235\u0026ndash;247, March, 2021\n  10.1007/978-3-030-72062-9_19\n PDF |  BiB @inproceedings{ShanL21, author = {Xinyu Shan and Ke Li}, title = {An Improved Two-Archive Evolutionary Algorithm for Constrained Multi-objective Optimization}, booktitle = {Evolutionary Multi-Criterion Optimization - 11th International Conference, {EMO} 2021, Shenzhen, China, March 28-31, 2021, Proceedings}, series = {Lecture Notes in Computer Science}, volume = {12654}, pages = {235--247}, publisher = {Springer}, year = {2021}, url = {https://doi.org/10.1007/978-3-030-72062-9\\_19}, doi = {10.1007/978-3-030-72062-9\\_19}, timestamp = {Thu, 08 Apr 2021 15:51:58 +0200}, biburl = {https://dblp.org/rec/conf/emo/ShanL21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Multi-Objective Reinforcement Learning based Multi-Microgrid System Optimisation Problem\nJiangjiao Xu+, Ke Li, Mohammad Abusara\nProc. of the 11th International Conference on Evolutionary Multi-Criterion Optimization (EMO'21), Springer LNCS, volume 12654, p. 684\u0026ndash;696, March, 2021\n  10.1007/978-3-030-72062-9_54\n PDF |  BiB @inproceedings{XuLA21, author = {Jiangjiao Xu and Ke Li and Mohammad Abusara}, title = {Multi-objective Reinforcement Learning Based Multi-microgrid System Optimisation Problem}, booktitle = {Evolutionary Multi-Criterion Optimization - 11th International Conference, {EMO} 2021, Shenzhen, China, March 28-31, 2021, Proceedings}, series = {Lecture Notes in Computer Science}, volume = {12654}, pages = {684--696}, publisher = {Springer}, year = {2021}, url = {https://doi.org/10.1007/978-3-030-72062-9\\_54}, doi = {10.1007/978-3-030-72062-9\\_54}, timestamp = {Mon, 12 Apr 2021 14:42:37 +0200}, biburl = {https://dblp.org/rec/conf/emo/XuLA21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Parallel Algorithms for Multiobjective Virtual Network Function Placement Problem\nJoseph Billingsley+, Ke Li, Wang Miao, Geyong Min, Nektarios Georgalas\nProc. of the 11th International Conference on Evolutionary Multi-Criterion Optimization (EMO'21), Springer LNCS, volume 12654, p. 708\u0026ndash;720, March, 2021\n  10.1007/978-3-030-72062-9_56\n PDF |  BiB @inproceedings{BillingsleyLMMG21, author = {Joseph Billingsley and Ke Li and Wang Miao and Geyong Min and Nektarios Georgalas}, title = {Parallel Algorithms for the Multiobjective Virtual Network Function Placement Problem}, booktitle = {Evolutionary Multi-Criterion Optimization - 11th International Conference, {EMO} 2021, Shenzhen, China, March 28-31, 2021, Proceedings}, series = {Lecture Notes in Computer Science}, volume = {12654}, pages = {708--720}, publisher = {Springer}, year = {2021},EDITOR url = {https://doi.org/10.1007/978-3-030-72062-9\\_56}, doi = {10.1007/978-3-030-72062-9\\_56}, timestamp = {Thu, 19 May 2022 17:23:34 +0200}, biburl = {https://dblp.org/rec/conf/emo/BillingsleyLMMG21.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   2020 #   Journal #    Does Preference Always Help? A Holistic Study on Preference-Based Evolutionary Multi-Objective Optimisation Using Reference Points\nKe Li, Minhui Liao+, Kalyanmoy Deb, Geyong Min, Xin Yao\nIEEE Trans. Evolutionary Computation (TEVC), 24(6): 1078\u0026ndash;1096, 2020.\n  10.1109/TEVC.2020.2987559\n PDF |  Code |  BiB @article{LiLDMY20, author = {Ke Li and Minhui Liao and Kalyanmoy Deb and Geyong Min and Xin Yao}, title = {Does Preference Always Help? {A} Holistic Study on Preference-Based Evolutionary Multiobjective Optimization Using Reference Points}, journal = {{IEEE} Trans. Evol. Comput.}, volume = {24}, number = {6}, pages = {1078--1096}, year = {2020}, url = {https://doi.org/10.1109/TEVC.2020.2987559}, doi = {10.1109/TEVC.2020.2987559}, timestamp = {Thu, 17 Dec 2020 18:29:03 +0100}, biburl = {https://dblp.org/rec/journals/tec/LiLDMY20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Reference Point Based Multi-Objective Optimization of Reservoir Operation: a Comparison of Three Algorithms\nRong Tang, Ke Li, Wei Ding, Yuntao Wang, Huicheng Zhou, Guangtao Fu\nWater Resources Management, 34: 1005\u0026ndash;1020, 2020.\n  10.1007/s11269-020-02485-9\n PDF |  BiB @article{tangLDWZF20, title = {Reference point based multi-objective optimization of reservoir operation: a comparison of three algorithms}, author = {Tang, Rong and Li, Ke and Ding, Wei and Wang, Yuntao and Zhou, Huicheng and Fu, Guangtao}, journal = {Water Resources Management}, volume = {34}, number = {3}, pages = {1005--1020}, year = {2020}, publisher = {Springer} }\n  Evolutionary Many-Objective Optimization Based on Adversarial Decomposition\nMengyuan Wu+, Ke Li, Sam Kwong, Qingfu Zhang\nIEEE Trans. Cybernetics (TCYB), 50(2): 753\u0026ndash;764, 2020.\n  10.1109/TCYB.2018.2872803\n PDF |  Supp |  Code |  BiB @article{WuLKZ20, author = {Mengyuan Wu and Ke Li and Sam Kwong and Qingfu Zhang}, title = {Evolutionary Many-Objective Optimization Based on Adversarial Decomposition}, journal = {{IEEE} Trans. Cybern.}, volume = {50}, number = {2}, pages = {753--764}, year = {2020}, url = {https://doi.org/10.1109/TCYB.2018.2872803}, doi = {10.1109/TCYB.2018.2872803}, timestamp = {Sat, 30 May 2020 19:51:36 +0200}, biburl = {https://dblp.org/rec/journals/tcyb/WuLKZ20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   Conference #    Performance Analysis of SDN and NFV enabled Mobile Cloud Computing\nJoseph Billingsley+, Ke Li, Wang Miao, Geyong Min, Nektarios Georgalas\nProc. of the 2020 IEEE Global Communications Conference (GLOBECOM'20), IEEE Press: p. 1\u0026ndash;6, December, 2020\n  10.1109/GLOBECOM42002.2020.9322530\n PDF |  BiB @inproceedings{BillingsleyMLMG20, author = {Joseph Billingsley and Wang Miao and Ke Li and Geyong Min and Nektarios Georgalas}, title = {Performance Analysis of {SDN} and {NFV} enabled Mobile Cloud Computing}, booktitle = {{IEEE} Global Communications Conference, {GLOBECOM} 2020, Virtual Event, Taiwan, December 7-11, 2020}, pages = {1--6}, publisher = {{IEEE}}, year = {2020}, url = {https://doi.org/10.1109/GLOBECOM42002.2020.9322530}, doi = {10.1109/GLOBECOM42002.2020.9322530}, timestamp = {Thu, 19 May 2022 17:23:34 +0200}, biburl = {https://dblp.org/rec/conf/globecom/BillingsleyMLMG20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Knee Point Identification Based on Voronoi Diagram\nHaifeng Nie+, Huiru Gao+, Ke Li\nProc. of the 2020 IEEE Conference on Systems, Man and Cybernetics (SMC'20), IEEE Press: p. 1\u0026ndash;6, December, 2020\n  10.1109/SMC42975.2020.9283262\n PDF |  BiB @inproceedings{NieGL20, author = {Haifeng Nie and Huiru Gao and Ke Li}, title = {Knee Point Identification Based on Voronoi Diagram}, booktitle = {2020 {IEEE} International Conference on Systems, Man, and Cybernetics, {SMC} 2020, Toronto, ON, Canada, October 11-14, 2020}, pages = {1081--1086}, publisher = {{IEEE}}, year = {2020}, url = {https://doi.org/10.1109/SMC42975.2020.9283262}, doi = {10.1109/SMC42975.2020.9283262}, timestamp = {Fri, 08 Jan 2021 11:20:37 +0100}, biburl = {https://dblp.org/rec/conf/smc/NieGL20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  BiLO-CPDP: Bi-Level Programming for Automated Model Discovery in Cross-Project Defect Prediction\nKe Li, Zilin Xiang+, Tao Chen, Kay Chen Tan\nProc. of the 35th IEEE/ACM International Conference on Automated Software Engineering (ASE'20), IEEE Press: September, 2020\n  10.1145/3324884.3416617\n PDF |  Code |  BiB @inproceedings{LiXCT20, author = {Ke Li and Zilin Xiang and Tao Chen and Kay Chen Tan}, title = {BiLO-CPDP: Bi-Level Programming for Automated Model Discovery in Cross-Project Defect Prediction}, booktitle = {35th {IEEE/ACM} International Conference on Automated Software Engineering, {ASE} 2020, Melbourne, Australia, September 21-25, 2020}, pages = {573--584}, publisher = {{IEEE}}, year = {2020}, url = {https://doi.org/10.1145/3324884.3416617}, doi = {10.1145/3324884.3416617}, timestamp = {Fri, 12 Feb 2021 13:04:43 +0100}, biburl = {https://dblp.org/rec/conf/kbse/LiXCT20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Adaptive Operator Selection Based on Dynamic Thompson Sampling for MOEA/D\nLei Sun+, Ke Li\nProc. of the 16th International Conference on Parallel Problem Solving from Nature (PPSN XVI), Springer LNCS, volume 12270, p. 271\u0026ndash;284, Septermber, 2020.\n  10.1007/978-3-030-58115-2_19\n PDF |  BiB @inproceedings{SunL20, author = {Lei Sun and Ke Li}, title = {Adaptive Operator Selection Based on Dynamic Thompson Sampling for {MOEA/D}}, booktitle = {Parallel Problem Solving from Nature - {PPSN} {XVI} - 16th International Conference, {PPSN} 2020, Leiden, The Netherlands, September 5-9, 2020, Proceedings, Part {II}}, series = {Lecture Notes in Computer Science}, volume = {12270}, pages = {271--284}, publisher = {Springer}, year = {2020}, url = {https://doi.org/10.1007/978-3-030-58115-2\\_19}, doi = {10.1007/978-3-030-58115-2\\_19}, timestamp = {Sat, 19 Sep 2020 13:19:33 +0200}, biburl = {https://dblp.org/rec/conf/ppsn/SunL20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Surrogate Assisted Evolutionary Algorithm for Medium Scale Multi-Objective Optimisation Problems\nXiaoran Ruan+, Ke Li, Bilel Derbel, Arnaud Liefooghe\nProc. of the 22th Annual Conference on Genetic and Evolutionary Computation (GECCO’20), ACM Press: p. 560\u0026ndash;568, July, 2020.\n  10.1145/3377930.3390191\n PDF |  BiB @inproceedings{RuanLDL20, author = {Xiaoran Ruan and Ke Li and Bilel Derbel and Arnaud Liefooghe}, title = {Surrogate assisted evolutionary algorithm for medium scale multi-objective optimisation problems}, booktitle = {{GECCO} '20: Genetic and Evolutionary Computation Conference, Canc{\\'{u}}n Mexico, July 8-12, 2020}, pages = {560--568}, publisher = {{ACM}}, year = {2020}, url = {https://doi.org/10.1145/3377930.3390191}, doi = {10.1145/3377930.3390191}, timestamp = {Thu, 19 May 2022 17:23:34 +0200}, biburl = {https://dblp.org/rec/conf/gecco/RuanLDL20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Routing-Led Placement of VNFs in Arbitrary Networks\nJoseph Billingsley+, Ke Li, Wang Miao, Geyong Min, Nektarios Georgalas\nProc. of the 2020 World Congress on Computational Intelligence (WCCI'20), IEEE Press: p. 1\u0026ndash;8, July, 2020.\n  10.1109/CEC48606.2020.9185531\n PDF |  BiB @article{BillingsleyLMMG20, author = {Joseph Billingsley and Ke Li and Wang Miao and Geyong Min and Nektarios Georgalas}, title = {Routing-Led Placement of VNFs in Arbitrary Networks}, journal = {CoRR}, volume = {abs/2001.11565}, year = {2020}, url = {https://arxiv.org/abs/2001.11565}, eprinttype = {arXiv}, eprint = {2001.11565}, timestamp = {Mon, 03 Feb 2020 11:21:05 +0100}, biburl = {https://dblp.org/rec/journals/corr/abs-2001-11565.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Surrogate Assisted Evolutionary Algorithm Based on Transfer Learning for Dynamic Expensive Multi-Objective Optimisation Problems\nXuezhou Fan, Ke Li, Kay Chen Tan\nProc. of the 2020 World Congress on Computational Intelligence (WCCI'20), IEEE Press: p. 1\u0026ndash;8, July, 2020.\n  10.1109/CEC48606.2020.9185522\n PDF |  BiB @inproceedings{FanLT20, author = {Xuezhou Fan and Ke Li and Kay Chen Tan}, title = {Surrogate Assisted Evolutionary Algorithm Based on Transfer Learning for Dynamic Expensive Multi-Objective Optimisation Problems}, booktitle = {{IEEE} Congress on Evolutionary Computation, {CEC} 2020, Glasgow, United Kingdom, July 19-24, 2020}, pages = {1--8}, publisher = {{IEEE}}, year = {2020}, url = {https://doi.org/10.1109/CEC48606.2020.9185522}, doi = {10.1109/CEC48606.2020.9185522}, timestamp = {Fri, 11 Sep 2020 15:04:41 +0200}, biburl = {https://dblp.org/rec/conf/cec/FanLT20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  DeepSQLi: Deep Semantic Learning for Testing SQL Injection\nMuyang Liu+, Ke Li, Tao Chen\nProc. of the ACM SIGSOFT 2020 International Symposium on Software Testing and Analysis (ISSTA'20), ACM Press: p. 286\u0026ndash;297, July, 2020.\n  10.1145/3395363.3397375\n PDF |  Code |  BiB @inproceedings{LiuLC20, author = {Muyang Liu and Ke Li and Tao Chen}, title = {DeepSQLi: deep semantic learning for testing {SQL} injection}, booktitle = {{ISSTA} '20: 29th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis, Virtual Event, USA, July 18-22, 2020}, pages = {286--297}, publisher = {{ACM}}, year = {2020}, url = {https://doi.org/10.1145/3395363.3397375}, doi = {10.1145/3395363.3397375}, timestamp = {Wed, 15 Jul 2020 16:06:56 +0200}, biburl = {https://dblp.org/rec/conf/issta/Liu0020.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Understanding the Automated Parameter Optimization on Transfer Learning for Cross-Project Defect Prediction: An Empirical Study\nKe Li*, Zilin Xiang+*, Tao Chen*, Shuo Wang, Kay Chen Tan\nProc. of the 42nd International Conference on Software Engineering (ICSE'20), ACM Press: p. 566\u0026ndash;577, June, 2020.\n  10.1145/3377811.3380360\n PDF |  Code |  BiB @inproceedings{LiX0WT20, author = {Ke Li and Zilin Xiang and Tao Chen and Shuo Wang and Kay Chen Tan}, title = {Understanding the automated parameter optimization on transfer learning for cross-project defect prediction: an empirical study}, booktitle = {{ICSE} '20: 42nd International Conference on Software Engineering, Seoul, South Korea, 27 June - 19 July, 2020}, pages = {566--577}, publisher = {{ACM}}, year = {2020}, url = {https://doi.org/10.1145/3377811.3380360}, doi = {10.1145/3377811.3380360}, timestamp = {Tue, 12 Jan 2021 14:44:41 +0100}, biburl = {https://dblp.org/rec/conf/icse/LiX0WT20.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  On the Combined Impact of Population Size and Sub-problem Selection in MOEA/D\nGeoffrey Pruvost, Bilel Derbel, Arnaud Liefooghe, Ke Li, Qingfu Zhang\nProc. of the 20th European Conference on Evolutionary Computation in Combinatorial Optimisation (EvoCOP'20), Springer LNCS, volume 12102, p. 131–147, April, 2020.\n  10.1007/978-3-030-43680-3_9\n PDF |  BiB @inproceedings{PruvostDLL020, author = {Geoffrey Pruvost and Bilel Derbel and Arnaud Liefooghe and Ke Li and Qingfu Zhang}, title = {On the Combined Impact of Population Size and Sub-problem Selection in {MOEA/D}}, booktitle = {Evolutionary Computation in Combinatorial Optimization - 20th European Conference, EvoCOP 2020, Held as Part of EvoStar 2020, Seville, Spain, April 15-17, 2020, Proceedings}, series = {Lecture Notes in Computer Science}, volume = {12102}, pages = {131--147}, publisher = {Springer}, year = {2020}, url = {https://doi.org/10.1007/978-3-030-43680-3\\_9}, doi = {10.1007/978-3-030-43680-3\\_9}, timestamp = {Sun, 25 Jul 2021 11:53:08 +0200}, biburl = {https://dblp.org/rec/conf/evoW/PruvostDLL020.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   2019 #   Journal #    Learning to Decompose: A Paradigm for Decomposition-Based Multi-Objective Optimization\nMengyuan Wu+, Ke Li, Sam Kwong, Qingfu Zhang, Jun Zhang\nIEEE Trans. Evolutionary Computation (TEVC), 23(3): 376–390, 2019.\n  10.1109/TEVC.2018.2865931\n PDF |  Supp |  Code |  BiB @article{WuLKZZ19, author = {Mengyuan Wu and Ke Li and Sam Kwong and Qingfu Zhang and Jun Zhang}, title = {Learning to Decompose: {A} Paradigm for Decomposition-Based Multiobjective Optimization}, journal = {{IEEE} Trans. Evol. Comput.}, volume = {23}, number = {3}, pages = {376--390}, year = {2019}, url = {https://doi.org/10.1109/TEVC.2018.2865931}, doi = {10.1109/TEVC.2018.2865931}, timestamp = {Tue, 12 May 2020 16:51:10 +0200}, biburl = {https://dblp.org/rec/journals/tec/WuLKZZ19.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Interactive Decomposition Multi-Objective Optimization via Progressively Learned Value Functions\nKe Li*, Renzhi Chen*+, Dragan Savic, Xin Yao\nIEEE Trans. Fuzzy Systems (TFS), 27(5): 845–860, 2019.\n   10.1109/TFUZZ.2018.2880700\n PDF |  Supp |  Code |  BiB @article{LiCSY19, author = {Ke Li and Renzhi Chen and Dragan A. Savic and Xin Yao}, title = {Interactive Decomposition Multiobjective Optimization Via Progressively Learned Value Functions}, journal = {{IEEE} Trans. Fuzzy Syst.}, volume = {27}, number = {5}, pages = {849--860}, year = {2019}, url = {https://doi.org/10.1109/TFUZZ.2018.2880700}, doi = {10.1109/TFUZZ.2018.2880700}, timestamp = {Tue, 12 May 2020 16:52:42 +0200}, biburl = {https://dblp.org/rec/journals/tfs/LiCSY19.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Two-Archive Evolutionary Algorithm for Constrained Multi-Objective Optimization\nKe Li*, Renzhi Chen*+, Guangtao Fu, Xin Yao\nIEEE Trans. Evolutionary Computation (TEVC), 23(2): 303–315, 2019.\n   10.1109/TEVC.2018.2855411\n PDF |  Supp |  Code |  BiB @article{LiCFY19, author = {Ke Li and Renzhi Chen and Guangtao Fu and Xin Yao}, title = {Two-Archive Evolutionary Algorithm for Constrained Multiobjective Optimization}, journal = {{IEEE} Trans. Evol. Comput.}, volume = {23}, number = {2}, pages = {303--315}, year = {2019}, url = {https://doi.org/10.1109/TEVC.2018.2855411}, doi = {10.1109/TEVC.2018.2855411}, timestamp = {Tue, 12 May 2020 16:51:04 +0200}, biburl = {https://dblp.org/rec/journals/tec/LiCFY19.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  A Knee-Point-Based Evolutionary Algorithm Using Weighted Subpopulation for Many-Objective Optimization\nJuan Zou, Chunhui Ji, Shengxiang Yang, Yuping Zhang, Jinhua Zheng, Ke Li\nSwarm and Evolutionary Computation, 47: 33\u0026ndash;43, 2019.\n  10.1016/j.swevo.2019.02.001\n PDF |  BiB @article{ZouJYZZL19, author = {Juan Zou and Chunhui Ji and Shengxiang Yang and Yuping Zhang and Jinhua Zheng and Ke Li}, title = {A Knee-Point-Based Evolutionary Algorithm Using Weighted Subpopulation for Many-Objective Optimization}, journal = {Swarm and Evolutionary Computation}, year = {2019}, note = {accepted for publication} } \n   Conference #    Which Surrogate Works for Empirical Performance Modelling? A Case Study with Differential Evolution\nKe Li, Zilin Xiang+, Kay Chen Tan\nProc. of the 2019 IEEE Congress on Evolutionary Computation (CEC'19), IEEE Press: p. 1988\u0026ndash;1995, June, 2019.\n  10.1109/CEC.2019.8789984\n PDF |  Supp |  BiB @article{LiXT19, author = {Ke Li and Zilin Xiang and Kay Chen Tan}, title = {Which Surrogate Works for Empirical Performance Modelling? {A} Case Study with Differential Evolution}, journal = {CoRR}, volume = {abs/1901.11120}, year = {2019}, url = {http://arxiv.org/abs/1901.11120}, eprinttype = {arXiv}, eprint = {1901.11120}, timestamp = {Mon, 16 Mar 2020 17:55:51 +0100}, biburl = {https://dblp.org/rec/journals/corr/abs-1901-11120.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Visualisation of Pareto Front Approximation: A Short Survey and Empirical Comparisons\nHuiru Gao+, Haifeng Nie+, Ke Li\nProc. of the 2019 IEEE Congress on Evolutionary Computation (CEC'19), IEEE Press: p. 1750\u0026ndash;1757, June, 2019.\n  10.1109/CEC.2019.8790298\n PDF |  Supp |  BiB @article{GaoNL19, author = {Huiru Gao and Haifeng Nie and Ke Li}, title = {Visualisation of Pareto Front Approximation: {A} Short Survey and Empirical Comparisons}, journal = {CoRR}, volume = {abs/1903.01768}, year = {2019}, url = {http://arxiv.org/abs/1903.01768}, eprinttype = {arXiv}, eprint = {1903.01768}, timestamp = {Fri, 08 Jan 2021 11:20:34 +0100}, biburl = {https://dblp.org/rec/journals/corr/abs-1903-01768.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Decomposition Multi-Objective Optimisation: Current Developments and Future Opportunities\nKe Li, Qingfu Zhang\nProc. of the 21th Annual Conference on Genetic and Evolutionary Computation (GECCO’19): ACM Press: p. 1002\u0026ndash;1031, July 2019.\n  10.1145/3319619.3323369\n Slides |  BiB @inproceedings{LiZ19, author = {Ke Li and Qingfu Zhang}, title = {Decomposition multi-objective optimisation: current developments and future opportunities}, booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion, {GECCO} 2019, Prague, Czech Republic, July 13-17, 2019}, pages = {1002--1031}, publisher = {{ACM}}, year = {2019}, url = {https://doi.org/10.1145/3319619.3323369}, doi = {10.1145/3319619.3323369}, timestamp = {Mon, 15 Jul 2019 16:26:46 +0200}, biburl = {https://dblp.org/rec/conf/gecco/LiZ19.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Security Testing of Web Applications: A Search-Based Approach for Detecting SQL Injection Vulnerabilities\nMuyang Liu+, Ke Li, Tao Chen\nProc. of the 21th Annual Conference on Genetic and Evolutionary Computation (GECCO’19), ACM Press: p. 417\u0026ndash;418, July 2019.\n  10.1145/3319619.3322026\n PDF |  BiB @inproceedings{LiuLC19, author = {Muyang Liu and Ke Li and Tao Chen}, title = {Security testing of web applications: a search-based approach for detecting {SQL} injection vulnerabilities}, booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion, {GECCO} 2019, Prague, Czech Republic, July 13-17, 2019}, pages = {417--418}, publisher = {{ACM}}, year = {2019}, url = {https://doi.org/10.1145/3319619.3322026}, doi = {10.1145/3319619.3322026}, timestamp = {Wed, 08 Jan 2020 08:56:46 +0100}, biburl = {https://dblp.org/rec/conf/gecco/LiuLC19.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Progressive Preference Learning: Proof-of-Principle Results in MOEA/D\nKe Li Proc. of the 10th International Conference on Evolutionary Multi-Criterion Optimization (EMO’19), Springer LNCS, volume 11411, p. 631\u0026ndash;643, March 2019.\n  10.1007/978-3-030-12598-1_50\n PDF |  Supp |  Code |  BiB @inproceedings{Li19, author = {Ke Li}, title = {Progressive Preference Learning: Proof-of-Principle Results in {MOEA/D}}, booktitle = {EMO'19: Proc. of the 10th International Conference Evolutionary Multi-Criterion Optimization}, pages = {631--643}, year = {2019}, url = {https://doi.org/10.1007/978-3-030-12598-1\\_50}, doi = {10.1007/978-3-030-12598-1\\_50}, timestamp = {Thu, 28 Feb 2019 14:53:34 +0100}, biburl = {https://dblp.org/rec/bib/conf/emo/Li19}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  A Formal Model for Multi-objective Optimisation of NFV Placement\nJoseph Billingsley, Ke Li, Wang Miao, Geyong Min, N. Georgalas\nProc. of the 10th International Conference on Evolutionary Multi-Criterion Optimization (EMO’19), Springer LNCS, volume 11411, p. 529\u0026ndash;540, March 2019.\n  10.1007/978-3-030-12598-1_42\n PDF |  BiB @inproceedings{BillingsleyLMMG19, author = {Joseph Billingsley and Ke Li and Wang Miao and Geyong Min and Nektarios Georgalas}, title = {A Formal Model for Multi-objective Optimisation of Network Function Virtualisation Placement}, booktitle = {Evolutionary Multi-Criterion Optimization - 10th International Conference, {EMO} 2019, East Lansing, MI, USA, March 10-13, 2019, Proceedings}, series = {Lecture Notes in Computer Science}, volume = {11411}, pages = {529--540}, publisher = {Springer}, year = {2019}, url = {https://doi.org/10.1007/978-3-030-12598-1\\_42}, doi = {10.1007/978-3-030-12598-1\\_42}, timestamp = {Fri, 26 Feb 2021 09:21:56 +0100}, biburl = {https://dblp.org/rec/conf/emo/BillingsleyLMMG19.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   2018 #   Journal #    R-Metric: Evaluating the Performance of Preference-Based Evolutionary Multi-Objective Optimization Using Reference Points\nKe Li, Kalyanmoy Deb, Xin Yao\nIEEE Trans. Evolutionary Computation (TEVC), 22(6): 821\u0026ndash;835, 2018.\n   10.1109/TEVC.2017.2737781\n PDF |  Supp |  Code |  BiB @article{LiDY18, author = {Ke Li and Kalyanmoy Deb and Xin Yao}, title = {R-Metric: Evaluating the Performance of Preference-Based Evolutionary Multiobjective Optimization Using Reference Points}, journal = {{IEEE} Trans. Evol. Comput.}, volume = {22}, number = {6}, pages = {821--835}, year = {2018}, url = {https://doi.org/10.1109/TEVC.2017.2737781}, doi = {10.1109/TEVC.2017.2737781}, timestamp = {Tue, 12 May 2020 16:50:45 +0200}, biburl = {https://dblp.org/rec/journals/tec/LiDY18.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Integration of Preferences in Decomposition Multiobjective Optimization\nKe Li*, Renzhi Chen*+, Geyong Min, Xin Yao\nIEEE Trans. Cybernetics (TCYB), 48(12): 3359\u0026ndash;3370, 2018.\n   10.1109/TCYB.2018.2859363\n PDF |  Supp |  Code |  BiB @article{LiCMY18, author = {Ke Li and Renzhi Chen and Geyong Min and Xin Yao}, title = {Integration of Preferences in Decomposition Multiobjective Optimization}, journal = {{IEEE} Trans. Cybernetics}, volume = {48}, number = {12}, pages = {3359--3370}, year = {2018}, url = {https://doi.org/10.1109/TCYB.2018.2859363}, doi = {10.1109/TCYB.2018.2859363}, timestamp = {Sun, 23 Dec 2018 17:21:04 +0100}, biburl = {https://dblp.org/rec/bib/journals/tcyb/LiCMY18}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Evolutionary Multiobjective Optimization-Based Multimodal Optimization: Fitness Landscape Approximation and Peak Detection\nRan Cheng, Miqing Li, Ke Li, Xin Yao\nIEEE Trans. Evolutionary Computation (TEVC), 22(5): 692\u0026ndash;706, 2018.\n   10.1109/TEVC.2017.2744328\n PDF |  BiB @article{ChengLLY18, author = {Ran Cheng and Miqing Li and Ke Li and Xin Yao}, title = {Evolutionary Multiobjective Optimization-Based Multimodal Optimization: Fitness Landscape Approximation and Peak Detection}, journal = {{IEEE} Trans. Evolutionary Computation}, volume = {22}, number = {5}, pages = {692--706}, year = {2018}, url = {https://doi.org/10.1109/TEVC.2017.2744328}, doi = {10.1109/TEVC.2017.2744328}, timestamp = {Sun, 23 Dec 2018 17:21:04 +0100}, biburl = {https://dblp.org/rec/bib/journals/tec/ChengLLY18}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  FEMOSAA: Feature Guided and Knee Driven Multi-Objective Optimization for Self-Adaptive Software at Runtime\nTao Chen, Ke Li, Rami Bahsoon, Xin Yao\nACM Trans. Software Engineering and Methodology (TOSEM), 27(2): 1\u0026ndash;50, 2018.\n   10.1145/3204459\n PDF |  Code |  BiB @article{ChenLBY18, author = {Tao Chen and Ke Li and Rami Bahsoon and Xin Yao}, title = {{FEMOSAA:} Feature-Guided and Knee-Driven Multi-Objective Optimization for Self-Adaptive Software}, journal = {{ACM} Trans. Softw. Eng. Methodol.}, volume = {27}, number = {2}, pages = {5:1--5:50}, year = {2018}, url = {https://doi.org/10.1145/3204459}, doi = {10.1145/3204459}, timestamp = {Wed, 21 Nov 2018 12:44:28 +0100}, biburl = {https://dblp.org/rec/bib/journals/tosem/ChenLBY18}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Dynamic Multi-Objectives Optimization with a Changing Number of Objectives\nKe Li*, Renzhi Chen*+, Xin Yao,\nIEEE Trans. Evolutionary Computation (TEVC), 21(1): 157\u0026ndash;171, 2018.\n   10.1109/TEVC.2017.2669638\n PDF |  Supp |  Code |  BiB @article{ChenLY18, author = {Renzhi Chen and Ke Li and Xin Yao}, title = {Dynamic Multiobjectives Optimization With a Changing Number of Objectives}, journal = {{IEEE} Trans. Evolutionary Computation}, volume = {22}, number = {1}, pages = {157--171}, year = {2018}, url = {https://doi.org/10.1109/TEVC.2017.2669638}, doi = {10.1109/TEVC.2017.2669638}, timestamp = {Wed, 04 Jul 2018 13:22:50 +0200}, biburl = {https://dblp.org/rec/bib/journals/tec/ChenLY18}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n   Conference #    Multi-Tenant Cloud Service Composition using Evolutionary Optimization\nSatish Kumar, Rami Bahsoon, Tao Chen, Ke Li, R. Buyya,\nProc. of the 24th International Conference on Parallel and Distributed Systems (ICPADS’18), IEEE Press: p. 972\u0026ndash;979, December 2018.\n  10.1109/PADSW.2018.8644640\n PDF |  BiB @inproceedings{KumarBCLB18, author = {Satish Kumar and Rami Bahsoon and Tao Chen and Ke Li and Rajkumar Buyya}, title = {Multi-Tenant Cloud Service Composition Using Evolutionary Optimization}, booktitle = {ICPADS: Proc. of the 24th {IEEE} International Conference on Parallel and Distributed Systems}, pages = {972--979}, year = {2018}, url = {https://doi.org/10.1109/PADSW.2018.8644640}, doi = {10.1109/PADSW.2018.8644640}, timestamp = {Tue, 26 Feb 2019 16:36:22 +0100}, biburl = {https://dblp.org/rec/bib/conf/icpads/KumarBCLB18}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Decomposition Multi-Objective Optimisation: Current Developments and Future Opportunities\nKe Li, Qingfu Zhang\nProc. of the 20th Annual Conference on Genetic and Evolutionary Computation (GECCO’18), ACM Press: p. 903\u0026ndash;936, July 2018.\n  10.1145/3205651.3207856\n Slides |  BiB\n  @inproceedings{LiZ18, author = {Ke Li and Qingfu Zhang}, title = {Decomposition multi-objective optimisation: current developments and future opportunities}, booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion, {GECCO} 2018, Kyoto, Japan, July 15-19, 2018}, pages = {907--936}, publisher = {{ACM}}, year = {2018}, url = {https://doi.org/10.1145/3205651.3207856}, doi = {10.1145/3205651.3207856}, timestamp = {Fri, 27 Dec 2019 21:30:09 +0100}, biburl = {https://dblp.org/rec/conf/gecco/0001Z18.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }  @inproceedings{LiZ18, author = {Ke Li and Qingfu Zhang}, title = {Decomposition multi-objective optimisation: current developments and future opportunities}, booktitle = {GECCO'18: Proc. of the 20th Genetic and Evolutionary Computation Conference Companion}, pages = {907--936}, year = {2018}, url = {https://doi.org/10.1145/3205651.3207856}, doi = {10.1145/3205651.3207856}, timestamp = {Wed, 21 Nov 2018 12:43:54 +0100}, biburl = {https://dblp.org/rec/bib/conf/gecco/0001Z18}, bibsource = {dblp computer science bibliography, https://dblp.org} }   2017 #   Journal #    Efficient Non-domination Level Update Method for Steady-State Evolutionary Multiobjective Optimization\nKe Li, Kalyanmoy Deb, Qingfu Zhang, Qiang Zhang\nIEEE Trans. Cybernetics (TCYB), 47(9): 2838\u0026ndash;2849, 2017.\n  10.1109/TCYB.2016.2621008\n PDF |  Supp |  Code |  BiB @article{LiDZZ17, author = {Ke Li and Kalyanmoy Deb and Qingfu Zhang and Qiang Zhang}, title = {Efficient Nondomination Level Update Method for Steady-State Evolutionary Multiobjective Optimization}, journal = {{IEEE} Trans. Cybernetics}, volume = {47}, number = {9}, pages = {2838--2849}, year = {2017}, url = {https://doi.org/10.1109/TCYB.2016.2621008}, doi = {10.1109/TCYB.2016.2621008}, timestamp = {Wed, 14 Nov 2018 10:31:31 +0100}, biburl = {https://dblp.org/rec/bib/journals/tcyb/LiDZZ17}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Matching-Based Selection with Incomplete Lists for Decomposition Multi-Objective Optimization\nMengyuan Wu+, Ke Li, Sam Kwong, Yu Zhou, Qingfu Zhang\nIEEE Trans. Evolutionary Computation (TEVC), 21(4): 554\u0026ndash;568, 2017.\n  10.1109/TEVC.2017.2656922\n PDF |  Supp |  Code |  BiB @article{WuLKZZ17, author = {Mengyuan Wu and Ke Li and Sam Kwong and Yu Zhou and Qingfu Zhang}, title = {Matching-Based Selection With Incomplete Lists for Decomposition Multiobjective Optimization}, journal = {{IEEE} Trans. Evolutionary Computation}, volume = {21}, number = {4}, pages = {554--568}, year = {2017}, url = {https://doi.org/10.1109/TEVC.2017.2656922}, doi = {10.1109/TEVC.2017.2656922}, timestamp = {Sun, 23 Sep 2018 19:44:31 +0200}, biburl = {https://dblp.org/rec/bib/journals/tec/WuLKZZ17}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Recent advances in semantic computing and personalization\nHaoran Xie, Fu Lee Wang, Xudong Mao, Ke Li, Qing Li, Handing Wang\nNeurocomputing (NEUCOM). 254: 1\u0026ndash;2, 2017.\n  10.1016/j.neucom.2017.02.073\n PDF |  BiB @article{XieWMLLW17, author = {Haoran Xie and Fu Lee Wang and Xudong Mao and Ke Li and Qing Li and Handing Wang}, title = {Recent advances in semantic computing and personalization}, journal = {Neurocomputing}, volume = {254}, pages = {1--2}, year = {2017}, url = {https://doi.org/10.1016/j.neucom.2017.02.073}, doi = {10.1016/j.neucom.2017.02.073}, timestamp = {Fri, 30 Nov 2018 13:23:21 +0100}, biburl = {https://dblp.org/rec/bib/journals/ijon/XieWMLLW17}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n   Conference #    Empirical Investigations of Reference Point Based Methods When Facing a Massively Large Number of Objectives: First Results\nKe Li, Kalyamoy Deb, Tolga Altinoz, Xin Yao\nProc. of the 9th International Conference on Evolutionary Multi-Criterion Optimization (EMO’17), Springer LNCS, volume 10173, p. 390\u0026ndash;405, March 2017.\n  10.1007/978-3-319-54157-0_27\n PDF |  BiB @inproceedings{LiDAY17, author = {Ke Li and Kalyanmoy Deb and Okkes Tolga Altin{\\\"{o}}z and Xin Yao}, title = {Empirical Investigations of Reference Point Based Methods When Facing a Massively Large Number of Objectives: First Results}, booktitle = {EMO'17: Proc. of the 9th International Conference Evolutionary Multi-Criterion Optimization}, pages = {390--405}, year = {2017}, url = {https://doi.org/10.1007/978-3-319-54157-0\\_27}, doi = {10.1007/978-3-319-54157-0\\_27}, timestamp = {Wed, 14 Nov 2018 10:59:29 +0100}, biburl = {https://dblp.org/rec/bib/conf/emo/LiDAY17}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Adaptive weights generation for decomposition-based multi-objective optimization using Gaussian process regression\nMengyuan Wu, Sam Kwong, Yuheng Jia, Ke Li, Qingfu Zhang\nProc. of the 19th Annual Conference on Genetic and Evolutionary Computation (GECCO’17), ACM Press: p. 641\u0026ndash;648, July 2017.\n  10.1145/3071178.3071339\n PDF |  BiB @inproceedings{WuKJLZ17, author = {Mengyuan Wu and Sam Kwong and Yuheng Jia and Ke Li and Qingfu Zhang}, title = {Adaptive weights generation for decomposition-based multi-objective optimization using Gaussian process regression}, booktitle = {GECCO'17: Proc. of the 19th Genetic and Evolutionary Computation Conference}, pages = {641--648}, year = {2017}, url = {https://doi.org/10.1145/3071178.3071339}, doi = {10.1145/3071178.3071339}, timestamp = {Tue, 06 Nov 2018 11:06:40 +0100}, biburl = {https://dblp.org/rec/bib/conf/gecco/WuKJLZ17}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n   2016 #   Journal #   Personalized Search for Social Media via Dominating Verbal Context\nHaoran Xie, Xiaodong Li, Tao Wang, Li Chen, Ke Li, Fu Lee Wang, Yi Cai, Qing Li, Huaqing Min\nNeurocomputing (NEUCOM). 172: 27\u0026ndash;37, 2016.\n  10.1016/j.neucom.2014.12.109\n PDF |  BiB @article{XieLWCLWCLM16, author = {Haoran Xie and Xiaodong Li and Tao Wang and Li Chen and Ke Li and Fu Lee Wang and Yi Cai and Qing Li and Huaqing Min}, title = {Personalized search for social media via dominating verbal context}, journal = {Neurocomputing}, volume = {172}, pages = {27--37}, year = {2016}, url = {https://doi.org/10.1016/j.neucom.2014.12.109}, doi = {10.1016/j.neucom.2014.12.109}, timestamp = {Wed, 14 Nov 2018 10:26:17 +0100}, biburl = {https://dblp.org/rec/bib/journals/ijon/XieLWCLWCLM16}, bibsource = {dblp computer science bibliography, https://dblp.org} }    Conference #   Variable Interactions in Multi-Objective Optimization Problems\nKe Li, Mohammad Nabi Omidvar, Kalyanmoy Deb, Xin Yao\nProc. of the 14th International Conference on Parallel Problem Solving from Nature (PPSN’16), Springer LNCS, volume 9921, p. 399\u0026ndash;409, September 2016.\n  10.1007/978-3-319-45823-6_37\n PDF |  BiB @inproceedings{LiODY16, author = {Ke Li and Mohammad Nabi Omidvar and Kalyanmoy Deb and Xin Yao}, title = {Variable Interaction in Multi-objective Optimization Problems}, booktitle = {Parallel Problem Solving from Nature - {PPSN} {XIV} - 14th International Conference, Edinburgh, UK, September 17-21, 2016, Proceedings}, series = {Lecture Notes in Computer Science}, volume = {9921}, pages = {399--409}, publisher = {Springer}, year = {2016}, url = {https://doi.org/10.1007/978-3-319-45823-6\\_37}, doi = {10.1007/978-3-319-45823-6\\_37}, timestamp = {Wed, 19 Jan 2022 09:30:47 +0100}, biburl = {https://dblp.org/rec/conf/ppsn/LiODY16.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }   2015 #   Journal #    An Evolutionary Many-Objective Optimization Algorithm Based on Dominance and Decomposition\nKe Li, Kalyanmoy Deb, Qingfu Zhang, Sam Kwong\nIEEE Trans. Evolutionary Computation (TEVC), 19(5): 694\u0026ndash;716, 2015.\n  10.1109/TEVC.2014.2373386\n PDF |  Code |  BiB @article{LiDZK15, author = {Ke Li and Kalyanmoy Deb and Qingfu Zhang and Sam Kwong}, title = {An Evolutionary Many-Objective Optimization Algorithm Based on Dominance and Decomposition}, journal = {{IEEE} Trans. Evolutionary Computation}, volume = {19}, number = {5}, pages = {694--716}, year = {2015}, url = {https://doi.org/10.1109/TEVC.2014.2373386}, doi = {10.1109/TEVC.2014.2373386}, timestamp = {Sun, 23 Sep 2018 19:44:31 +0200}, biburl = {https://dblp.org/rec/bib/journals/tec/LiDZK15}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Interrelationship-Based Selection for Decomposition Multiobjective Optimization\nKe Li, Sam Kwong, Qingfu Zhang, Kalyanmoy Deb\nIEEE Trans. Cybernetics (TCYB), 45(10): 2076\u0026ndash;2088, 2015\n  10.1109/TCYB.2014.2365354\n PDF |  PDF |  Code |  BiB @article{LiKZD15, author = {Ke Li and Sam Kwong and Qingfu Zhang and Kalyanmoy Deb}, title = {Interrelationship-Based Selection for Decomposition Multiobjective Optimization}, journal = {{IEEE} Trans. Cybernetics}, volume = {45}, number = {10}, pages = {2076--2088}, year = {2015}, url = {https://doi.org/10.1109/TCYB.2014.2365354}, doi = {10.1109/TCYB.2014.2365354}, timestamp = {Wed, 14 Nov 2018 10:31:35 +0100}, biburl = {https://dblp.org/rec/bib/journals/tcyb/LiKZD15}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  A Dual-Population Paradigm for Evolutionary Multiobjective Optimization\nKe Li, Sam Kwong, Kalyanmoy Deb\nInformation Sciences (INS), 309: 50\u0026ndash;72, 2015.\n  10.1016/j.ins.2015.03.002\n PDF |  Code |  BiB @article{LiKD15, author = {Ke Li and Sam Kwong and Kalyanmoy Deb}, title = {A dual-population paradigm for evolutionary multiobjective optimization}, journal = {Inf. Sci.}, volume = {309}, pages = {50--72}, year = {2015}, url = {https://doi.org/10.1016/j.ins.2015.03.002}, doi = {10.1016/j.ins.2015.03.002}, timestamp = {Wed, 14 Nov 2018 10:27:37 +0100}, biburl = {https://dblp.org/rec/bib/journals/isci/LiKD15}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Class-Specific Soft Voting based Multiple Extreme Learning Machines Ensemble\nJingjing Cao, Sam Kwong, Ran Wang, Xiaodong Li, Ke Li, Xiangfei Kong\nNeurocomputing (NEUCOM). 149: 275\u0026ndash;284, 2015.\n  10.1016/j.neucom.2014.02.072\n PDF |  BiB @article{CaoKWLLK15, author = {Jingjing Cao and Sam Kwong and Ran Wang and Xiaodong Li and Ke Li and Xiangfei Kong}, title = {Class-specific soft voting based multiple extreme learning machines ensemble}, journal = {Neurocomputing}, volume = {149}, pages = {275--284}, year = {2015}, url = {https://doi.org/10.1016/j.neucom.2014.02.072}, doi = {10.1016/j.neucom.2014.02.072}, timestamp = {Wed, 14 Nov 2018 10:26:17 +0100}, biburl = {https://dblp.org/rec/bib/journals/ijon/CaoKWLLK15}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n   Conference #    Two-Level Stable Matching-Based Selection in MOEA/D\nMengyuan Wu, Sam Kwong, Qingfu Zhang, Ke Li, Ran Wang, Bo Liu\nProc. of 2015 IEEE Conference on Systems, Mans and Cybernetics (SMC’15), IEEE Press: p. 1720\u0026ndash;1725, October 2015.\n  10.1109/SMC.2015.302\n PDF |  Code |  BiB @inproceedings{WuKZLWL15, author = {Mengyuan Wu and Sam Kwong and Qingfu Zhang and Ke Li and Ran Wang and Bo Liu}, title = {Two-Level Stable Matching-Based Selection in {MOEA/D}}, booktitle = {2015 {IEEE} International Conference on Systems, Man, and Cybernetics, Kowloon Tong, Hong Kong, October 9-12, 2015}, pages = {1720--1725}, publisher = {{IEEE}}, year = {2015}, url = {https://doi.org/10.1109/SMC.2015.302}, doi = {10.1109/SMC.2015.302}, timestamp = {Wed, 16 Oct 2019 14:14:51 +0200}, biburl = {https://dblp.org/rec/conf/smc/WuKZLWL15.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n  Evolutionary Multiobjective Optimization with Hybrid Selection Principles\nKe Li, Kalyanmoy Deb, Qingfu Zhang\nProc. of 2015 IEEE Congress on Evolutionary Computation (CEC’15), IEEE Press: p. 900\u0026ndash;907, May 2015.\n  10.1109/CEC.2015.7256986\n PDF |  Code |  BiB\n  @inproceedings{LiDZ15, author = {Ke Li and Kalyanmoy Deb and Qingfu Zhang}, title = {Evolutionary multiobjective optimization with hybrid selection principles}, booktitle = {{IEEE} Congress on Evolutionary Computation, {CEC} 2015, Sendai, Japan, May 25-28, 2015}, pages = {900--907}, publisher = {{IEEE}}, year = {2015}, url = {https://doi.org/10.1109/CEC.2015.7256986}, doi = {10.1109/CEC.2015.7256986}, timestamp = {Wed, 16 Oct 2019 14:14:52 +0200}, biburl = {https://dblp.org/rec/conf/cec/LiDZ15.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }  @article{LiZKLW14, author = {Ke Li and Qingfu Zhang and Sam Kwong and Miqing Li and Ran Wang}, title = {Stable Matching-Based Selection in Evolutionary Multiobjective Optimization}, journal = {{IEEE} Trans. Evolutionary Computation}, volume = {18}, number = {6}, pages = {909--923}, year = {2014}, url = {https://doi.org/10.1109/TEVC.2013.2293776}, doi = {10.1109/TEVC.2013.2293776}, timestamp = {Sun, 23 Sep 2018 19:44:31 +0200}, biburl = {https://dblp.org/rec/bib/journals/tec/LiZKLW14}, bibsource = {dblp computer science bibliography, https://dblp.org} }   2014 #   Journal #    Stable Matching Based Selection in Evolutionary Multiobjective Optimization\nKe Li, Qingfu Zhang, Sam Kwong, Miqing Li, Ran Wang\nIEEE Trans. Evolutionary Computation (TEVC). 18(6): 909\u0026ndash;923, 2014.\n  10.1109/TEVC.2013.2293776\n PDF |  Code |  BiB @article{LiZKLW14, author = {Ke Li and Qingfu Zhang and Sam Kwong and Miqing Li and Ran Wang}, title = {Stable Matching-Based Selection in Evolutionary Multiobjective Optimization}, journal = {{IEEE} Trans. Evolutionary Computation}, volume = {18}, number = {6}, pages = {909--923}, year = {2014}, url = {https://doi.org/10.1109/TEVC.2013.2293776}, doi = {10.1109/TEVC.2013.2293776}, timestamp = {Sun, 23 Sep 2018 19:44:31 +0200}, biburl = {https://dblp.org/rec/bib/journals/tec/LiZKLW14}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Adaptive Operator Selection with Bandits for Multiobjective Evolutionary Algorithm Based on Decomposition\nKe Li, Álvaro Fialho, Sam Kwong, Qingfu Zhang\nIEEE Trans. Evolutionary Computation (TEVC). 18(1): 114\u0026ndash;130, 2014.\n  10.1109/TEVC.2013.2239648\n PDF |  Supp |  Code |  BiB @article{LiFKZ14, author = {Ke Li and {\\'{A}}lvaro Fialho and Sam Kwong and Qingfu Zhang}, title = {Adaptive Operator Selection With Bandits for a Multiobjective Evolutionary Algorithm Based on Decomposition}, journal = {{IEEE} Trans. Evolutionary Computation}, volume = {18}, number = {1}, pages = {114--130}, year = {2014}, url = {https://doi.org/10.1109/TEVC.2013.2239648}, doi = {10.1109/TEVC.2013.2239648}, timestamp = {Sun, 23 Sep 2018 19:44:31 +0200}, biburl = {https://dblp.org/rec/bib/journals/tec/LiFKZ14}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  A General Framework for Evolutionary Multiobjective Optimization via Manifold Learning\nKe Li, Sam Kwong\nNeurocomputing (NEUCOM). 146: 65\u0026ndash;74, 2014.\n  10.1016/j.neucom.2014.03.070\n PDF |  BiB @article{LiK14, author = {Ke Li and Sam Kwong}, title = {A general framework for evolutionary multiobjective optimization via manifold learning}, journal = {Neurocomputing}, volume = {146}, pages = {65--74}, year = {2014}, url = {https://doi.org/10.1016/j.neucom.2014.03.070}, doi = {10.1016/j.neucom.2014.03.070}, timestamp = {Wed, 14 Nov 2018 10:26:16 +0100}, biburl = {https://dblp.org/rec/bib/journals/ijon/LiK14}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Evolutionary Algorithms with Segment-based Search for Multiobjective Optimization Problems\nMiqing Li, Shengxiang Yang, Ke Li, Xiaohui Liu\nIEEE Trans. Cybernetics (TCYB). 44(8): 1295\u0026ndash;1313, 2014.\n  10.1109/TCYB.2013.2282503\n PDF |  BiB @article{LiYLL14, author = {Miqing Li and Shengxiang Yang and Ke Li and Xiaohui Liu}, title = {Evolutionary Algorithms With Segment-Based Search for Multiobjective Optimization Problems}, journal = {{IEEE} Trans. Cybernetics}, volume = {44}, number = {8}, pages = {1295--1313}, year = {2014}, url = {https://doi.org/10.1109/TCYB.2013.2282503}, doi = {10.1109/TCYB.2013.2282503}, timestamp = {Wed, 14 Nov 2018 10:31:34 +0100}, biburl = {https://dblp.org/rec/bib/journals/tcyb/LiYLL14}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n   Conference #   An Indicator-based Selection Multi-Objective Evolutionary Algorithm with Preference for Multi-Class Ensemble\nJingjing Cao, Sam Kwong, Ran Wang, Ke Li\nProc. of 2014 International Conference on Machine Learning and Cybernetics (ICMLC’12), IEEE Press: p. 147\u0026ndash;152, July 2014.\n  10.1109/ICMLC.2014.7009108\n PDF |  BiB  @inproceedings{CaoKWL14, author = {Jingjing Cao and Sam Kwong and Ran Wang and Ke Li}, title = {{AN} indicator-based selection multi-objective evolutionary algorithm with preference for multi-class ensemble}, booktitle = {ICMLC'14: Proc. of the 2014 International Conference on Machine Learning and Cybernetics}, pages = {147--152}, year = {2014}, url = {https://doi.org/10.1109/ICMLC.2014.7009108}, doi = {10.1109/ICMLC.2014.7009108}, timestamp = {Mon, 29 Jan 2018 16:21:37 +0100}, biburl = {https://dblp.org/rec/bib/conf/icmlc/CaoKWL14}, bibsource = {dblp computer science bibliography, https://dblp.org} }  @article{LiKWTM13, author = {Ke Li and Sam Kwong and Ran Wang and Kit{-}Sang Tang and Kim{-}Fung Man}, title = {Learning paradigm based on jumping genes: {A} general framework for enhancing exploration in evolutionary multiobjective optimization}, journal = {Inf. Sci.}, volume = {226}, pages = {1--22}, year = {2013}, url = {https://doi.org/10.1016/j.ins.2012.11.002}, doi = {10.1016/j.ins.2012.11.002}, timestamp = {Wed, 14 Nov 2018 10:27:36 +0100}, biburl = {https://dblp.org/rec/bib/journals/isci/LiKWTM13}, bibsource = {dblp computer science bibliography, https://dblp.org} }   2013 #   Journal #   Learning Paradigm Based on Jumping Genes: A General Framework for Enhancing Exploration in Evolutionary Multiobjective Optimization\nKe Li, Sam Kwong, Ran Wang, Kit-Sang Tang, Kim-Fung Man\nInformation Sciences (INS), 226: 1\u0026ndash;22, 2013.\n  10.1016/j.ins.2012.11.002\n PDF |  Code |  BiB @article{LiKWTM13, author = {Ke Li and Sam Kwong and Ran Wang and Kit{-}Sang Tang and Kim{-}Fung Man}, title = {Learning paradigm based on jumping genes: {A} general framework for enhancing exploration in evolutionary multiobjective optimization}, journal = {Inf. Sci.}, volume = {226}, pages = {1--22}, year = {2013}, url = {https://doi.org/10.1016/j.ins.2012.11.002}, doi = {10.1016/j.ins.2012.11.002}, timestamp = {Wed, 14 Nov 2018 10:27:36 +0100}, biburl = {https://dblp.org/rec/bib/journals/isci/LiKWTM13}, bibsource = {dblp computer science bibliography, https://dblp.org} }    Conference #   Evolving Extreme Learning Machine Paradigm with Adaptive Operator Selection and Parameter Control\nKe Li, Ran Wang, Sam Kwong, Jingjing Cao\nInternational Journal of Uncertainty, Fuzziness and Knowledge-Based Systems (IJUFKS). 21(supp02): 143\u0026ndash;154, 2013.\n 10.1142/S0218488513400229\n PDF |  Code |  BiB @ARTICLE{IJUFKS13, author = {Ke Li and Ran Wang and Sam Kwong and Jingjing Cao}, title = {Evolving Extreme Learning Machine Paradigm with Adaptive Operator Selection and Parameter Control}, journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems}, year = {2013}, volume = {21}, pages = {143-154} }   2012 #   Journal #   Achieving Balance Between Proximity and Diversity in Multi-objective Evolutionary Algorithm\nKe Li, Sam Kwong, Jingjing Cao, Miqing Li, Jinhua Zheng, Ruimin Shen\nInformation Sciences (INS), 182(1): 220\u0026ndash;242, 2012.\n  10.1016/j.ins.2011.08.027\n PDF |  BiB @article{LiKCLZS12, author = {Ke Li and Sam Kwong and Jingjing Cao and Miqing Li and Jinhua Zheng and Ruimin Shen}, title = {Achieving balance between proximity and diversity in multi-objective evolutionary algorithm}, journal = {Inf. Sci.}, volume = {182}, number = {1}, pages = {220--242}, year = {2012}, url = {https://doi.org/10.1016/j.ins.2011.08.027}, doi = {10.1016/j.ins.2011.08.027}, timestamp = {Wed, 14 Nov 2018 10:27:37 +0100}, biburl = {https://dblp.org/rec/bib/journals/isci/LiKCLZS12}, bibsource = {dblp computer science bibliography, https://dblp.org} }    Conference #    Multi-Objective Differential Evolution with Self-Navigation\nKe Li, Sam Kwong, Ran Wang, Jingjing Cao, Imre J. Rudas\nProc. of 2012 IEEE International Conference on Systems, Mans and Cybernetics (SMC’12), IEEE Press: p. 508\u0026ndash;513, October 2012.\n  10.1109/ICSMC.2012.6377775\n PDF |  BiB @inproceedings{LiKWCR12, author = {Ke Li and Sam Kwong and Ran Wang and Jingjing Cao and Imre J. Rudas}, title = {Multi-objective differential evolution with self-navigation}, booktitle = {SMC'12: Proc. of the 2012 {IEEE} International Conference on Systems, Man, and Cybernetics}, pages = {508--513}, year = {2012}, url = {https://doi.org/10.1109/ICSMC.2012.6377775}, doi = {10.1109/ICSMC.2012.6377775}, timestamp = {Mon, 29 Jan 2018 16:21:37 +0100}, biburl = {https://dblp.org/rec/bib/conf/smc/LiKWCR12}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  A Weighted Voting Method Using Minimum Square Error based on Extreme Learning Machine\nJingjing Cao, Sam Kwong, Ran Wang, Ke Li\nProc. of 2012 International Conference on Machine Learning and Cybernetics (ICMLC’12), IEEE Press: p. 411\u0026ndash;414, July 2012.\n  10.1109/ICMLC.2012.6358949\n PDF |  BiB @inproceedings{CaoKWL12, author = {Jingjing Cao and Sam Kwong and Ran Wang and Ke Li}, title = {A weighted voting method using minimum square error based on Extreme Learning Machine}, booktitle = {ICMLC'12: Proc. of the 2012 International Conference on Machine Learning and Cybernetics}, pages = {411--414}, year = {2012}, url = {https://doi.org/10.1109/ICMLC.2012.6358949}, doi = {10.1109/ICMLC.2012.6358949}, timestamp = {Mon, 29 Jan 2018 16:21:37 +0100}, biburl = {https://dblp.org/rec/bib/conf/icmlc/CaoKWL12}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n   2011 #   Conference #    Combining Interpretable Fuzzy Rule-based Classifiers via Multi-Objective Hierarchical Evolutionary Algorithm\nJingjing Cao, Hanli Wang, Sam Kwong, Ke Li\nProc. of 2011 IEEE International Conference on Systems, Mans and Cybernetics (SMC’11), IEEE Press: p. 1771\u0026ndash;1776, October 2011.\n  10.1109/ICSMC.2011.6083928\n PDF |  BiB @inproceedings{CaoWKL11, author = {Jingjing Cao and Hanli Wang and Sam Kwong and Ke Li}, title = {Combining interpretable fuzzy rule-based classifiers via multi-objective hierarchical evolutionary algorithm}, booktitle = {ICMLC'11: Proc. of the 2011 {IEEE} International Conference on Systems, Man and Cybernetics}, pages = {1771--1776}, year = {2011}, url = {https://doi.org/10.1109/ICSMC.2011.6083928}, doi = {10.1109/ICSMC.2011.6083928}, timestamp = {Mon, 27 Nov 2017 16:55:26 +0100}, biburl = {https://dblp.org/rec/bib/conf/smc/CaoWKL11}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  JGBL paradigm: A Novel Strategy to Enhance the Exploration Ability of NSGA-II\nKe Li, Sam Kwong, Kim-Fung Man\nProc. of the 13th Annual Conference on Genetic and Evolutionary Computation (GECCO’11), ACM Press: p. 99\u0026ndash;100, July 2011.\n  10.1145/2001858.2001915\n PDF |  BiB @inproceedings{LiKM11, author = {Ke Li and Sam Kwong and Kim{-}Fung Man}, title = {{JGBL} paradigm: a novel strategy to enhance the exploration ability of nsga-ii}, booktitle = {GECCO'11: Proc. of the 13th Annual Genetic and Evolutionary Computation Conference}, pages = {99--100}, year = {2011}, url = {https://doi.org/10.1145/2001858.2001915}, doi = {10.1145/2001858.2001915}, timestamp = {Tue, 06 Nov 2018 11:06:35 +0100}, biburl = {https://dblp.org/rec/bib/conf/gecco/LiKM11}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Multi-Objective Differential Evolution with Adaptive Control of Parameters and Operators\nKe Li, Álvaro Fialho, Sam Kwong\nProc. of the 5th International Conference on Learning and Intelligent OptimizatioN (LION’11), Springer Verlag, LNCS, p. 473\u0026ndash;487, January 2011.\n  10.1007/978-3-642-25566-3_37\n PDF |  BiB @inproceedings{LiFK11, author = {Ke Li and {\\'{A}}lvaro Fialho and Sam Kwong}, title = {Multi-Objective Differential Evolution with Adaptive Control of Parameters and Operators}, booktitle = {Learning and Intelligent Optimization - 5th International Conference, {LION} 5, Rome, Italy, January 17-21, 2011. Selected Papers}, series = {Lecture Notes in Computer Science}, volume = {6683}, pages = {473--487}, publisher = {Springer}, year = {2011}, url = {https://doi.org/10.1007/978-3-642-25566-3\\_37}, doi = {10.1007/978-3-642-25566-3\\_37}, timestamp = {Tue, 14 May 2019 10:00:51 +0200}, biburl = {https://dblp.org/rec/conf/lion/LiFK11.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   2010 #   Journal #   A Novel Slicing Based Algorithm to Calculate Hypervolume for Multi-Objective Optimization Problems\nKe Li, Jinhua Zheng, Miqing Li, Cong Zhou, Hui Lv\nICIC Express Letters: An International Journal of Research and Surveys, 4(4): 1113\u0026ndash;1120, 2010.\n PDF |  BiB @article{LiZLZL10, author = {Ke Li and Jinhua Zheng and Miqing Li and Cong Zhou and Hui Lv}, title = {A Novel Slicing Based Algorithm to Calculate Hypervolume for Multi-Objective Optimization Problems}, journal = {ICIC Express Letters: An International Journal of Research and Surveys}, volume = {4}, number = {4}, year = {2010}, pages = {1133-1120} }   Conference #    Enhancing Diversity for Average Ranking Method in Evolutionary Many-Objective Optimization\nMiqing Li, Jinhua Zheng, Ke Li, Qizhao Yuan, Ruimin Shen\nProc. of the 11th International Conference on Parallel Problem Solving from Nature (PPSN’10), Springer Verlag, LNCS, volume 6238: p. 647\u0026ndash;656, September 2010.\n  10.1007/978-3-642-15844-5_65\n PDF |  BiB @inproceedings{LiZLYS10, author = {Miqing Li and Jinhua Zheng and Ke Li and Qizhao Yuan and Ruimin Shen}, title = {Enhancing Diversity for Average Ranking Method in Evolutionary Many-Objective Optimization}, booktitle = {PPSN'10: Proc. of 11th International Conference on Parallel Problem Solving from Nature}, pages = {647--656}, year = {2010}, url = {https://doi.org/10.1007/978-3-642-15844-5\\_65}, doi = {10.1007/978-3-642-15844-5\\_65}, timestamp = {Wed, 14 Nov 2018 10:55:35 +0100}, biburl = {https://dblp.org/rec/bib/conf/ppsn/LiZLYS10}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  A Grid-based Fitness Strategy for Evolutionary Many-Objective Optimization\nMiqing Li, Jinhua Zheng, Ruimin Shen, Ke Li, Qizhao Yuan\nProc. of the 12th Annual Conference on Genetic and Evolutionary Computation (GECCO’10), ACM Press: p. 463\u0026ndash;470, July 2010.\n  10.1145/1830483.1830570\n PDF |  BiB @inproceedings{LiZSLY10, author = {Miqing Li and Jinhua Zheng and Ruimin Shen and Ke Li and Qizhao Yuan}, title = {A grid-based fitness strategy for evolutionary many-objective optimization}, booktitle = {Genetic and Evolutionary Computation Conference, {GECCO} 2010, Proceedings, Portland, Oregon, USA, July 7-11, 2010}, pages = {463--470}, publisher = {{ACM}}, year = {2010}, url = {https://doi.org/10.1145/1830483.1830570}, doi = {10.1145/1830483.1830570}, timestamp = {Tue, 06 Nov 2018 11:06:40 +0100}, biburl = {https://dblp.org/rec/conf/gecco/LiZSLY10.bib}, bibsource = {dblp computer science bibliography, https://dblp.org} }\n   2009 #   Conference #    A Novel Algorithm for Non-dominated Hypervolume-based Multiobjective Optimization\nKe Li, Jinhua Zheng, Miqing Li, Cong Zhou, Hui Lv\nProc. of 2009 IEEE International Conference on Systems, Mans and Cybernetics (SMC’09), IEEE Press: p. 5220\u0026ndash;5226, December 2009.\n  10.1109/ICSMC.2009.5345983\n PDF |  BiB @inproceedings{LiZLZL09, author = {Ke Li and Jinhua Zheng and Miqing Li and Cong Zhou and Hui Lv}, title = {A Novel Algorithm for Non-dominated Hypervolume-based Multiobjective Optimization}, booktitle = {SMC'09: Proc. of the 2009 {IEEE} International Conference on Systems, Man and Cybernetics}, pages = {5220--5226}, year = {2009}, url = {https://doi.org/10.1109/ICSMC.2009.5345983}, doi = {10.1109/ICSMC.2009.5345983}, timestamp = {Tue, 28 Nov 2017 16:18:09 +0100}, biburl = {https://dblp.org/rec/bib/conf/smc/LiZLZL09}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  An Spanning Tree Based Method For Pruning Non-Dominated Solutions in Multi- Objective Optimization Problems\nMiqing Li, Jinhua Zheng, Ke Li, Jun Wu, Guixia Xiao\nProc. of 2009 IEEE International Conference on Systems, Mans and Cybernetics (SMC’09), IEEE Press: p. 4882\u0026ndash;4887, December 2009.\n  10.1109/ICSMC.2009.5346322\n PDF |  BiB @inproceedings{LiZLWX09, author = {Miqing Li and Jinhua Zheng and Ke Li and Jun Wu and Guixia Xiao}, title = {An Spanning Tree Based Method For Pruning Non-Dominated Solutions in Multi-Objective Optimization Problems}, booktitle = {SMC'09: Proc. of the 2009 {IEEE} International Conference on Systems, Man and Cybernetics}, pages = {4882--4887}, year = {2009}, url = {https://doi.org/10.1109/ICSMC.2009.5346322}, doi = {10.1109/ICSMC.2009.5346322}, timestamp = {Tue, 28 Nov 2017 16:18:09 +0100}, biburl = {https://dblp.org/rec/bib/conf/smc/LiZLWX09}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  Objective Reduction based on the Least Square Method for Large-dimensional Multiobjective Optimization Problem\nCong Zhou, Jinhua Zheng, Ke Li, Hui Lv\nProc. of the 5th International Conference on Natural Computation (ICNC’09), IEEE Press: p. 350\u0026ndash;354, August 2009.\n  10.1109/ICNC.2009.40\n PDF |  BiB @inproceedings{ZhouZLL09, author = {Cong Zhou and Jinhua Zheng and Ke Li and Hui Lv}, title = {Objective Reduction Based on the Least Square Method for Large-Dimensional Multi-objective Optimization Problem}, booktitle = {ICNC'09: Proc. of the 5th International Conference on Natural Computation}, pages = {350--354}, year = {2009}, url = {https://doi.org/10.1109/ICNC.2009.40}, doi = {10.1109/ICNC.2009.40}, timestamp = {Tue, 28 Nov 2017 16:18:09 +0100}, biburl = {https://dblp.org/rec/bib/conf/icnc/ZhouZLL09}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  The Convergence Analysis of Genetic Algorithm based on Space Mating\nHui Lv, Jinhua Zheng, Jun Wu, Cong Zhou, Ke Li\nProc. of the 5th International Conference on Natural Computation (ICNC’09), IEEE Press: p. 557\u0026ndash;562, August 2009.\n  10.1109/ICNC.2009.39\n PDF |  BiB @inproceedings{LvZWZL09, author = {Hui Lv and Jinhua Zheng and Jun Wu and Cong Zhou and Ke Li}, title = {The Convergence Analysis of Genetic Algorithm Based on Space Mating}, booktitle = {ICNC'09: Proc. of 5th International Conference on Natural Computation}, pages = {557--562}, year = {2009}, url = {https://doi.org/10.1109/ICNC.2009.39}, doi = {10.1109/ICNC.2009.39}, timestamp = {Tue, 28 Nov 2017 16:18:09 +0100}, biburl = {https://dblp.org/rec/bib/conf/icnc/LvZWZL09}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  An Improved Multi-objective Evolutionary Algorithm based on Differential Evolution\nKe Li, Jinhua Zheng\nProc. of 2009 WRI World Congress on Computer Science and Information Engineering (CSIE’09), IEEE Press: p. 825\u0026ndash;830, March 2009.\n  10.1109/CSIE.2009.181\n PDF |  BiB @inproceedings{LiZZL09, author = {Ke Li and Jinhua Zheng and Cong Zhou and Hui Lv}, title = {An Improved Differential Evolution for Multi-objective Optimization}, booktitle = {CSIE'09: Proc. of the 2009 {WRI} World Congress on Computer Science and Information Engineering}, pages = {825--830}, year = {2009}, url = {https://doi.org/10.1109/CSIE.2009.181}, doi = {10.1109/CSIE.2009.181}, timestamp = {Tue, 28 Nov 2017 16:18:09 +0100}, biburl = {https://dblp.org/rec/bib/conf/csie/LiZZL09}, bibsource = {dblp computer science bibliography, https://dblp.org} } \n  "}),e.add({id:17,href:"/docs/events/readinggroup/",title:"Reading Group",section:"Docs",content:"Reading Group #     The paper reading group meets weekly during the semester to discuss papers. Participation is open to all, guests are always welcome; if you are interested in engaging with us, please feel free to contact Dr Ke Li.   More about our reading group culture \u0026#43;  The paper to discuss is announced about one week in advance by the presenter. All participants are expected to read the paper before the meeting. It is recommended to take notes about insights, questions, and other points potentially worth discussions.\nThe goals of the reading group are:\n Critical reflection on scientific work Practice of reading and argumentation strategies Exposure to a broad range of research topics Practice of leading group discussions  The discussion is usually limited to one hour. The presenter will kick off the meeting by giving a short summary of the paper and raising a few points for discussion. The present is expected to inspire participants into the discussion.\n   Agenda (Year 2023) #  May   Bayesian Optimization with Conformal Prediction Sets\nAISTAS 2023\n paper |  slides |  Shengbo Wang |  May 7\n  A Statistical Framework for Low-bitwidth Training of Deep Neural Networks\nNeurIPS 2020\n paper |  slides |  Fan Li |  May 14\n  RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy \u0026amp; Out-of-Distribution Robustness\nNeurIPS 2022\n paper |  slides |  Shasha Zhou |  May 21\n  Moderator: Shengbo Wang\nJun   Optimistic tree search strategies for black-box combinatorial optimization\nNeurIPS 2022\n paper |  slides |  Peili Mao |  June 4\n  Explaining Hyperparameter Optimization via Partial Dependence Plots\nNeurIPS 2021\n paper |  slides |  Mingyu Huang |  June 18\n  Moderator: Peili Mao\n  Previous reading group information can be found from our archive.\n"}),e.add({id:18,href:"/docs/events/studygroup/",title:"Study Group",section:"Docs",content:"Study Group #     The core purpose of this study group, which runs every Sunday afternoon, is to learn some fundamental knowledge pertinent to our research. Participation is usually expected to be our COLA members. However, if you are interested in engaging with us, please feel free to contact Dr Ke Li for a discussion.  Agenda (Year 2022) #  Dec   Zero article: no article\nAcademic Writing Series #7\n slides |  Ke Li |  December 25\n  Zero article: no article\nAcademic Writing Series #6\n slides |  Ke Li |  December 18\n  Definite article: the\nAcademic Writing Series #5\n slides |  Ke Li |  December 11\n  Nov   Indefinite article: a / an\nAcademic Writing Series #4\n slides |  Ke Li |  November 27\n  Genitive: the possessive form of nouns\nAcademic Writing Series #3\n slides |  Ke Li |  November 20\n  Nouns: plurals, countable versus uncountable\nAcademic Writing Series #2\n slides |  Ke Li |  November 13\n  第一、二章: 基础知识\n《最优化计算方法》\n slides |  Fan Li, Heng Yang |  November 13\n  Nouns: plurals, countable versus uncountable\nAcademic Writing Series #1\n slides |  Ke Li |  November 4\n    Previous study group information can be found from our archive.\n"}),e.add({id:19,href:"/docs/research/supp/supp_deto/",title:"Supplementary",section:"Docs",content:"Supplementary Materials #     This website maintains the supplementary materials related to the following paper:\nKe Li+, Renzhi Chen+, Xin Yao, \u0026ldquo;A Data-Driven Evolutionary Transfer Optimization for Expensive Problems in Dynamic Environments\u0026rdquo;, arXiv CoRR abs/xxxx.xxxxx, 2022.  It consists of the following parts:\n Appendix document of this paper can be found from our  Dropbox link. Examples of the dynamically changing fitness landscape of both the moving peak benchmark problems (left hand side) and the moving peak benchmark with Gaussian peaks (right hand side).    Illustrative examples of the dynamically rotating handwritten digital images collected from the MNIST dataset at different time steps.   We are keen on promoting reproducibility and transparency in scientific research. Since this manuscript is currently submitted for possible publication, the source codes used in our empirical study will be publicly available after its acceptance.  "}),e.add({id:20,href:"/docs/research/supp/supp_dmi/",title:"Supplementary",section:"Docs",content:"Supplementary Materials #     This website maintains the supplementary materials related to the following paper:\nKe Li, Renzhi Chen, \u0026ldquo;Batched Data-Driven Evolutionary Multi-Objective Optimization Based on Manifold Interpolation\u0026rdquo;, IEEE Trans. Evol. Comput., accepted for publication, 2022.  It consists of the following parts:\n The source code of this paper can be found from our  Github repo. Appendix document of this paper can be found from this  Dropbox link. Tables of all comparison results can be found in this  Dropbox link. Figures of all comparison results of the population distributions of on different benchmark test problems can be found in this  Dropbox link.  Please cite the paper by using the following bibtex.\n@article{LiC22, author = {Ke Li and Renzhi Chen}, title = {Batched Data-Driven Evolutionary Multi-Objective Optimization Based on Manifold Interpolation}, journal = {{IEEE} Trans. Evol. Comput.}, pages = {1--15}, year = {2022}, note = {accepted for publication} } "}),e.add({id:21,href:"/docs/research/supp/supp_ranknet/",title:"Supplementary",section:"Docs",content:"Supplementary Materials #     This website maintains the supplementary materials related to the following paper:\nKe Li, Guiyu Lai+, Xin Yao, \u0026ldquo;Interactive Evolutionary Multi-Objective Optimization via Learning-to-Rank\u0026rdquo;, IEEE Trans. Evol. Comput., accepted for publication, 2022.  It consists of the following parts:\n The source code of this paper can be found from our  Github repo. Appendix document of this paper can be found from this  Dropbox link. Video clips of the best policy obtained by different algorithms. In particular,   \\(f_1\\)  is the x-axis speed,  \\(f_2\\)  is the y-axis speed,  \\(f_3 \\text{ is the energy consumption} \\)   BC-EMO:  \\( (f_1=68.45730, f_2=111.72400, f_3=95.55980)^\\top \\)   NEMO-0:  \\( (f_1=68.45730, f_2=111.72400, f_3=95.55980)^\\top \\)   I-MOEA/D-PLVF:  \\( (f_1=156.62800, f_2=30.54620, f_3=75.83200)^\\top \\)   IEMO/D:  \\( (f_1=66.09890, f_2=61.94570, f_3=75.91520)^\\top \\)   I-NSGA-II/LTR:  \\( (f_1=100.52500, f_2=96.36920, f_3=100.34000)^\\top \\)   I-MOEA/D/LTR:  \\( (f_1=114.31000, f_2=68.71040, f_3=102.49200)^\\top \\)   I-R2-IBEA/LTR:  \\( (f_1=120.48400, f_2=74.36900, f_3=111.71900)^\\top \\)       Please cite the paper by using the following bibtex.\n@article{LiLY22, author = {Ke Li and Guiyu Lai and Xin Yao}, title = {Interactive Evolutionary Multi-Objective Optimization via Learning-to-Rank}, journal = {{IEEE} Trans. Evol. Comput.}, pages = {1--15}, year = {2022}, note = {accepted for publication} } "}),e.add({id:22,href:"/docs/events/activities/exeter_leiden_symposium/",title:"Symposium",section:"Docs",content:"Exeter-Leiden Symposium on Data-Driven Modeling and Optimization #      function toggle_visibility(id) { var e = document.getElementById(id); if(e.style.display == 'block') e.style.display = 'none'; else e.style.display = 'block'; }   hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 40% 60%; grid-gap: 5px; background-color: transparent; padding: 5px; } .bibtexpre{ background-color:#F8F8FA; border-radius:5px; border: 2px solid #D8D8DA; margin:10px; white-space: pre-wrap; word-wrap: break-word; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; }   Objectives #  Data has been playing an ever-growing role in artificial/computational intelligence. Such role goes beyond its typical use in neural networks and learning systems, encompassing also evolutionary and other meta-heuristic optimization algorithms. The objective of this symposium is to provide a unique and vibrant cohort for sharing and experiencing the emerging methodologies and applications of data-driven artificial/computational intelligence. It will offer keynotes, invited lectures and discussion groups given by experts from Exeter, Leiden and other high-profile institutions. It will provide a unique opportunity for participants to 1) learn about artificial/computational intelligence approaches and their applications; 2) interact with world-renowned experts in computational intelligence; and 3) communicate with experts and peers with a broad range of backgrounds to exchange ideas and form new collaborations.\nIt will take place as part of the outreach activities of the Alan Turing Institute and the Institute for Data Science and Artificial Intelligence (AI) at the University of Exeter. Both institutes are actively developing and fostering a culture of effective interactions for promoting data science and AI for addressing global challenges across disciplines.\n  Venue and Date #  This symposium will be running fully online via Zoom.\n Zoom ID: 931 5551 9825 | PWD: 959476\n June 6, 2022\n  Speakers #    Prof. Michael Emmerich, Leiden University, Netherlands  Prof. Yaochu Jin, University of Bielefeld, Germany\n  Prof. Thomas Bäck, Leiden University, Netherlands  Prof. Juergen Branke, University of Warwick, UK  Prof. Kaisa Miettinen, University of Jyväskylä, Finland    Schedule #  Note that the time goes with Central European Time (CET)  The symposium will be organized in one day with the following agenda.\n 9:00 – 9:10: Introduction talk by Ke Li/Hao Wang    9:10 – 10:00 | Prof. Michael Emmerich | Leiden University, Netherlands\n Lipschitz Models versus Gaussian Process Models in Data-Driven Multi-objective Optimization\n Bio Michael Emmerich is a Germany-born Computer Scientist who currently lives in Finland and in The Netherlands. Since 2016 he is appointed as Associate Professor at Leiden University, The Netherlands, where he leads the Multicriteria Optimization and Decision Analytics Group and since 2019 he is a visiting researcher at Jyvaskyla University, Finland in the Multiobjective and Industrial Optimization Group. He also is Lead AI Scientist at SILO.ai, a provider of AI solutions n the Nordic Countries. He has received his Doctorate in Natural Sciences from the Technical University of Dortmund on the topic of Gaussian Processes for Surrogate-Assisted Multiobjective Design Optimization (2005) under the supervision of Prof. Dr. Ing. H.-P. Schwefel. He also worked as a visiting fellow at the Center for Applied Systems Analysis, ICD e.V. Dorttmund, Institut für Erstarrung unter Schwerelosigkeit e.V. (Aachen), Institute for Fundamental Research of Matter (FOM) Amsterdam, Unversity of the Algarve, IST Lisbon, and Jyvaskyla University. His main contributions are in the field of indicator-based and Bayesian multiobjective optimization, and application of multiobjective optimization in chemical engineering and architectural design.  |  Abstract The quantification of uncertainty is an important topic when it comes to modeling function landscapes based on previously evaluated input-output pairs. Gaussian process regression and the closely related Kriging method form allegedly the most well known class of surrogate models supporting uncertainty quantification. Here the uncertainty stems from the assumption that outputs are correlated by means of a distance (in the input-space) dependent correlation function. Such knowledge can be used to compute probabilistic confidence bounds to quantify uncertainty of predictions. Lipschitz continuity (and the more general Hölder continuity) on the other hand makes assumptions about bounded change rates. It, too, is based on distances in the input space but its model assumptions yield deterministic upper and lower bounds for the uncertainty ranges in prediction tasks.\nWe contrast these two techniques and reveal commonalities and differences and also comment on their usefulness in the integration to (multiobjective) Bayesian optimization frameworks. A special focus will be on variants of expected improvements and show that the use of a Lipschitzian interpretation of the Expected Improvement is almost equivalent to Shubert's algorithm Computations in the Lipschitzian case are far easier and more efficient while many of the interesting properties of Gaussian process models are preserved.  |  video    10:00 – 10:50 | Prof. Yaochu Jin | University of Bielefeld, Germany\n Privacy-Preserving Data-driven Evolutionary Optimization\n Bio Yaochu Jin is an Alexander von Humboldt Professor for Artificial Intelligence endowed by the German Federal Ministry of Education and Research, Faculty of Technology, Bielefeld University, Germany. He is also a Distinguished Chair in Computational Intelligence, Department of Computer Science, University of Surrey, Guildford, U.K. He was a \"Finland Distinguished Professor\", University of Jyväskylä, Finland, \"Changjiang Distinguished Visiting Professor\", Northeastern University, China, and \"Distinguished Visiting Scholar\", University of Technology Sydney, Australia. His main research interests include evolutionary optimization, evolutionary learning, trustworthy machine learning, and evolutionary developmental systems.\nProf Jin is presently the Editor-in-Chief of Complex \u0026 Intelligent Systems. He was an IEEE Distinguished Lecturer and the Vice President for Technical Activities of the IEEE Computational Intelligence Society. He is named by the Web of Science as \"a Highly Cited Researcher\" from 2019 to 2021 consecutively. He is a Member of Academia Europaea and Fellow of IEEE.  |  Abstract Data-driven optimization has received increased interest over the past decade due to its practical importance in many industrial sectors and scientific research fields. Little attention, however, has been paid to privacy preservation the data used for optimization. This talk presents our recent work on privacy-preserving data-driven evolutionary optimization based on federated learning techniques and infill criteria. The prosed framework is applicable to both single- and multi-objective optimization.  |  video    10:50 – 11:40 | Prof. Thomas Bäck | Leiden University, Netherlands\n Evolutionary Computation meets Algorithm Configuration (and Applications)\n Bio Thomas Bäck is Full Professor of Computer Science at the Leiden Institute of Advanced Computer Science (LIACS), Leiden University, The Netherlands, where he is head of the Natural Computing group since 2002. He received his PhD (adviser: Hans-Paul Schwefel) in computer science from Dortmund University, Germany, in 1994, and then worked for the Informatik Centrum Dortmund (ICD) as department leader of the Center for Applied Systems Analysis. From 2000 - 2009, Thomas was Managing Director of NuTech Solutions GmbH and CTO of NuTech Solutions, Inc. He gained ample experience in solving real-life problems in optimization and data mining through working with global enterprises such as BMW, Beiersdorf, Daimler, Ford, Honda, and many others.\nThomas has more than 300 publications on natural computing, as well as two books on evolutionary algorithms: Evolutionary Algorithms in Theory and Practice (1996), Contemporary Evolution Strategies (2013). He is co-editor of the Handbook of Evolutionary Computation, and the Handbook of Natural Computing, and co-editor-in-chief of Springer's Natural Computing book series. He is also editorial board member and associate editor of a number of journals on evolutionary and natural computing. Thomas received the best dissertation award from the German Society of Computer Science (Gesellschaft für Informatik, GI) in 1995 and the IEEE Computational Intelligence Society Evolutionary Computation Pioneer Award in 2015.  |  Abstract Direct global optimization algorithms based on evolutionary computation have shown big successes in a wide range of application domains, for example engineering design optimization.\nIn machine learning, the optimization of hyperparameters (also called the algorithm configuration problem) is an important task. I will briefly explain this problem and provide some examples illustrating that this task can be handled by direct global optimization algorithms as well. While algorithm configuration is commonly applied to machine learning algorithms, algorithm configuration for evolution strategies is also an exciting application domain. I will give a simple example how a combinatorial design space of 4608 configuration variants of evolution strategies can be explored and investigated using data mining. This approach provides an opportunity for discovering the unexplored areas of the optimization algorithm design space. Conversely, direct global optimization methods can also be used as algorithm configurators, or even for addressing the combined algorithm selection and hyperparameter optimization (CASH) task in machine learning. I will provide some insight into research in this direction, too.\nTo conclude, I return to real world application examples and illustrate a few of those that my group worked on, over the past more than 20 years.  |  video    11:40 – 14:00: Lunch break    14:00 – 14:50 | Prof. Juergen Branke | University of Warwick, UK\n Bayesian Optimisation and Input Uncertainty Reduction\n Bio Juergen Branke is Professor of Operational Research and Systems at Warwick Business School, University of Warwick (UK). His main research interests include metaheuristics and Bayesian optimisation applied to problems under uncertainty, such as simulation optimisation, dynamically changing problems, and multi-objective problems. Prof. Branke is Editor of ACM Transactions on Evolutionary Learning and Optimization, Area Editor of the Journal of Heuristics and the Journal on Multi-Criteria Decision Analysis, as well as Associate Editor of IEEE Transactions on Evolutionary Computation and the Evolutionary Computation Journal.  |  Abstract Simulators often require calibration inputs estimated from real world data and the estimate can significantly affect simulation output. Particularly when performing simulation optimisation to find an optimal solution, the uncertainty in the inputs significantly affects the quality of the found solution. One remedy is to search for the solution that has the best performance on average over the uncertain range of inputs yielding an optimal compromise solution. We consider the more general setting where a user may choose between either running simulations or instead querying an external data source, improving the input estimate and enabling the search for a more targeted, less compromised solution. We explicitly examine the trade-off between simulation and real data collection in order to find the optimal solution of the simulator with the true inputs. Using a value of information procedure, we propose a novel unified simulation optimisation procedure called Bayesian Information Collection and Optimisation (BICO) that, in each iteration, automatically determines which of the two actions (running simulations or data collection) is more beneficial. Numerical experiments demonstrate that the proposed algorithm is able to automatically determine an appropriate balance between optimisation and data collection.  |  video    14:50 – 15:40 | Prof. Kaisa Miettinen | University of Jyväskylä, Finland\n Perspectives to Data-driven Multiobjective Optimization with Interactive Methods\n Bio Kaisa Miettinen is Professor of Industrial Optimization at the University of Jyvaskyla. Her research interests include theory, methods, applications and software of nonlinear multiobjective optimization including interactive and evolutionary approaches. She heads the Research Group on Multiobjective Optimization and is the director of the thematic research area called Decision Analytics utilizing Causal Models and Multiobjective Optimization (DEMO, www.jyu.fi/demo). She has authored over 200 refereed journal, proceedings and collection papers, edited 18 proceedings, collections and special issues and written a monograph Nonlinear Multiobjective Optimization. She is a member of the Finnish Academy of Science and Letters, Section of Science and has served as the President of the International Society on Multiple Criteria Decision Making (MCDM). She belongs to the editorial boards of seven international journals and the Steering Committee of Evolutionary Multiobjective Optimization. She has previously worked at IIASA, International Institute for Applied Systems Analysis in Austria, KTH Royal Institute of Technology in Stockholm, Sweden and Helsinki School of Economics, Finland. She has received the Georg Cantor Award of the International Society on MCDM for independent inquiry in developing innovative ideas in the theory and methodology.  |  Abstract In data analytics, we can use descriptive analytics to understand the data or predictive analytics to make predictions, but to know what actions to take to reach desired outcomes, we need prescriptive analytics. To make optimized recommendations or decisions based on the data, we can fit models in the data and derive optimization problems. In many cases, real decisions to be made are characterized by multiple conflicting objectives to be optimized and we can support decision making by applying appropriate multiobjective optimization methods. This we can call decision analytics.\nIn this talk, I discuss different elements of a seamless chain from data to data-driven decision support involving multiobjective optimization. Eventually, the derived multiobjective optimization problem is solved with an appropriate interactive method. In that way, the decision maker with domain expertise can augment information contained in the data and direct the solution process with one’s preferences. At the same time, the decision maker gains insight into the interdependencies and trade-offs among the conflicting objectives, and can get convinced of the quality of the most preferred solution. In addition, I give some examples of data-driven decision making problems. Finally, I give an overview of the modular, open-source software framework DESDEO containing different interactive methods.  |  video    15:40 – 16:55\n Panel discussion |  video    16:55 – 17:00: Closing remark    Sponsors #  We are grateful to the support from UKRI Future Leaders Fellowship (MR/S017062/1), European Network Fund@Exeter (No. GP ENF5.10) and Turing Fellowship.\n"}),e.add({id:23,href:"/docs/events/activities/turing_workshop/",title:"Symposium",section:"Docs",content:"Turing Workshop on Human-Centric Artificial and Computational Intelligence and Applications #      function toggle_visibility(id) { var e = document.getElementById(id); if(e.style.display == 'block') e.style.display = 'none'; else e.style.display = 'block'; }   hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 40% 60%; grid-gap: 5px; background-color: transparent; padding: 5px; } .bibtexpre{ background-color:#F8F8FA; border-radius:5px; border: 2px solid #D8D8DA; margin:10px; white-space: pre-wrap; word-wrap: break-word; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; }   Objectives #  Data has been playing an ever-growing role in artificial/computational intelligence. Such role goes beyond its typical use in neural networks and learning systems, encompassing also evolutionary and other meta-heuristic optimization algorithms. The objective of this symposium is to provide a unique and vibrant cohort for sharing and experiencing the emerging methodologies and applications of data-driven artificial/computational intelligence. It will offer keynotes, invited lectures and discussion groups given by experts from Exeter, Leiden and other high-profile institutions. It will provide a unique opportunity for participants to 1) learn about artificial/computational intelligence approaches and their applications; 2) interact with world-renowned experts in computational intelligence; and 3) communicate with experts and peers with a broad range of backgrounds to exchange ideas and form new collaborations.\nIt will take place as part of the outreach activities of the Alan Turing Institute and the Institute for Data Science and Artificial Intelligence (AI) at the University of Exeter. Both institutes are actively developing and fostering a culture of effective interactions for promoting data science and AI for addressing global challenges across disciplines.\n  Venue and Date #  This workshop will be running in person at beautiful Streatham Campus of the University of Exeter.\n April 26\u0026ndash;28, 2023\n  Speakers #  TBD\n  Schedule #  Note that the time goes with Greenwich Mean Time (GMT)  The agenda of this workshop will be released soon.\n April 26, 2023\n 11:30 – 14:00: Registration and lunch    April 27, 2023\n  April 28, 2023\n  11:40 – 14:00: Lunch break    Sponsors #  We are grateful to the support from Turing Network Fund and UKRI Future Leaders Fellowship (MR/S017062/1, MR/X011135/1).\n"}),e.add({id:24,href:"/docs/turing_workshop/",title:"Symposium",section:"Docs",content:"Turing Workshop on Human-Centric Artificial and Computational Intelligence and Applications #      function toggle_visibility(id) { var e = document.getElementById(id); if(e.style.display == 'block') e.style.display = 'none'; else e.style.display = 'block'; }   hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 40% 60%; grid-gap: 5px; background-color: transparent; padding: 5px; } .bibtexpre{ background-color:#F8F8FA; border-radius:5px; border: 2px solid #D8D8DA; margin:10px; white-space: pre-wrap; word-wrap: break-word; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; }   Synopsis #  Human-Centered artificial/computational intelligence (HCAI/CI) is an emerging discipline intent on creating AI/CI systems that amplify and augment rather than displace human abilities. Instead, HCAI/CI seeks to preserve human control in a way that ensures AI meets our needs while also operating in a reliable, robust, and transparent manner, delivering equitable outcomes, and respecting privacy.\nThis workshop is designed to bring key data scientists and AI experts from both academia and industry to sharing up to date research and innovation developments themed on HCAI/CI, but also help identify the key challenges in stakeholders. We anticipate this workshop playing as the springboard to explore potential collaboration between academics and with industrial stakeholders. It will take place as part of the outreach activities of the Alan Turing Institute and the Institute for Data Science and Artificial Intelligence (AI) at the University of Exeter (partnering with the University of Oxford and the University of Birmingham). Both institutes are actively developing and fostering a culture of effective interactions for promoting data science and AI for addressing global challenges across disciplines.\n Objectives #  We want to leverage this workshop as a driver to develop an emerging area related to human-centric C/AI and raise the awareness of the Alan Turing Institute nationally and internationally in the forefront of AI/CI.\n Promote the inter-disciplinary knowledge exchange and conversation between academics and industrial stakeholders themed on the HCAI/CI approaches for engineering, scientific and public sectors. Identify the key challenges and opportunities of bringing human in the loop of AI and CI as well as their uptake in the real world. Promote and explore the potential collaboration across different universities and with industry.    Date #  This workshop will be running from April 26 to April 28, 2023\n  Speakers #  TBD\n  Schedule #  Note that the time goes with Greenwich Mean Time (GMT)  The detailed agenda of this workshop will be released in due course.\n April 26, 2023\n 11:30 \u0026ndash; 14:00: Registration and lunch 14:00 \u0026ndash; 17:30: Talks 18:00 \u0026ndash; 20:00: Dinner    April 27, 2023\n 9:00 \u0026ndash; 12:00: Talks 12:00 \u0026ndash; 14:00: Lunch 14:00 \u0026ndash; 17:30: Talks and breakout groups 18:00 \u0026ndash; 20:00: Dinner    April 28, 2023\n 9:00 \u0026ndash; 12:00: Talks and panel discussion 12:00 \u0026ndash; 14:00: Lunch 14:00 \u0026ndash; 17:30: Talks    11:40 – 14:00: Lunch break    Sponsors #  We are grateful to the support from Turing Network Fund and UKRI Future Leaders Fellowship (MR/S017062/1, MR/X011135/1).\n  Venue #  This workshop will be running in person at beautiful Streatham Campus of the University of Exeter.\n "}),e.add({id:25,href:"/turing_workshop/",title:"Symposium",section:"Home",content:"Turing Workshop on Human-Centric Artificial and Computational Intelligence and Applications #      function toggle_visibility(id) { var e = document.getElementById(id); if(e.style.display == 'block') e.style.display = 'none'; else e.style.display = 'block'; }   hr.dashed { border-top: 1px dashed #bbb; } .grid-container { display: grid; grid-template-columns: 40% 60%; grid-gap: 5px; background-color: transparent; padding: 5px; } .bibtexpre{ background-color:#F8F8FA; border-radius:5px; border: 2px solid #D8D8DA; margin:10px; white-space: pre-wrap; word-wrap: break-word; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; }   Synopsis #  Human-Centered artificial/computational intelligence (HCAI/CI) is an emerging discipline intent on creating AI/CI systems that amplify and augment rather than displace human abilities. Instead, HCAI/CI seeks to preserve human control in a way that ensures AI meets our needs while also operating in a reliable, robust, and transparent manner, delivering equitable outcomes, and respecting privacy.\nThis workshop is designed to bring key data scientists and AI experts from both academia and industry to sharing up to date research and innovation developments themed on HCAI/CI, but also help identify the key challenges in stakeholders. We anticipate this workshop playing as the springboard to explore potential collaboration between academics and with industrial stakeholders. It will take place as part of the outreach activities of the Alan Turing Institute and the Institute for Data Science and Artificial Intelligence (AI) at the University of Exeter (partnering with the University of Oxford and the University of Birmingham). Both institutes are actively developing and fostering a culture of effective interactions for promoting data science and AI for addressing global challenges across disciplines.\n Objectives #  We want to leverage this workshop as a driver to develop an emerging area related to human-centric C/AI and raise the awareness of the Alan Turing Institute nationally and internationally in the forefront of AI/CI.\n Promote the inter-disciplinary knowledge exchange and conversation between academics and industrial stakeholders themed on the HCAI/CI approaches for engineering, scientific and public sectors. Identify the key challenges and opportunities of bringing human in the loop of AI and CI as well as their uptake in the real world. Promote and explore the potential collaboration across different universities and with industry.    Date #  This workshop will be running from April 26 to April 28, 2023\n  Speakers #  TBD\n  Schedule #  Note that the time goes with Greenwich Mean Time (GMT)  The detailed agenda of this workshop will be released in due course.\n April 26, 2023\n 11:30 \u0026ndash; 14:30: Registration and lunch 14:30 \u0026ndash; 17:30: Talks    April 27, 2023\n 8:30 \u0026ndash; 9:30: Arrival \u0026ndash; tea and coffee 9:30 \u0026ndash; 12:30: Academic talks 12:30 \u0026ndash; 14:30: Lunch break and poster session 14:30 \u0026ndash; 17:30: Industrial session 18:00 \u0026ndash; 20:00: Dinner    April 28, 2023\n 8:30 \u0026ndash; 9:30: Arrival \u0026ndash; tea and coffee 9:30 \u0026ndash; 11:30: Industrial session 11:30 – 14:00: Round up lunch and close    Sponsors #  We are grateful to the support from Turing Network Fund and UKRI Future Leaders Fellowship (MR/S017062/1, MR/X011135/1).\n  Venue #  This workshop will be running in person at beautiful Streatham Campus of the University of Exeter.\n "}),e.add({id:26,href:"/docs/home/vacancies/",title:"Vacancies",section:"Docs",content:"Vacancies #    We very much welcome and support applications from underrepresented groups and from people of all shapes, shades, and genders. If you are uncertain about your possible role in our team, please do not hesitate to get in touch with Ke Li.\nWe have multiple fully funded PhD studentships available for September 2023 entry.\n UKRI and CEMPS co-funded PhD studentship to commence on 25th September 2023 or as soon as possible thereafter. For eligible students the studentship will cover Home tuition fees plus an annual tax-free stipend of at least £17,668 for 3.5 years full-time, or pro rata for part-time study. More detailed information can be found from here. Exeter-CSC PhD studentship is open for application. The application deadline for this entry is 4th January 2023. Please contact me as soon as possible about this opportunity and I can support your application materials. More detailed information can be found from here.   PhD There are multiple opportunities available at the University of Exeter to fund your PhD study.\n China Scholarship Council (Chinese Students): The University of Exeter is proud to offer up to 50 full-time PhD scholarships in collaboration with the China Scholarship Council (CSC). The application deadline is usually around the beginning of January. More detailed information can be found from here. Doctor Training Partnerships (UK/EU \u0026amp; International Students): As a research intensive university in the UK, Exeter has strong commitments to work in partnerships with several research councils to fund talented students for a PhD. The deadline is usually around the end of January every year. More detailed information can be found from here.  Research Fellow We welcome applications by post-doc and research fellows. Unfortunately, we do not have funding available at this time. However, if you want to propose a collaboration based on an externally-funded post-doctoral scholarship, please get in touch. Here are some potential funding opportunities:\n  Dorothy Hodkin Fellowship  Marie-Curie Fellowship  EPSRC Post-Doctoral Fellowship  Newton International Fellowships (for who are not based in the UK)  University Research Fellowship  Royal Commission for the Exhibition of 1851 Research Fellowship  Royal Academy of Engineering Fellowship  Visiting Scholar We are also welcome the self-funded visiting scholars (supported by CSC or other government organisations) to join the COLA Laboratory. Note that I prefer at most host 3 long-term (at least one year) visitors simultaneously in order to allocate enough supervision time.  Some useful tips to know when preparing your pitching email \u0026#43;   Use Subject Line: 20** Prospective Students/Postdoc/Visiting Scholar_YourName Briefly introduce your education background, GPA/Rank, IELTS/TOEFL score, and other highlights (e.g., publications, previous awards and industrial experiences). Briefly (1-page summary) introduce your research experience, and explain what your general research interests and strengths are. Explain why you want to choose our lab. Briefly mention one of my recent work that you are most interested in, and discuss the potential extensions that you might want to work on. Include your CV in the attachment.  Due to the large volume of inquiries, I cannot unfortunately afford to reply all those enquiry emails.     We are not able to host any summer intern in our lab at the moment.\n "})})()